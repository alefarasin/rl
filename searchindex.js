Search.setIndex({"docnames": ["index", "reference/collectors", "reference/data", "reference/envs", "reference/generated/knowledge_base/DEBUGGING_RL", "reference/generated/knowledge_base/GYM", "reference/generated/knowledge_base/HABITAT", "reference/generated/knowledge_base/MUJOCO_INSTALLATION", "reference/generated/knowledge_base/PRO-TIPS", "reference/generated/knowledge_base/RESOURCES", "reference/generated/knowledge_base/VERSIONING_ISSUES", "reference/generated/torchrl._utils.implement_for", "reference/generated/torchrl.collectors.collectors.DataCollectorBase", "reference/generated/torchrl.collectors.collectors.MultiSyncDataCollector", "reference/generated/torchrl.collectors.collectors.MultiaSyncDataCollector", "reference/generated/torchrl.collectors.collectors.RandomPolicy", "reference/generated/torchrl.collectors.collectors.SyncDataCollector", "reference/generated/torchrl.collectors.collectors.aSyncDataCollector", "reference/generated/torchrl.collectors.distributed.DistributedDataCollector", "reference/generated/torchrl.collectors.distributed.DistributedSyncDataCollector", "reference/generated/torchrl.collectors.distributed.RPCDataCollector", "reference/generated/torchrl.collectors.distributed.RayCollector", "reference/generated/torchrl.collectors.distributed.submitit_delayed_launcher", "reference/generated/torchrl.collectors.utils.split_trajectories", "reference/generated/torchrl.data.BinaryDiscreteTensorSpec", "reference/generated/torchrl.data.BoundedTensorSpec", "reference/generated/torchrl.data.CompositeSpec", "reference/generated/torchrl.data.DiscreteTensorSpec", "reference/generated/torchrl.data.LazyStackedCompositeSpec", "reference/generated/torchrl.data.LazyStackedTensorSpec", "reference/generated/torchrl.data.MultiDiscreteTensorSpec", "reference/generated/torchrl.data.MultiOneHotDiscreteTensorSpec", "reference/generated/torchrl.data.MultiStep", "reference/generated/torchrl.data.OneHotDiscreteTensorSpec", "reference/generated/torchrl.data.PairwiseDataset", "reference/generated/torchrl.data.PrioritizedReplayBuffer", "reference/generated/torchrl.data.PromptData", "reference/generated/torchrl.data.PromptTensorDictTokenizer", "reference/generated/torchrl.data.ReplayBuffer", "reference/generated/torchrl.data.RewardData", "reference/generated/torchrl.data.RolloutFromModel", "reference/generated/torchrl.data.TensorDictPrioritizedReplayBuffer", "reference/generated/torchrl.data.TensorDictReplayBuffer", "reference/generated/torchrl.data.TensorDictTokenizer", "reference/generated/torchrl.data.TensorSpec", "reference/generated/torchrl.data.TokenizedDatasetLoader", "reference/generated/torchrl.data.UnboundedContinuousTensorSpec", "reference/generated/torchrl.data.UnboundedDiscreteTensorSpec", "reference/generated/torchrl.data.check_no_exclusive_keys", "reference/generated/torchrl.data.consolidate_spec", "reference/generated/torchrl.data.contains_lazy_spec", "reference/generated/torchrl.data.create_infinite_iterator", "reference/generated/torchrl.data.datasets.D4RLExperienceReplay", "reference/generated/torchrl.data.datasets.GenDGRLExperienceReplay", "reference/generated/torchrl.data.datasets.MinariExperienceReplay", "reference/generated/torchrl.data.datasets.OpenMLExperienceReplay", "reference/generated/torchrl.data.datasets.OpenXExperienceReplay", "reference/generated/torchrl.data.datasets.RobosetExperienceReplay", "reference/generated/torchrl.data.datasets.VD4RLExperienceReplay", "reference/generated/torchrl.data.get_dataloader", "reference/generated/torchrl.data.replay_buffers.ImmutableDatasetWriter", "reference/generated/torchrl.data.replay_buffers.LazyMemmapStorage", "reference/generated/torchrl.data.replay_buffers.LazyTensorStorage", "reference/generated/torchrl.data.replay_buffers.ListStorage", "reference/generated/torchrl.data.replay_buffers.PrioritizedSampler", "reference/generated/torchrl.data.replay_buffers.RandomSampler", "reference/generated/torchrl.data.replay_buffers.ReplayBufferEnsemble", "reference/generated/torchrl.data.replay_buffers.RoundRobinWriter", "reference/generated/torchrl.data.replay_buffers.Sampler", "reference/generated/torchrl.data.replay_buffers.SamplerEnsemble", "reference/generated/torchrl.data.replay_buffers.SamplerWithoutReplacement", "reference/generated/torchrl.data.replay_buffers.SliceSampler", "reference/generated/torchrl.data.replay_buffers.SliceSamplerWithoutReplacement", "reference/generated/torchrl.data.replay_buffers.Storage", "reference/generated/torchrl.data.replay_buffers.StorageEnsemble", "reference/generated/torchrl.data.replay_buffers.TensorDictMaxValueWriter", "reference/generated/torchrl.data.replay_buffers.TensorDictRoundRobinWriter", "reference/generated/torchrl.data.replay_buffers.TensorStorage", "reference/generated/torchrl.data.replay_buffers.Writer", "reference/generated/torchrl.data.replay_buffers.WriterEnsemble", "reference/generated/torchrl.envs.BraxEnv", "reference/generated/torchrl.envs.BraxWrapper", "reference/generated/torchrl.envs.DMControlEnv", "reference/generated/torchrl.envs.DMControlWrapper", "reference/generated/torchrl.envs.EnvBase", "reference/generated/torchrl.envs.EnvCreator", "reference/generated/torchrl.envs.EnvMetaData", "reference/generated/torchrl.envs.GymEnv", "reference/generated/torchrl.envs.GymLikeEnv", "reference/generated/torchrl.envs.GymWrapper", "reference/generated/torchrl.envs.HabitatEnv", "reference/generated/torchrl.envs.IsaacGymEnv", "reference/generated/torchrl.envs.IsaacGymWrapper", "reference/generated/torchrl.envs.JumanjiEnv", "reference/generated/torchrl.envs.JumanjiWrapper", "reference/generated/torchrl.envs.MOGymEnv", "reference/generated/torchrl.envs.MOGymWrapper", "reference/generated/torchrl.envs.MarlGroupMapType", "reference/generated/torchrl.envs.ModelBasedEnvBase", "reference/generated/torchrl.envs.MultiThreadedEnv", "reference/generated/torchrl.envs.MultiThreadedEnvWrapper", "reference/generated/torchrl.envs.OpenMLEnv", "reference/generated/torchrl.envs.ParallelEnv", "reference/generated/torchrl.envs.PettingZooEnv", "reference/generated/torchrl.envs.PettingZooWrapper", "reference/generated/torchrl.envs.RoboHiveEnv", "reference/generated/torchrl.envs.SMACv2Env", "reference/generated/torchrl.envs.SMACv2Wrapper", "reference/generated/torchrl.envs.SerialEnv", "reference/generated/torchrl.envs.VmasEnv", "reference/generated/torchrl.envs.VmasWrapper", "reference/generated/torchrl.envs.check_marl_grouping", "reference/generated/torchrl.envs.gym_backend", "reference/generated/torchrl.envs.model_based.dreamer.DreamerEnv", "reference/generated/torchrl.envs.set_gym_backend", "reference/generated/torchrl.envs.transforms.ActionMask", "reference/generated/torchrl.envs.transforms.BinarizeReward", "reference/generated/torchrl.envs.transforms.BurnInTransform", "reference/generated/torchrl.envs.transforms.CatFrames", "reference/generated/torchrl.envs.transforms.CatTensors", "reference/generated/torchrl.envs.transforms.CenterCrop", "reference/generated/torchrl.envs.transforms.ClipTransform", "reference/generated/torchrl.envs.transforms.Compose", "reference/generated/torchrl.envs.transforms.DTypeCastTransform", "reference/generated/torchrl.envs.transforms.DeviceCastTransform", "reference/generated/torchrl.envs.transforms.DiscreteActionProjection", "reference/generated/torchrl.envs.transforms.DoubleToFloat", "reference/generated/torchrl.envs.transforms.EndOfLifeTransform", "reference/generated/torchrl.envs.transforms.ExcludeTransform", "reference/generated/torchrl.envs.transforms.FiniteTensorDictCheck", "reference/generated/torchrl.envs.transforms.FlattenObservation", "reference/generated/torchrl.envs.transforms.FrameSkipTransform", "reference/generated/torchrl.envs.transforms.GrayScale", "reference/generated/torchrl.envs.transforms.InitTracker", "reference/generated/torchrl.envs.transforms.KLRewardTransform", "reference/generated/torchrl.envs.transforms.NoopResetEnv", "reference/generated/torchrl.envs.transforms.ObservationNorm", "reference/generated/torchrl.envs.transforms.ObservationTransform", "reference/generated/torchrl.envs.transforms.PermuteTransform", "reference/generated/torchrl.envs.transforms.PinMemoryTransform", "reference/generated/torchrl.envs.transforms.R3MTransform", "reference/generated/torchrl.envs.transforms.RandomCropTensorDict", "reference/generated/torchrl.envs.transforms.RemoveEmptySpecs", "reference/generated/torchrl.envs.transforms.RenameTransform", "reference/generated/torchrl.envs.transforms.Resize", "reference/generated/torchrl.envs.transforms.Reward2GoTransform", "reference/generated/torchrl.envs.transforms.RewardClipping", "reference/generated/torchrl.envs.transforms.RewardScaling", "reference/generated/torchrl.envs.transforms.RewardSum", "reference/generated/torchrl.envs.transforms.SelectTransform", "reference/generated/torchrl.envs.transforms.SignTransform", "reference/generated/torchrl.envs.transforms.SqueezeTransform", "reference/generated/torchrl.envs.transforms.StepCounter", "reference/generated/torchrl.envs.transforms.TargetReturn", "reference/generated/torchrl.envs.transforms.TensorDictPrimer", "reference/generated/torchrl.envs.transforms.TimeMaxPool", "reference/generated/torchrl.envs.transforms.ToTensorImage", "reference/generated/torchrl.envs.transforms.Transform", "reference/generated/torchrl.envs.transforms.TransformedEnv", "reference/generated/torchrl.envs.transforms.UnsqueezeTransform", "reference/generated/torchrl.envs.transforms.VC1Transform", "reference/generated/torchrl.envs.transforms.VIPRewardTransform", "reference/generated/torchrl.envs.transforms.VIPTransform", "reference/generated/torchrl.envs.transforms.VecGymEnvTransform", "reference/generated/torchrl.envs.transforms.VecNorm", "reference/generated/torchrl.envs.transforms.gSDENoise", "reference/generated/torchrl.envs.utils.check_env_specs", "reference/generated/torchrl.envs.utils.exploration_mode", "reference/generated/torchrl.envs.utils.exploration_type", "reference/generated/torchrl.envs.utils.get_available_libraries", "reference/generated/torchrl.envs.utils.make_composite_from_td", "reference/generated/torchrl.envs.utils.set_exploration_mode", "reference/generated/torchrl.envs.utils.set_exploration_type", "reference/generated/torchrl.envs.utils.step_mdp", "reference/generated/torchrl.envs.utils.terminated_or_truncated", "reference/generated/torchrl.modules.CEMPlanner", "reference/generated/torchrl.modules.Conv3dNet", "reference/generated/torchrl.modules.ConvNet", "reference/generated/torchrl.modules.DTActor", "reference/generated/torchrl.modules.DdpgCnnActor", "reference/generated/torchrl.modules.DdpgCnnQNet", "reference/generated/torchrl.modules.DdpgMlpActor", "reference/generated/torchrl.modules.DdpgMlpQNet", "reference/generated/torchrl.modules.DecisionTransformer", "reference/generated/torchrl.modules.Delta", "reference/generated/torchrl.modules.DistributionalDQNnet", "reference/generated/torchrl.modules.DistributionalQValueHook", "reference/generated/torchrl.modules.DreamerActor", "reference/generated/torchrl.modules.DuelingCnnDQNet", "reference/generated/torchrl.modules.GRU", "reference/generated/torchrl.modules.GRUCell", "reference/generated/torchrl.modules.GRUModule", "reference/generated/torchrl.modules.IndependentNormal", "reference/generated/torchrl.modules.LSTM", "reference/generated/torchrl.modules.LSTMCell", "reference/generated/torchrl.modules.LSTMModule", "reference/generated/torchrl.modules.LSTMNet", "reference/generated/torchrl.modules.MLP", "reference/generated/torchrl.modules.MPCPlannerBase", "reference/generated/torchrl.modules.MPPIPlanner", "reference/generated/torchrl.modules.MaskedCategorical", "reference/generated/torchrl.modules.MaskedOneHotCategorical", "reference/generated/torchrl.modules.MultiAgentConvNet", "reference/generated/torchrl.modules.MultiAgentMLP", "reference/generated/torchrl.modules.NoisyLazyLinear", "reference/generated/torchrl.modules.NoisyLinear", "reference/generated/torchrl.modules.NormalParamWrapper", "reference/generated/torchrl.modules.ObsDecoder", "reference/generated/torchrl.modules.ObsEncoder", "reference/generated/torchrl.modules.OneHotCategorical", "reference/generated/torchrl.modules.OnlineDTActor", "reference/generated/torchrl.modules.QMixer", "reference/generated/torchrl.modules.QValueHook", "reference/generated/torchrl.modules.RSSMPosterior", "reference/generated/torchrl.modules.RSSMPrior", "reference/generated/torchrl.modules.Squeeze2dLayer", "reference/generated/torchrl.modules.SqueezeLayer", "reference/generated/torchrl.modules.TanhDelta", "reference/generated/torchrl.modules.TanhNormal", "reference/generated/torchrl.modules.TruncatedNormal", "reference/generated/torchrl.modules.VDNMixer", "reference/generated/torchrl.modules.VmapModule", "reference/generated/torchrl.modules.reset_noise", "reference/generated/torchrl.modules.tensordict_module.Actor", "reference/generated/torchrl.modules.tensordict_module.ActorCriticOperator", "reference/generated/torchrl.modules.tensordict_module.ActorCriticWrapper", "reference/generated/torchrl.modules.tensordict_module.ActorValueOperator", "reference/generated/torchrl.modules.tensordict_module.AdditiveGaussianWrapper", "reference/generated/torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper", "reference/generated/torchrl.modules.tensordict_module.DistributionalQValueActor", "reference/generated/torchrl.modules.tensordict_module.DistributionalQValueModule", "reference/generated/torchrl.modules.tensordict_module.EGreedyModule", "reference/generated/torchrl.modules.tensordict_module.EGreedyWrapper", "reference/generated/torchrl.modules.tensordict_module.LMHeadActorValueOperator", "reference/generated/torchrl.modules.tensordict_module.OrnsteinUhlenbeckProcessWrapper", "reference/generated/torchrl.modules.tensordict_module.ProbabilisticActor", "reference/generated/torchrl.modules.tensordict_module.QValueActor", "reference/generated/torchrl.modules.tensordict_module.QValueModule", "reference/generated/torchrl.modules.tensordict_module.SafeModule", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticModule", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential", "reference/generated/torchrl.modules.tensordict_module.SafeSequential", "reference/generated/torchrl.modules.tensordict_module.TanhModule", "reference/generated/torchrl.modules.tensordict_module.ValueOperator", "reference/generated/torchrl.modules.tensordict_module.WorldModelWrapper", "reference/generated/torchrl.modules.utils.biased_softplus", "reference/generated/torchrl.modules.utils.inv_softplus", "reference/generated/torchrl.modules.utils.mappings", "reference/generated/torchrl.objectives.A2CLoss", "reference/generated/torchrl.objectives.CQLLoss", "reference/generated/torchrl.objectives.ClipPPOLoss", "reference/generated/torchrl.objectives.DDPGLoss", "reference/generated/torchrl.objectives.DQNLoss", "reference/generated/torchrl.objectives.DTLoss", "reference/generated/torchrl.objectives.DiscreteCQLLoss", "reference/generated/torchrl.objectives.DiscreteIQLLoss", "reference/generated/torchrl.objectives.DiscreteSACLoss", "reference/generated/torchrl.objectives.DistributionalDQNLoss", "reference/generated/torchrl.objectives.DreamerActorLoss", "reference/generated/torchrl.objectives.DreamerModelLoss", "reference/generated/torchrl.objectives.DreamerValueLoss", "reference/generated/torchrl.objectives.HardUpdate", "reference/generated/torchrl.objectives.IQLLoss", "reference/generated/torchrl.objectives.KLPENPPOLoss", "reference/generated/torchrl.objectives.LossModule", "reference/generated/torchrl.objectives.OnlineDTLoss", "reference/generated/torchrl.objectives.PPOLoss", "reference/generated/torchrl.objectives.REDQLoss", "reference/generated/torchrl.objectives.ReinforceLoss", "reference/generated/torchrl.objectives.SACLoss", "reference/generated/torchrl.objectives.SoftUpdate", "reference/generated/torchrl.objectives.TD3Loss", "reference/generated/torchrl.objectives.ValueEstimators", "reference/generated/torchrl.objectives.default_value_kwargs", "reference/generated/torchrl.objectives.distance_loss", "reference/generated/torchrl.objectives.hold_out_net", "reference/generated/torchrl.objectives.hold_out_params", "reference/generated/torchrl.objectives.multiagent.QMixerLoss", "reference/generated/torchrl.objectives.next_state_value", "reference/generated/torchrl.objectives.value.GAE", "reference/generated/torchrl.objectives.value.TD0Estimator", "reference/generated/torchrl.objectives.value.TD1Estimator", "reference/generated/torchrl.objectives.value.TDLambdaEstimator", "reference/generated/torchrl.objectives.value.ValueEstimatorBase", "reference/generated/torchrl.objectives.value.functional.generalized_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.reward2go", "reference/generated/torchrl.objectives.value.functional.td0_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.td0_return_estimate", "reference/generated/torchrl.objectives.value.functional.td1_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.td1_return_estimate", "reference/generated/torchrl.objectives.value.functional.td_lambda_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.td_lambda_return_estimate", "reference/generated/torchrl.objectives.value.functional.vec_generalized_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.vec_td1_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.vec_td1_return_estimate", "reference/generated/torchrl.objectives.value.functional.vec_td_lambda_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.vec_td_lambda_return_estimate", "reference/generated/torchrl.record.TensorDictRecorder", "reference/generated/torchrl.record.VideoRecorder", "reference/generated/torchrl.record.loggers.Logger", "reference/generated/torchrl.record.loggers.csv.CSVLogger", "reference/generated/torchrl.record.loggers.generate_exp_name", "reference/generated/torchrl.record.loggers.get_logger", "reference/generated/torchrl.record.loggers.mlflow.MLFlowLogger", "reference/generated/torchrl.record.loggers.tensorboard.TensorboardLogger", "reference/generated/torchrl.record.loggers.wandb.WandbLogger", "reference/generated/torchrl.trainers.BatchSubSampler", "reference/generated/torchrl.trainers.ClearCudaCache", "reference/generated/torchrl.trainers.CountFramesLog", "reference/generated/torchrl.trainers.LogReward", "reference/generated/torchrl.trainers.OptimizerHook", "reference/generated/torchrl.trainers.Recorder", "reference/generated/torchrl.trainers.ReplayBufferTrainer", "reference/generated/torchrl.trainers.RewardNormalizer", "reference/generated/torchrl.trainers.SelectKeys", "reference/generated/torchrl.trainers.Trainer", "reference/generated/torchrl.trainers.TrainerHookBase", "reference/generated/torchrl.trainers.UpdateWeights", "reference/generated/torchrl.trainers.helpers.correct_for_frame_skip", "reference/generated/torchrl.trainers.helpers.get_stats_random_rollout", "reference/generated/torchrl.trainers.helpers.make_collector_offpolicy", "reference/generated/torchrl.trainers.helpers.make_collector_onpolicy", "reference/generated/torchrl.trainers.helpers.make_dqn_loss", "reference/generated/torchrl.trainers.helpers.make_redq_loss", "reference/generated/torchrl.trainers.helpers.make_redq_model", "reference/generated/torchrl.trainers.helpers.make_replay_buffer", "reference/generated/torchrl.trainers.helpers.make_target_updater", "reference/generated/torchrl.trainers.helpers.make_trainer", "reference/generated/torchrl.trainers.helpers.parallel_env_constructor", "reference/generated/torchrl.trainers.helpers.sync_async_collector", "reference/generated/torchrl.trainers.helpers.sync_sync_collector", "reference/generated/torchrl.trainers.helpers.transformed_env_constructor", "reference/generated/tutorials/README", "reference/index", "reference/knowledge_base", "reference/modules", "reference/objectives", "reference/trainers", "reference/utils", "sg_execution_times", "tutorials/coding_ddpg", "tutorials/coding_dqn", "tutorials/coding_ppo", "tutorials/dqn_with_rnn", "tutorials/index", "tutorials/multi_task", "tutorials/multiagent_ppo", "tutorials/pendulum", "tutorials/pretrained_models", "tutorials/rb_tutorial", "tutorials/sg_execution_times", "tutorials/torchrl_demo", "tutorials/torchrl_envs"], "filenames": ["index.rst", "reference/collectors.rst", "reference/data.rst", "reference/envs.rst", "reference/generated/knowledge_base/DEBUGGING_RL.rst", "reference/generated/knowledge_base/GYM.rst", "reference/generated/knowledge_base/HABITAT.rst", "reference/generated/knowledge_base/MUJOCO_INSTALLATION.rst", "reference/generated/knowledge_base/PRO-TIPS.rst", "reference/generated/knowledge_base/RESOURCES.rst", "reference/generated/knowledge_base/VERSIONING_ISSUES.rst", "reference/generated/torchrl._utils.implement_for.rst", "reference/generated/torchrl.collectors.collectors.DataCollectorBase.rst", "reference/generated/torchrl.collectors.collectors.MultiSyncDataCollector.rst", "reference/generated/torchrl.collectors.collectors.MultiaSyncDataCollector.rst", "reference/generated/torchrl.collectors.collectors.RandomPolicy.rst", "reference/generated/torchrl.collectors.collectors.SyncDataCollector.rst", "reference/generated/torchrl.collectors.collectors.aSyncDataCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedDataCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedSyncDataCollector.rst", "reference/generated/torchrl.collectors.distributed.RPCDataCollector.rst", "reference/generated/torchrl.collectors.distributed.RayCollector.rst", "reference/generated/torchrl.collectors.distributed.submitit_delayed_launcher.rst", "reference/generated/torchrl.collectors.utils.split_trajectories.rst", "reference/generated/torchrl.data.BinaryDiscreteTensorSpec.rst", "reference/generated/torchrl.data.BoundedTensorSpec.rst", "reference/generated/torchrl.data.CompositeSpec.rst", "reference/generated/torchrl.data.DiscreteTensorSpec.rst", "reference/generated/torchrl.data.LazyStackedCompositeSpec.rst", "reference/generated/torchrl.data.LazyStackedTensorSpec.rst", "reference/generated/torchrl.data.MultiDiscreteTensorSpec.rst", "reference/generated/torchrl.data.MultiOneHotDiscreteTensorSpec.rst", "reference/generated/torchrl.data.MultiStep.rst", "reference/generated/torchrl.data.OneHotDiscreteTensorSpec.rst", "reference/generated/torchrl.data.PairwiseDataset.rst", "reference/generated/torchrl.data.PrioritizedReplayBuffer.rst", "reference/generated/torchrl.data.PromptData.rst", "reference/generated/torchrl.data.PromptTensorDictTokenizer.rst", "reference/generated/torchrl.data.ReplayBuffer.rst", "reference/generated/torchrl.data.RewardData.rst", "reference/generated/torchrl.data.RolloutFromModel.rst", "reference/generated/torchrl.data.TensorDictPrioritizedReplayBuffer.rst", "reference/generated/torchrl.data.TensorDictReplayBuffer.rst", "reference/generated/torchrl.data.TensorDictTokenizer.rst", "reference/generated/torchrl.data.TensorSpec.rst", "reference/generated/torchrl.data.TokenizedDatasetLoader.rst", "reference/generated/torchrl.data.UnboundedContinuousTensorSpec.rst", "reference/generated/torchrl.data.UnboundedDiscreteTensorSpec.rst", "reference/generated/torchrl.data.check_no_exclusive_keys.rst", "reference/generated/torchrl.data.consolidate_spec.rst", "reference/generated/torchrl.data.contains_lazy_spec.rst", "reference/generated/torchrl.data.create_infinite_iterator.rst", "reference/generated/torchrl.data.datasets.D4RLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.GenDGRLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.MinariExperienceReplay.rst", "reference/generated/torchrl.data.datasets.OpenMLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.OpenXExperienceReplay.rst", "reference/generated/torchrl.data.datasets.RobosetExperienceReplay.rst", "reference/generated/torchrl.data.datasets.VD4RLExperienceReplay.rst", "reference/generated/torchrl.data.get_dataloader.rst", "reference/generated/torchrl.data.replay_buffers.ImmutableDatasetWriter.rst", "reference/generated/torchrl.data.replay_buffers.LazyMemmapStorage.rst", "reference/generated/torchrl.data.replay_buffers.LazyTensorStorage.rst", "reference/generated/torchrl.data.replay_buffers.ListStorage.rst", "reference/generated/torchrl.data.replay_buffers.PrioritizedSampler.rst", "reference/generated/torchrl.data.replay_buffers.RandomSampler.rst", "reference/generated/torchrl.data.replay_buffers.ReplayBufferEnsemble.rst", "reference/generated/torchrl.data.replay_buffers.RoundRobinWriter.rst", "reference/generated/torchrl.data.replay_buffers.Sampler.rst", "reference/generated/torchrl.data.replay_buffers.SamplerEnsemble.rst", "reference/generated/torchrl.data.replay_buffers.SamplerWithoutReplacement.rst", "reference/generated/torchrl.data.replay_buffers.SliceSampler.rst", "reference/generated/torchrl.data.replay_buffers.SliceSamplerWithoutReplacement.rst", "reference/generated/torchrl.data.replay_buffers.Storage.rst", "reference/generated/torchrl.data.replay_buffers.StorageEnsemble.rst", "reference/generated/torchrl.data.replay_buffers.TensorDictMaxValueWriter.rst", "reference/generated/torchrl.data.replay_buffers.TensorDictRoundRobinWriter.rst", "reference/generated/torchrl.data.replay_buffers.TensorStorage.rst", "reference/generated/torchrl.data.replay_buffers.Writer.rst", "reference/generated/torchrl.data.replay_buffers.WriterEnsemble.rst", "reference/generated/torchrl.envs.BraxEnv.rst", "reference/generated/torchrl.envs.BraxWrapper.rst", "reference/generated/torchrl.envs.DMControlEnv.rst", "reference/generated/torchrl.envs.DMControlWrapper.rst", "reference/generated/torchrl.envs.EnvBase.rst", "reference/generated/torchrl.envs.EnvCreator.rst", "reference/generated/torchrl.envs.EnvMetaData.rst", "reference/generated/torchrl.envs.GymEnv.rst", "reference/generated/torchrl.envs.GymLikeEnv.rst", "reference/generated/torchrl.envs.GymWrapper.rst", "reference/generated/torchrl.envs.HabitatEnv.rst", "reference/generated/torchrl.envs.IsaacGymEnv.rst", "reference/generated/torchrl.envs.IsaacGymWrapper.rst", "reference/generated/torchrl.envs.JumanjiEnv.rst", "reference/generated/torchrl.envs.JumanjiWrapper.rst", "reference/generated/torchrl.envs.MOGymEnv.rst", "reference/generated/torchrl.envs.MOGymWrapper.rst", "reference/generated/torchrl.envs.MarlGroupMapType.rst", "reference/generated/torchrl.envs.ModelBasedEnvBase.rst", "reference/generated/torchrl.envs.MultiThreadedEnv.rst", "reference/generated/torchrl.envs.MultiThreadedEnvWrapper.rst", "reference/generated/torchrl.envs.OpenMLEnv.rst", "reference/generated/torchrl.envs.ParallelEnv.rst", "reference/generated/torchrl.envs.PettingZooEnv.rst", "reference/generated/torchrl.envs.PettingZooWrapper.rst", "reference/generated/torchrl.envs.RoboHiveEnv.rst", "reference/generated/torchrl.envs.SMACv2Env.rst", "reference/generated/torchrl.envs.SMACv2Wrapper.rst", "reference/generated/torchrl.envs.SerialEnv.rst", "reference/generated/torchrl.envs.VmasEnv.rst", "reference/generated/torchrl.envs.VmasWrapper.rst", "reference/generated/torchrl.envs.check_marl_grouping.rst", "reference/generated/torchrl.envs.gym_backend.rst", "reference/generated/torchrl.envs.model_based.dreamer.DreamerEnv.rst", "reference/generated/torchrl.envs.set_gym_backend.rst", "reference/generated/torchrl.envs.transforms.ActionMask.rst", "reference/generated/torchrl.envs.transforms.BinarizeReward.rst", "reference/generated/torchrl.envs.transforms.BurnInTransform.rst", "reference/generated/torchrl.envs.transforms.CatFrames.rst", "reference/generated/torchrl.envs.transforms.CatTensors.rst", "reference/generated/torchrl.envs.transforms.CenterCrop.rst", "reference/generated/torchrl.envs.transforms.ClipTransform.rst", "reference/generated/torchrl.envs.transforms.Compose.rst", "reference/generated/torchrl.envs.transforms.DTypeCastTransform.rst", "reference/generated/torchrl.envs.transforms.DeviceCastTransform.rst", "reference/generated/torchrl.envs.transforms.DiscreteActionProjection.rst", "reference/generated/torchrl.envs.transforms.DoubleToFloat.rst", "reference/generated/torchrl.envs.transforms.EndOfLifeTransform.rst", "reference/generated/torchrl.envs.transforms.ExcludeTransform.rst", "reference/generated/torchrl.envs.transforms.FiniteTensorDictCheck.rst", "reference/generated/torchrl.envs.transforms.FlattenObservation.rst", "reference/generated/torchrl.envs.transforms.FrameSkipTransform.rst", "reference/generated/torchrl.envs.transforms.GrayScale.rst", "reference/generated/torchrl.envs.transforms.InitTracker.rst", "reference/generated/torchrl.envs.transforms.KLRewardTransform.rst", "reference/generated/torchrl.envs.transforms.NoopResetEnv.rst", "reference/generated/torchrl.envs.transforms.ObservationNorm.rst", "reference/generated/torchrl.envs.transforms.ObservationTransform.rst", "reference/generated/torchrl.envs.transforms.PermuteTransform.rst", "reference/generated/torchrl.envs.transforms.PinMemoryTransform.rst", "reference/generated/torchrl.envs.transforms.R3MTransform.rst", "reference/generated/torchrl.envs.transforms.RandomCropTensorDict.rst", "reference/generated/torchrl.envs.transforms.RemoveEmptySpecs.rst", "reference/generated/torchrl.envs.transforms.RenameTransform.rst", "reference/generated/torchrl.envs.transforms.Resize.rst", "reference/generated/torchrl.envs.transforms.Reward2GoTransform.rst", "reference/generated/torchrl.envs.transforms.RewardClipping.rst", "reference/generated/torchrl.envs.transforms.RewardScaling.rst", "reference/generated/torchrl.envs.transforms.RewardSum.rst", "reference/generated/torchrl.envs.transforms.SelectTransform.rst", "reference/generated/torchrl.envs.transforms.SignTransform.rst", "reference/generated/torchrl.envs.transforms.SqueezeTransform.rst", "reference/generated/torchrl.envs.transforms.StepCounter.rst", "reference/generated/torchrl.envs.transforms.TargetReturn.rst", "reference/generated/torchrl.envs.transforms.TensorDictPrimer.rst", "reference/generated/torchrl.envs.transforms.TimeMaxPool.rst", "reference/generated/torchrl.envs.transforms.ToTensorImage.rst", "reference/generated/torchrl.envs.transforms.Transform.rst", "reference/generated/torchrl.envs.transforms.TransformedEnv.rst", "reference/generated/torchrl.envs.transforms.UnsqueezeTransform.rst", "reference/generated/torchrl.envs.transforms.VC1Transform.rst", "reference/generated/torchrl.envs.transforms.VIPRewardTransform.rst", "reference/generated/torchrl.envs.transforms.VIPTransform.rst", "reference/generated/torchrl.envs.transforms.VecGymEnvTransform.rst", "reference/generated/torchrl.envs.transforms.VecNorm.rst", "reference/generated/torchrl.envs.transforms.gSDENoise.rst", "reference/generated/torchrl.envs.utils.check_env_specs.rst", "reference/generated/torchrl.envs.utils.exploration_mode.rst", "reference/generated/torchrl.envs.utils.exploration_type.rst", "reference/generated/torchrl.envs.utils.get_available_libraries.rst", "reference/generated/torchrl.envs.utils.make_composite_from_td.rst", "reference/generated/torchrl.envs.utils.set_exploration_mode.rst", "reference/generated/torchrl.envs.utils.set_exploration_type.rst", "reference/generated/torchrl.envs.utils.step_mdp.rst", "reference/generated/torchrl.envs.utils.terminated_or_truncated.rst", "reference/generated/torchrl.modules.CEMPlanner.rst", "reference/generated/torchrl.modules.Conv3dNet.rst", "reference/generated/torchrl.modules.ConvNet.rst", "reference/generated/torchrl.modules.DTActor.rst", "reference/generated/torchrl.modules.DdpgCnnActor.rst", "reference/generated/torchrl.modules.DdpgCnnQNet.rst", "reference/generated/torchrl.modules.DdpgMlpActor.rst", "reference/generated/torchrl.modules.DdpgMlpQNet.rst", "reference/generated/torchrl.modules.DecisionTransformer.rst", "reference/generated/torchrl.modules.Delta.rst", "reference/generated/torchrl.modules.DistributionalDQNnet.rst", "reference/generated/torchrl.modules.DistributionalQValueHook.rst", "reference/generated/torchrl.modules.DreamerActor.rst", "reference/generated/torchrl.modules.DuelingCnnDQNet.rst", "reference/generated/torchrl.modules.GRU.rst", "reference/generated/torchrl.modules.GRUCell.rst", "reference/generated/torchrl.modules.GRUModule.rst", "reference/generated/torchrl.modules.IndependentNormal.rst", "reference/generated/torchrl.modules.LSTM.rst", "reference/generated/torchrl.modules.LSTMCell.rst", "reference/generated/torchrl.modules.LSTMModule.rst", "reference/generated/torchrl.modules.LSTMNet.rst", "reference/generated/torchrl.modules.MLP.rst", "reference/generated/torchrl.modules.MPCPlannerBase.rst", "reference/generated/torchrl.modules.MPPIPlanner.rst", "reference/generated/torchrl.modules.MaskedCategorical.rst", "reference/generated/torchrl.modules.MaskedOneHotCategorical.rst", "reference/generated/torchrl.modules.MultiAgentConvNet.rst", "reference/generated/torchrl.modules.MultiAgentMLP.rst", "reference/generated/torchrl.modules.NoisyLazyLinear.rst", "reference/generated/torchrl.modules.NoisyLinear.rst", "reference/generated/torchrl.modules.NormalParamWrapper.rst", "reference/generated/torchrl.modules.ObsDecoder.rst", "reference/generated/torchrl.modules.ObsEncoder.rst", "reference/generated/torchrl.modules.OneHotCategorical.rst", "reference/generated/torchrl.modules.OnlineDTActor.rst", "reference/generated/torchrl.modules.QMixer.rst", "reference/generated/torchrl.modules.QValueHook.rst", "reference/generated/torchrl.modules.RSSMPosterior.rst", "reference/generated/torchrl.modules.RSSMPrior.rst", "reference/generated/torchrl.modules.Squeeze2dLayer.rst", "reference/generated/torchrl.modules.SqueezeLayer.rst", "reference/generated/torchrl.modules.TanhDelta.rst", "reference/generated/torchrl.modules.TanhNormal.rst", "reference/generated/torchrl.modules.TruncatedNormal.rst", "reference/generated/torchrl.modules.VDNMixer.rst", "reference/generated/torchrl.modules.VmapModule.rst", "reference/generated/torchrl.modules.reset_noise.rst", "reference/generated/torchrl.modules.tensordict_module.Actor.rst", "reference/generated/torchrl.modules.tensordict_module.ActorCriticOperator.rst", "reference/generated/torchrl.modules.tensordict_module.ActorCriticWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.ActorValueOperator.rst", "reference/generated/torchrl.modules.tensordict_module.AdditiveGaussianWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.DistributionalQValueActor.rst", "reference/generated/torchrl.modules.tensordict_module.DistributionalQValueModule.rst", "reference/generated/torchrl.modules.tensordict_module.EGreedyModule.rst", "reference/generated/torchrl.modules.tensordict_module.EGreedyWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.LMHeadActorValueOperator.rst", "reference/generated/torchrl.modules.tensordict_module.OrnsteinUhlenbeckProcessWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.ProbabilisticActor.rst", "reference/generated/torchrl.modules.tensordict_module.QValueActor.rst", "reference/generated/torchrl.modules.tensordict_module.QValueModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential.rst", "reference/generated/torchrl.modules.tensordict_module.SafeSequential.rst", "reference/generated/torchrl.modules.tensordict_module.TanhModule.rst", "reference/generated/torchrl.modules.tensordict_module.ValueOperator.rst", "reference/generated/torchrl.modules.tensordict_module.WorldModelWrapper.rst", "reference/generated/torchrl.modules.utils.biased_softplus.rst", "reference/generated/torchrl.modules.utils.inv_softplus.rst", "reference/generated/torchrl.modules.utils.mappings.rst", "reference/generated/torchrl.objectives.A2CLoss.rst", "reference/generated/torchrl.objectives.CQLLoss.rst", "reference/generated/torchrl.objectives.ClipPPOLoss.rst", "reference/generated/torchrl.objectives.DDPGLoss.rst", "reference/generated/torchrl.objectives.DQNLoss.rst", "reference/generated/torchrl.objectives.DTLoss.rst", "reference/generated/torchrl.objectives.DiscreteCQLLoss.rst", "reference/generated/torchrl.objectives.DiscreteIQLLoss.rst", "reference/generated/torchrl.objectives.DiscreteSACLoss.rst", "reference/generated/torchrl.objectives.DistributionalDQNLoss.rst", "reference/generated/torchrl.objectives.DreamerActorLoss.rst", "reference/generated/torchrl.objectives.DreamerModelLoss.rst", "reference/generated/torchrl.objectives.DreamerValueLoss.rst", "reference/generated/torchrl.objectives.HardUpdate.rst", "reference/generated/torchrl.objectives.IQLLoss.rst", "reference/generated/torchrl.objectives.KLPENPPOLoss.rst", "reference/generated/torchrl.objectives.LossModule.rst", "reference/generated/torchrl.objectives.OnlineDTLoss.rst", "reference/generated/torchrl.objectives.PPOLoss.rst", "reference/generated/torchrl.objectives.REDQLoss.rst", "reference/generated/torchrl.objectives.ReinforceLoss.rst", "reference/generated/torchrl.objectives.SACLoss.rst", "reference/generated/torchrl.objectives.SoftUpdate.rst", "reference/generated/torchrl.objectives.TD3Loss.rst", "reference/generated/torchrl.objectives.ValueEstimators.rst", "reference/generated/torchrl.objectives.default_value_kwargs.rst", "reference/generated/torchrl.objectives.distance_loss.rst", "reference/generated/torchrl.objectives.hold_out_net.rst", "reference/generated/torchrl.objectives.hold_out_params.rst", "reference/generated/torchrl.objectives.multiagent.QMixerLoss.rst", "reference/generated/torchrl.objectives.next_state_value.rst", "reference/generated/torchrl.objectives.value.GAE.rst", "reference/generated/torchrl.objectives.value.TD0Estimator.rst", "reference/generated/torchrl.objectives.value.TD1Estimator.rst", "reference/generated/torchrl.objectives.value.TDLambdaEstimator.rst", "reference/generated/torchrl.objectives.value.ValueEstimatorBase.rst", "reference/generated/torchrl.objectives.value.functional.generalized_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.reward2go.rst", "reference/generated/torchrl.objectives.value.functional.td0_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.td0_return_estimate.rst", "reference/generated/torchrl.objectives.value.functional.td1_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.td1_return_estimate.rst", "reference/generated/torchrl.objectives.value.functional.td_lambda_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.td_lambda_return_estimate.rst", "reference/generated/torchrl.objectives.value.functional.vec_generalized_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.vec_td1_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.vec_td1_return_estimate.rst", "reference/generated/torchrl.objectives.value.functional.vec_td_lambda_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.vec_td_lambda_return_estimate.rst", "reference/generated/torchrl.record.TensorDictRecorder.rst", "reference/generated/torchrl.record.VideoRecorder.rst", "reference/generated/torchrl.record.loggers.Logger.rst", "reference/generated/torchrl.record.loggers.csv.CSVLogger.rst", "reference/generated/torchrl.record.loggers.generate_exp_name.rst", "reference/generated/torchrl.record.loggers.get_logger.rst", "reference/generated/torchrl.record.loggers.mlflow.MLFlowLogger.rst", "reference/generated/torchrl.record.loggers.tensorboard.TensorboardLogger.rst", "reference/generated/torchrl.record.loggers.wandb.WandbLogger.rst", "reference/generated/torchrl.trainers.BatchSubSampler.rst", "reference/generated/torchrl.trainers.ClearCudaCache.rst", "reference/generated/torchrl.trainers.CountFramesLog.rst", "reference/generated/torchrl.trainers.LogReward.rst", "reference/generated/torchrl.trainers.OptimizerHook.rst", "reference/generated/torchrl.trainers.Recorder.rst", "reference/generated/torchrl.trainers.ReplayBufferTrainer.rst", "reference/generated/torchrl.trainers.RewardNormalizer.rst", "reference/generated/torchrl.trainers.SelectKeys.rst", "reference/generated/torchrl.trainers.Trainer.rst", "reference/generated/torchrl.trainers.TrainerHookBase.rst", "reference/generated/torchrl.trainers.UpdateWeights.rst", "reference/generated/torchrl.trainers.helpers.correct_for_frame_skip.rst", "reference/generated/torchrl.trainers.helpers.get_stats_random_rollout.rst", "reference/generated/torchrl.trainers.helpers.make_collector_offpolicy.rst", "reference/generated/torchrl.trainers.helpers.make_collector_onpolicy.rst", "reference/generated/torchrl.trainers.helpers.make_dqn_loss.rst", "reference/generated/torchrl.trainers.helpers.make_redq_loss.rst", "reference/generated/torchrl.trainers.helpers.make_redq_model.rst", "reference/generated/torchrl.trainers.helpers.make_replay_buffer.rst", "reference/generated/torchrl.trainers.helpers.make_target_updater.rst", "reference/generated/torchrl.trainers.helpers.make_trainer.rst", "reference/generated/torchrl.trainers.helpers.parallel_env_constructor.rst", "reference/generated/torchrl.trainers.helpers.sync_async_collector.rst", "reference/generated/torchrl.trainers.helpers.sync_sync_collector.rst", "reference/generated/torchrl.trainers.helpers.transformed_env_constructor.rst", "reference/generated/tutorials/README.rst", "reference/index.rst", "reference/knowledge_base.rst", "reference/modules.rst", "reference/objectives.rst", "reference/trainers.rst", "reference/utils.rst", "sg_execution_times.rst", "tutorials/coding_ddpg.rst", "tutorials/coding_dqn.rst", "tutorials/coding_ppo.rst", "tutorials/dqn_with_rnn.rst", "tutorials/index.rst", "tutorials/multi_task.rst", "tutorials/multiagent_ppo.rst", "tutorials/pendulum.rst", "tutorials/pretrained_models.rst", "tutorials/rb_tutorial.rst", "tutorials/sg_execution_times.rst", "tutorials/torchrl_demo.rst", "tutorials/torchrl_envs.rst"], "titles": ["TorchRL", "torchrl.collectors package", "torchrl.data package", "torchrl.envs package", "Things to consider when debugging RL", "Working with gym", "Working with <code class=\"docutils literal notranslate\"><span class=\"pre\">habitat-lab</span></code>", "Working with MuJoCo-based environments", "Common PyTorch errors and solutions", "Useful resources", "Versioning Issues", "implement_for", "DataCollectorBase", "MultiSyncDataCollector", "MultiaSyncDataCollector", "RandomPolicy", "SyncDataCollector", "aSyncDataCollector", "DistributedDataCollector", "DistributedSyncDataCollector", "RPCDataCollector", "RayCollector", "submitit_delayed_launcher", "split_trajectories", "BinaryDiscreteTensorSpec", "BoundedTensorSpec", "CompositeSpec", "DiscreteTensorSpec", "LazyStackedCompositeSpec", "LazyStackedTensorSpec", "MultiDiscreteTensorSpec", "MultiOneHotDiscreteTensorSpec", "MultiStep", "OneHotDiscreteTensorSpec", "PairwiseDataset", "PrioritizedReplayBuffer", "PromptData", "PromptTensorDictTokenizer", "ReplayBuffer", "RewardData", "RolloutFromModel", "TensorDictPrioritizedReplayBuffer", "TensorDictReplayBuffer", "TensorDictTokenizer", "TensorSpec", "TokenizedDatasetLoader", "UnboundedContinuousTensorSpec", "UnboundedDiscreteTensorSpec", "check_no_exclusive_keys", "consolidate_spec", "contains_lazy_spec", "create_infinite_iterator", "D4RLExperienceReplay", "GenDGRLExperienceReplay", "MinariExperienceReplay", "OpenMLExperienceReplay", "OpenXExperienceReplay", "RobosetExperienceReplay", "VD4RLExperienceReplay", "get_dataloader", "ImmutableDatasetWriter", "LazyMemmapStorage", "LazyTensorStorage", "ListStorage", "PrioritizedSampler", "RandomSampler", "ReplayBufferEnsemble", "RoundRobinWriter", "Sampler", "SamplerEnsemble", "SamplerWithoutReplacement", "SliceSampler", "SliceSamplerWithoutReplacement", "Storage", "StorageEnsemble", "TensorDictMaxValueWriter", "TensorDictRoundRobinWriter", "TensorStorage", "Writer", "WriterEnsemble", "BraxEnv", "BraxWrapper", "DMControlEnv", "DMControlWrapper", "EnvBase", "EnvCreator", "EnvMetaData", "GymEnv", "GymLikeEnv", "GymWrapper", "HabitatEnv", "IsaacGymEnv", "IsaacGymWrapper", "JumanjiEnv", "JumanjiWrapper", "MOGymEnv", "MOGymWrapper", "MarlGroupMapType", "ModelBasedEnvBase", "MultiThreadedEnv", "MultiThreadedEnvWrapper", "OpenMLEnv", "ParallelEnv", "PettingZooEnv", "PettingZooWrapper", "RoboHiveEnv", "SMACv2Env", "SMACv2Wrapper", "SerialEnv", "VmasEnv", "VmasWrapper", "check_marl_grouping", "gym_backend", "DreamerEnv", "set_gym_backend", "ActionMask", "BinarizeReward", "BurnInTransform", "CatFrames", "CatTensors", "CenterCrop", "ClipTransform", "Compose", "DTypeCastTransform", "DeviceCastTransform", "DiscreteActionProjection", "DoubleToFloat", "EndOfLifeTransform", "ExcludeTransform", "FiniteTensorDictCheck", "FlattenObservation", "FrameSkipTransform", "GrayScale", "InitTracker", "KLRewardTransform", "NoopResetEnv", "ObservationNorm", "ObservationTransform", "PermuteTransform", "PinMemoryTransform", "R3MTransform", "RandomCropTensorDict", "RemoveEmptySpecs", "RenameTransform", "Resize", "Reward2GoTransform", "RewardClipping", "RewardScaling", "RewardSum", "SelectTransform", "SignTransform", "SqueezeTransform", "StepCounter", "TargetReturn", "TensorDictPrimer", "TimeMaxPool", "ToTensorImage", "Transform", "TransformedEnv", "UnsqueezeTransform", "VC1Transform", "VIPRewardTransform", "VIPTransform", "VecGymEnvTransform", "VecNorm", "gSDENoise", "check_env_specs", "exploration_mode", "exploration_type", "get_available_libraries", "make_composite_from_td", "set_exploration_mode", "set_exploration_type", "step_mdp", "terminated_or_truncated", "CEMPlanner", "Conv3dNet", "ConvNet", "DTActor", "DdpgCnnActor", "DdpgCnnQNet", "DdpgMlpActor", "DdpgMlpQNet", "DecisionTransformer", "Delta", "DistributionalDQNnet", "DistributionalQValueHook", "DreamerActor", "DuelingCnnDQNet", "GRU", "GRUCell", "GRUModule", "IndependentNormal", "LSTM", "LSTMCell", "LSTMModule", "LSTMNet", "MLP", "MPCPlannerBase", "MPPIPlanner", "MaskedCategorical", "MaskedOneHotCategorical", "MultiAgentConvNet", "MultiAgentMLP", "NoisyLazyLinear", "NoisyLinear", "NormalParamWrapper", "ObsDecoder", "ObsEncoder", "OneHotCategorical", "OnlineDTActor", "QMixer", "QValueHook", "RSSMPosterior", "RSSMPrior", "Squeeze2dLayer", "SqueezeLayer", "TanhDelta", "TanhNormal", "TruncatedNormal", "VDNMixer", "VmapModule", "reset_noise", "Actor", "ActorCriticOperator", "ActorCriticWrapper", "ActorValueOperator", "AdditiveGaussianWrapper", "DecisionTransformerInferenceWrapper", "DistributionalQValueActor", "DistributionalQValueModule", "EGreedyModule", "EGreedyWrapper", "LMHeadActorValueOperator", "OrnsteinUhlenbeckProcessWrapper", "ProbabilisticActor", "QValueActor", "QValueModule", "SafeModule", "SafeProbabilisticModule", "SafeProbabilisticTensorDictSequential", "SafeSequential", "TanhModule", "ValueOperator", "WorldModelWrapper", "biased_softplus", "inv_softplus", "mappings", "A2CLoss", "CQLLoss", "ClipPPOLoss", "DDPGLoss", "DQNLoss", "DTLoss", "DiscreteCQLLoss", "DiscreteIQLLoss", "DiscreteSACLoss", "DistributionalDQNLoss", "DreamerActorLoss", "DreamerModelLoss", "DreamerValueLoss", "HardUpdate", "IQLLoss", "KLPENPPOLoss", "LossModule", "OnlineDTLoss", "PPOLoss", "REDQLoss", "ReinforceLoss", "SACLoss", "SoftUpdate", "TD3Loss", "ValueEstimators", "default_value_kwargs", "distance_loss", "hold_out_net", "hold_out_params", "QMixerLoss", "next_state_value", "GAE", "TD0Estimator", "TD1Estimator", "TDLambdaEstimator", "ValueEstimatorBase", "generalized_advantage_estimate", "reward2go", "td0_advantage_estimate", "td0_return_estimate", "td1_advantage_estimate", "td1_return_estimate", "td_lambda_advantage_estimate", "td_lambda_return_estimate", "vec_generalized_advantage_estimate", "vec_td1_advantage_estimate", "vec_td1_return_estimate", "vec_td_lambda_advantage_estimate", "vec_td_lambda_return_estimate", "TensorDictRecorder", "VideoRecorder", "Logger", "CSVLogger", "generate_exp_name", "get_logger", "MLFlowLogger", "TensorboardLogger", "WandbLogger", "BatchSubSampler", "ClearCudaCache", "CountFramesLog", "LogReward", "OptimizerHook", "Recorder", "ReplayBufferTrainer", "RewardNormalizer", "SelectKeys", "Trainer", "TrainerHookBase", "UpdateWeights", "correct_for_frame_skip", "get_stats_random_rollout", "make_collector_offpolicy", "make_collector_onpolicy", "make_dqn_loss", "make_redq_loss", "make_redq_model", "make_replay_buffer", "make_target_updater", "make_trainer", "parallel_env_constructor", "sync_async_collector", "sync_sync_collector", "transformed_env_constructor", "README Tutos", "API Reference", "Knowledge Base", "torchrl.modules package", "torchrl.objectives package", "torchrl.trainers package", "torchrl._utils package", "Computation times", "TorchRL objectives: Coding a DDPG loss", "TorchRL trainer: A DQN example", "Reinforcement Learning (PPO) with TorchRL Tutorial", "Recurrent DQN: Training recurrent policies", "README Tutos", "Task-specific policy in multi-task environments", "Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial", "Pendulum: Writing your environment and transforms with TorchRL", "Using pretrained models", "Using Replay Buffers", "Computation times", "Introduction to TorchRL", "TorchRL envs"], "terms": {"an": [0, 1, 2, 3, 5, 8, 9, 10, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 66, 67, 69, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 87, 88, 89, 90, 98, 99, 101, 102, 103, 104, 105, 108, 111, 115, 117, 118, 120, 123, 125, 126, 129, 135, 136, 140, 141, 142, 143, 145, 153, 154, 155, 156, 157, 158, 160, 163, 164, 166, 176, 177, 179, 180, 181, 182, 189, 191, 193, 195, 196, 197, 198, 202, 203, 204, 208, 215, 216, 224, 225, 226, 227, 228, 229, 230, 231, 233, 234, 235, 236, 239, 240, 244, 247, 248, 249, 250, 252, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 283, 298, 301, 310, 311, 315, 316, 319, 328, 329, 330, 331, 334, 335, 336, 340, 341, 345, 346, 348, 349, 351, 352], "open": [0, 5, 7, 11, 56, 341, 346, 351], "sourc": [0, 1, 4, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 169, 170, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 351, 352], "reinforc": [0, 3, 9, 53, 118, 179, 180, 181, 182, 186, 230, 234, 248, 249, 253, 254, 255, 257, 261, 262, 268, 269, 270, 333, 339, 341, 344, 347, 350, 351], "learn": [0, 3, 7, 8, 9, 18, 32, 53, 55, 57, 58, 101, 118, 179, 180, 181, 182, 186, 199, 205, 230, 234, 248, 249, 253, 254, 255, 257, 261, 262, 267, 268, 269, 270, 333, 335, 336, 339, 340, 341, 343, 344, 345, 347, 349, 350, 351, 352], "rl": [0, 1, 2, 3, 5, 8, 10, 13, 14, 16, 17, 98, 153, 205, 223, 235, 243, 248, 264, 266, 306, 334, 335, 336, 337, 340, 341, 342, 346, 348, 349, 352], "librari": [0, 1, 2, 5, 6, 7, 8, 9, 10, 18, 19, 20, 37, 43, 82, 83, 92, 99, 169, 333, 334, 335, 338, 340, 341, 342, 346, 347, 352], "pytorch": [0, 1, 2, 3, 54, 109, 110, 156, 189, 193, 204, 205, 315, 334, 337, 340, 342, 343, 346, 347, 348, 351, 352], "It": [0, 2, 3, 4, 7, 32, 37, 40, 41, 43, 45, 52, 54, 56, 57, 58, 66, 69, 79, 84, 88, 90, 98, 99, 102, 103, 104, 108, 109, 110, 117, 127, 134, 136, 141, 153, 158, 163, 166, 179, 181, 187, 202, 203, 211, 213, 214, 220, 221, 230, 231, 234, 237, 239, 248, 249, 250, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 270, 271, 277, 278, 279, 311, 324, 334, 335, 336, 340, 341, 343, 346, 347, 348, 349, 351, 352], "provid": [0, 1, 2, 3, 5, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 30, 31, 32, 33, 35, 38, 41, 42, 45, 49, 52, 53, 54, 55, 56, 57, 58, 59, 61, 65, 66, 69, 71, 72, 80, 81, 82, 83, 84, 87, 88, 89, 90, 93, 94, 98, 99, 100, 102, 103, 104, 105, 108, 117, 118, 119, 120, 121, 123, 126, 130, 135, 136, 138, 140, 141, 144, 145, 148, 149, 153, 154, 155, 158, 160, 162, 163, 164, 174, 176, 177, 183, 186, 189, 190, 191, 193, 194, 195, 196, 197, 198, 200, 201, 202, 203, 221, 223, 227, 230, 231, 232, 234, 235, 236, 237, 242, 248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 278, 279, 280, 281, 282, 283, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 298, 302, 306, 312, 319, 324, 327, 334, 335, 336, 337, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "python": [0, 3, 5, 6, 7, 10, 21, 100, 114, 189, 190, 191, 193, 194, 195, 200, 201, 337, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 351, 352], "first": [0, 1, 3, 4, 5, 7, 8, 18, 20, 21, 26, 28, 52, 53, 54, 56, 57, 58, 61, 62, 71, 72, 77, 84, 88, 102, 108, 118, 119, 130, 136, 140, 141, 156, 158, 160, 189, 191, 193, 195, 197, 202, 203, 204, 208, 223, 228, 229, 230, 235, 236, 238, 239, 250, 259, 263, 264, 266, 297, 314, 335, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "low": [0, 25, 84, 88, 102, 108, 121, 125, 170, 230, 235, 242, 340, 341, 342, 346, 347, 351, 352], "high": [0, 9, 25, 41, 84, 88, 102, 108, 121, 125, 135, 170, 230, 235, 242, 279, 284, 292, 340, 341, 342, 346, 347, 349, 351, 352], "level": [0, 3, 4, 22, 26, 28, 118, 152, 263, 340, 341, 351], "abstract": [0, 3, 8, 24, 25, 26, 27, 28, 29, 30, 44, 46, 47, 78, 84, 137, 198, 283, 307, 316, 337, 342, 347, 351], "ar": [0, 1, 2, 3, 7, 8, 9, 10, 13, 14, 16, 17, 18, 19, 20, 21, 23, 28, 29, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 48, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 66, 69, 70, 72, 73, 74, 77, 84, 85, 87, 88, 89, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 117, 118, 121, 122, 123, 125, 126, 127, 129, 130, 134, 135, 138, 140, 145, 148, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 170, 174, 175, 182, 184, 189, 190, 191, 193, 194, 195, 196, 198, 200, 201, 202, 205, 209, 211, 214, 228, 229, 231, 234, 235, 236, 238, 239, 240, 241, 242, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 274, 277, 278, 279, 280, 281, 282, 283, 312, 327, 331, 335, 336, 337, 338, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "intend": [0, 7, 13, 14, 16, 17, 18, 19, 20, 21, 45, 117, 125, 221, 264, 335, 351], "effici": [0, 1, 2, 4, 8, 189, 205, 335, 340, 341, 342, 343, 345, 346, 348, 349, 351], "modular": [0, 241, 349, 351], "document": [0, 5, 7, 18, 19, 21, 32, 56, 84, 88, 102, 108, 158, 341, 343, 351], "properli": [0, 84, 88, 102, 108, 342, 346, 347, 351], "test": [0, 3, 5, 80, 81, 93, 94, 160, 166, 191, 195, 196, 311, 327, 342, 343, 351], "The": [0, 1, 2, 3, 4, 5, 7, 8, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 66, 69, 71, 72, 73, 75, 80, 81, 82, 83, 84, 87, 88, 89, 90, 92, 93, 94, 99, 100, 102, 103, 104, 105, 108, 109, 110, 117, 118, 122, 123, 126, 127, 128, 136, 138, 140, 145, 147, 148, 149, 152, 153, 154, 157, 158, 160, 162, 163, 173, 174, 175, 179, 180, 181, 182, 183, 186, 189, 190, 191, 193, 194, 195, 196, 198, 199, 200, 201, 202, 205, 206, 212, 213, 214, 223, 224, 228, 229, 230, 234, 235, 236, 237, 238, 239, 241, 243, 244, 245, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 278, 279, 280, 281, 282, 283, 285, 300, 303, 304, 305, 306, 310, 327, 329, 330, 335, 336, 337, 341, 342, 343, 346, 347, 348, 349, 351, 352], "code": [0, 3, 5, 7, 8, 56, 84, 88, 102, 108, 140, 158, 160, 189, 190, 191, 193, 194, 195, 241, 339, 341, 342, 343, 344, 345, 346, 348, 349, 350, 351, 352], "aim": [0, 3, 7, 28, 29, 140, 160, 162, 197, 318, 334, 335, 336, 340, 341, 351], "support": [0, 1, 3, 18, 20, 26, 55, 58, 59, 61, 62, 73, 74, 77, 79, 80, 81, 89, 93, 94, 99, 101, 103, 105, 118, 127, 136, 154, 155, 157, 169, 186, 221, 229, 230, 235, 238, 241, 257, 279, 280, 281, 282, 303, 335, 337, 342, 343, 346, 347, 349, 351], "research": [0, 7, 9, 351], "most": [0, 3, 7, 8, 32, 71, 72, 84, 88, 102, 108, 125, 163, 340, 342, 347, 351, 352], "written": [0, 3, 11, 34, 36, 39, 45, 52, 53, 56, 61, 66, 71, 72, 82, 83, 84, 87, 88, 89, 90, 102, 105, 108, 118, 127, 134, 148, 152, 155, 163, 173, 174, 223, 234, 235, 238, 239, 243, 248, 250, 263, 266, 268, 278, 297, 298, 335, 336, 337, 340, 343, 345, 347, 351], "highli": [0, 2, 351, 352], "wai": [0, 2, 3, 4, 54, 66, 92, 140, 143, 162, 163, 193, 266, 279, 280, 281, 282, 335, 340, 341, 342, 345, 346, 347, 348, 349, 351, 352], "can": [0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 52, 53, 54, 56, 57, 58, 64, 66, 70, 71, 72, 75, 80, 81, 82, 83, 84, 85, 87, 88, 92, 93, 94, 97, 102, 103, 104, 106, 107, 108, 109, 110, 114, 115, 117, 118, 121, 122, 123, 125, 126, 127, 135, 136, 140, 141, 145, 148, 152, 153, 154, 157, 158, 160, 162, 164, 174, 175, 189, 191, 192, 193, 195, 198, 199, 202, 203, 205, 206, 219, 221, 223, 227, 229, 230, 231, 232, 235, 236, 237, 238, 239, 240, 241, 242, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 278, 279, 280, 281, 282, 283, 311, 324, 329, 330, 331, 334, 335, 336, 337, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "easili": [0, 3, 7, 84, 88, 102, 108, 324, 336, 340, 341, 342, 346, 351, 352], "swap": [0, 3, 87, 163, 342, 348, 351], "compon": [0, 2, 3, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 66, 73, 74, 77, 186, 212, 229, 230, 237, 248, 249, 250, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 310, 315, 340, 341, 342, 343, 345, 346, 347, 348, 351], "transform": [0, 1, 2, 4, 8, 13, 14, 16, 18, 19, 20, 21, 32, 35, 37, 38, 40, 41, 42, 43, 52, 53, 54, 55, 56, 57, 58, 66, 74, 84, 85, 88, 102, 103, 104, 108, 109, 110, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 178, 179, 183, 186, 187, 210, 211, 212, 220, 228, 233, 242, 245, 247, 253, 265, 298, 312, 324, 331, 333, 339, 341, 343, 344, 348, 350], "them": [0, 2, 3, 7, 9, 21, 32, 35, 37, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 79, 84, 85, 88, 92, 97, 102, 103, 104, 108, 109, 110, 123, 126, 158, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 220, 221, 227, 228, 230, 231, 232, 234, 237, 242, 245, 263, 269, 298, 340, 341, 343, 345, 346, 347, 348, 349, 351, 352], "write": [0, 3, 8, 23, 32, 34, 36, 37, 39, 45, 66, 74, 79, 88, 121, 138, 139, 148, 150, 152, 156, 174, 223, 238, 239, 241, 243, 251, 252, 254, 255, 256, 262, 267, 269, 271, 278, 283, 298, 335, 337, 339, 340, 341, 342, 343, 344, 345, 346, 348, 349, 350, 351, 352], "new": [0, 2, 3, 4, 8, 13, 14, 16, 17, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 44, 46, 47, 64, 70, 84, 88, 99, 102, 106, 107, 108, 148, 157, 164, 173, 174, 189, 191, 195, 234, 238, 239, 244, 248, 249, 250, 252, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 340, 342, 343, 346, 347, 351, 352], "ones": [0, 2, 15, 26, 32, 35, 41, 42, 84, 88, 102, 108, 119, 122, 123, 124, 126, 136, 140, 145, 154, 157, 158, 160, 162, 200, 201, 221, 238, 248, 249, 251, 262, 266, 267, 269, 271, 285, 340, 342, 346, 347, 349, 351, 352], "littl": [0, 3, 43, 342, 343, 349, 351, 352], "effort": [0, 3, 347, 349, 351], "thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 66, 69, 70, 71, 72, 73, 74, 75, 77, 79, 80, 81, 84, 87, 88, 89, 90, 93, 94, 97, 98, 101, 102, 103, 104, 108, 109, 110, 114, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 133, 134, 136, 140, 141, 142, 143, 145, 148, 149, 150, 152, 154, 155, 157, 158, 160, 161, 162, 163, 164, 166, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 202, 203, 204, 205, 206, 207, 208, 209, 210, 212, 213, 214, 216, 219, 221, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 244, 245, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 266, 267, 268, 269, 270, 271, 277, 279, 280, 281, 282, 283, 297, 306, 308, 311, 312, 315, 317, 318, 319, 324, 327, 331, 334, 335, 336, 337, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "repo": [0, 6, 52, 118, 155, 160, 334, 346, 351], "attempt": [0, 71, 72, 82, 83, 87, 89, 90, 105, 227, 232, 234, 252, 255, 262, 277, 351], "align": [0, 189, 193, 351], "exist": [0, 3, 4, 11, 18, 21, 32, 34, 36, 39, 45, 84, 88, 102, 108, 119, 124, 158, 269, 319, 331, 346, 351, 352], "ecosystem": [0, 351], "ha": [0, 2, 3, 4, 5, 7, 8, 10, 16, 17, 18, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 37, 40, 44, 46, 47, 56, 66, 69, 71, 75, 84, 85, 88, 92, 102, 108, 109, 110, 118, 152, 153, 154, 155, 158, 189, 191, 193, 195, 202, 227, 230, 232, 234, 239, 263, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "dataset": [0, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 52, 53, 54, 55, 56, 57, 58, 59, 60, 66, 69, 71, 72, 101, 164, 333, 340, 341, 348, 349, 351, 352], "pillar": [0, 351], "environ": [0, 1, 2, 5, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 115, 117, 118, 119, 123, 124, 125, 126, 131, 135, 136, 140, 141, 142, 148, 152, 153, 154, 155, 157, 158, 160, 163, 164, 166, 175, 191, 195, 196, 198, 199, 227, 234, 254, 258, 279, 280, 281, 282, 283, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 298, 306, 308, 311, 318, 319, 320, 321, 324, 327, 328, 329, 330, 331, 333, 334, 335, 339, 344, 348, 349, 350], "model": [0, 1, 3, 8, 9, 13, 14, 16, 17, 18, 19, 20, 21, 32, 40, 45, 84, 88, 98, 102, 108, 123, 140, 154, 160, 162, 165, 176, 177, 178, 183, 191, 195, 197, 198, 199, 203, 210, 211, 220, 224, 225, 226, 233, 238, 244, 248, 249, 250, 252, 253, 254, 255, 258, 259, 260, 262, 263, 264, 266, 267, 269, 277, 315, 320, 321, 322, 323, 324, 333, 334, 337, 339, 342, 344, 346, 347, 349, 350, 352], "data": [0, 3, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 93, 94, 98, 99, 100, 101, 102, 103, 104, 105, 108, 115, 117, 118, 123, 124, 126, 128, 134, 136, 142, 145, 152, 163, 166, 170, 174, 175, 186, 191, 195, 196, 199, 202, 203, 212, 221, 223, 229, 231, 232, 234, 235, 236, 238, 241, 242, 243, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 283, 306, 312, 315, 317, 320, 327, 329, 330, 331, 333, 335, 336, 337, 343, 347, 348, 349, 352], "util": [0, 3, 17, 23, 32, 40, 81, 84, 88, 93, 94, 102, 103, 104, 108, 111, 140, 162, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 183, 189, 193, 245, 246, 247, 264, 327, 333, 338, 340, 342, 346, 347, 351, 352], "e": [0, 1, 3, 7, 8, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 26, 28, 32, 33, 61, 62, 77, 84, 85, 88, 102, 108, 109, 117, 119, 122, 130, 136, 140, 148, 154, 157, 158, 160, 162, 166, 189, 191, 192, 193, 195, 199, 203, 206, 212, 218, 219, 228, 230, 235, 237, 238, 239, 269, 278, 279, 280, 281, 282, 306, 318, 330, 335, 340, 341, 342, 346, 348, 351, 352], "g": [0, 1, 3, 7, 8, 10, 11, 32, 33, 84, 85, 88, 102, 108, 109, 117, 119, 122, 130, 136, 140, 148, 154, 157, 158, 160, 162, 166, 189, 191, 192, 193, 194, 195, 199, 203, 218, 219, 228, 235, 238, 239, 269, 278, 288, 289, 290, 291, 293, 294, 295, 296, 330, 335, 340, 341, 342, 346, 347, 348, 351, 352], "collector": [0, 3, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 40, 56, 71, 72, 118, 145, 152, 234, 312, 315, 317, 320, 321, 327, 329, 330, 333, 337, 349, 352], "contain": [0, 3, 7, 12, 13, 14, 16, 17, 19, 20, 26, 28, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 50, 52, 53, 54, 55, 56, 57, 58, 60, 64, 66, 67, 69, 73, 76, 78, 79, 84, 88, 98, 102, 108, 122, 123, 126, 140, 154, 157, 158, 160, 162, 163, 164, 173, 174, 175, 176, 177, 189, 190, 193, 194, 197, 199, 203, 223, 229, 230, 235, 237, 238, 243, 248, 249, 250, 251, 252, 254, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 278, 279, 280, 281, 282, 283, 285, 302, 306, 318, 324, 327, 328, 329, 330, 331, 335, 336, 337, 340, 341, 342, 343, 346, 347, 348, 349, 351, 352], "etc": [0, 3, 7, 8, 11, 32, 46, 47, 56, 84, 88, 102, 108, 134, 158, 197, 203, 340, 341, 342, 349, 351, 352], "have": [0, 1, 2, 3, 5, 6, 7, 8, 9, 13, 14, 17, 18, 20, 21, 26, 30, 32, 34, 35, 36, 38, 39, 40, 41, 42, 45, 52, 53, 54, 55, 56, 57, 58, 66, 70, 73, 84, 88, 102, 103, 104, 108, 118, 123, 126, 127, 134, 135, 136, 152, 157, 158, 164, 166, 174, 176, 177, 196, 197, 202, 203, 221, 240, 241, 248, 250, 263, 266, 274, 277, 279, 280, 281, 282, 283, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 306, 315, 335, 336, 337, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "few": [0, 2, 8, 88, 306, 342, 343, 346, 349, 351, 352], "depend": [0, 1, 2, 3, 4, 7, 8, 34, 36, 87, 89, 90, 105, 109, 110, 123, 126, 243, 266, 335, 340, 342, 343, 346, 347, 351, 352], "possibl": [0, 2, 3, 4, 27, 29, 32, 33, 34, 36, 39, 53, 56, 58, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 176, 177, 189, 190, 193, 194, 238, 311, 315, 335, 340, 342, 343, 346, 347, 349, 351, 352], "standard": [0, 3, 136, 147, 164, 175, 187, 199, 204, 205, 227, 228, 271, 279, 280, 281, 282, 340, 341, 346, 349, 351], "numpi": [0, 11, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 84, 88, 102, 108, 156, 315, 347, 349, 351, 352], "common": [0, 2, 3, 4, 21, 88, 93, 115, 224, 225, 226, 233, 248, 249, 250, 255, 256, 262, 263, 266, 267, 268, 269, 271, 327, 334, 335, 337, 340, 342, 345, 346, 347, 348, 351, 352], "openai": [0, 7, 87, 89, 105, 342, 347, 351, 352], "gym": [0, 1, 3, 4, 8, 11, 13, 14, 16, 17, 21, 22, 84, 85, 87, 88, 89, 90, 92, 99, 100, 102, 105, 108, 109, 110, 112, 114, 118, 121, 127, 133, 134, 136, 138, 143, 145, 148, 154, 157, 163, 164, 324, 327, 334, 340, 341, 342, 343, 347, 348, 349, 351], "onli": [0, 1, 3, 4, 7, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 38, 41, 44, 46, 47, 52, 61, 62, 71, 72, 77, 82, 83, 84, 87, 88, 89, 90, 92, 99, 100, 102, 103, 104, 105, 108, 118, 119, 121, 122, 123, 125, 126, 130, 136, 140, 141, 145, 152, 153, 154, 155, 157, 158, 160, 162, 164, 193, 195, 196, 202, 203, 223, 228, 229, 235, 236, 238, 239, 240, 241, 248, 250, 251, 255, 256, 262, 263, 264, 266, 267, 268, 269, 270, 271, 279, 280, 281, 282, 283, 319, 337, 340, 341, 342, 343, 345, 346, 347, 349, 351, 352], "option": [0, 1, 3, 4, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 64, 65, 66, 69, 70, 71, 72, 74, 77, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 98, 99, 100, 101, 102, 103, 104, 105, 108, 109, 110, 115, 116, 117, 118, 119, 120, 121, 123, 125, 126, 127, 130, 131, 133, 134, 135, 136, 140, 141, 143, 144, 145, 147, 148, 149, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 166, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 188, 190, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 212, 213, 214, 217, 218, 219, 221, 223, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 277, 278, 279, 280, 281, 282, 283, 285, 288, 289, 290, 291, 293, 294, 295, 296, 297, 298, 300, 303, 306, 308, 309, 310, 311, 312, 313, 315, 319, 320, 321, 322, 323, 324, 326, 327, 329, 330, 331, 335, 343, 346, 347, 349, 351], "On": [0, 3, 7, 18, 19, 20, 21, 53, 190, 194, 335, 341, 346], "end": [0, 3, 13, 14, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 70, 71, 72, 84, 88, 102, 108, 127, 138, 152, 153, 158, 176, 177, 189, 190, 193, 194, 198, 269, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "come": [0, 1, 3, 8, 88, 97, 102, 108, 123, 126, 223, 224, 225, 226, 235, 243, 340, 341, 342, 343, 346, 349, 351, 352], "set": [0, 1, 2, 3, 7, 9, 11, 13, 14, 16, 17, 18, 19, 20, 21, 28, 29, 32, 33, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 57, 58, 61, 62, 66, 70, 73, 77, 84, 86, 88, 98, 102, 103, 104, 108, 109, 110, 114, 115, 118, 119, 122, 123, 126, 133, 134, 140, 145, 152, 153, 154, 155, 157, 158, 160, 162, 164, 166, 171, 172, 174, 189, 191, 193, 195, 198, 202, 203, 227, 228, 238, 256, 264, 266, 269, 283, 306, 311, 312, 321, 331, 334, 335, 336, 338, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "re": [0, 3, 8, 32, 70, 84, 88, 102, 108, 195, 200, 201, 235, 239, 337, 340, 342, 343, 345, 347, 351, 352], "usabl": [0, 337, 343, 351], "function": [0, 3, 8, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 43, 44, 45, 46, 47, 49, 61, 62, 63, 66, 73, 74, 77, 84, 85, 88, 102, 108, 114, 123, 126, 158, 164, 166, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 200, 201, 202, 203, 206, 207, 208, 209, 210, 213, 214, 216, 219, 221, 224, 225, 226, 227, 228, 230, 231, 232, 234, 235, 237, 238, 239, 241, 242, 243, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 262, 263, 264, 266, 267, 268, 269, 271, 272, 273, 274, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 324, 327, 333, 335, 340, 343, 345, 347, 349, 352], "cost": [0, 2, 27, 56, 340, 341, 346, 347, 349], "return": [0, 2, 3, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 66, 67, 69, 71, 72, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 98, 99, 100, 101, 102, 103, 104, 105, 108, 109, 110, 112, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 132, 133, 134, 136, 138, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 167, 168, 169, 173, 174, 175, 178, 179, 180, 181, 182, 184, 186, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 206, 209, 210, 211, 213, 214, 217, 218, 219, 220, 223, 224, 225, 226, 228, 235, 237, 238, 239, 243, 244, 245, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 274, 277, 278, 279, 280, 281, 282, 283, 285, 286, 287, 288, 289, 290, 291, 293, 294, 295, 296, 302, 315, 318, 320, 324, 327, 328, 329, 330, 331, 333, 335, 337, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "process": [0, 1, 3, 4, 5, 8, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 35, 36, 39, 43, 45, 53, 57, 58, 84, 85, 88, 92, 97, 99, 102, 103, 104, 108, 117, 123, 126, 156, 164, 202, 203, 230, 234, 237, 333, 337, 340, 341, 343, 346, 347, 348, 349, 351, 352], "good": [0, 1, 4, 9, 102, 340, 342, 343, 346, 351, 352], "runtim": [0, 3, 32, 84, 88, 102, 108, 347], "perform": [0, 3, 4, 8, 13, 14, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 44, 45, 46, 47, 82, 83, 84, 87, 88, 89, 90, 102, 105, 108, 111, 123, 126, 135, 158, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 242, 245, 259, 266, 269, 311, 315, 336, 340, 341, 342, 343, 345, 346, 347, 352], "To": [0, 2, 3, 4, 6, 7, 8, 9, 18, 19, 20, 32, 35, 38, 40, 41, 42, 52, 53, 54, 55, 56, 57, 58, 71, 72, 74, 79, 80, 81, 84, 87, 88, 89, 93, 94, 97, 102, 103, 104, 105, 106, 107, 108, 109, 152, 164, 224, 225, 226, 234, 256, 264, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 335, 336, 340, 341, 342, 343, 346, 347, 348, 349, 351, 352], "read": [0, 2, 3, 7, 17, 23, 37, 40, 56, 61, 62, 63, 66, 73, 74, 77, 84, 87, 88, 89, 102, 108, 115, 117, 118, 119, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131, 133, 134, 138, 139, 141, 142, 143, 145, 148, 149, 150, 152, 153, 154, 155, 157, 160, 161, 163, 164, 174, 209, 223, 224, 225, 226, 229, 235, 238, 239, 241, 243, 244, 248, 249, 250, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 283, 298, 311, 315, 324, 335, 340, 341, 342, 345, 346, 347, 348, 352], "more": [0, 2, 3, 4, 6, 8, 9, 11, 13, 14, 16, 17, 18, 19, 20, 21, 32, 35, 38, 41, 42, 43, 52, 53, 54, 55, 56, 57, 58, 66, 75, 84, 88, 91, 92, 102, 103, 104, 105, 108, 109, 110, 156, 160, 165, 186, 193, 197, 204, 206, 223, 227, 229, 230, 238, 243, 248, 257, 264, 266, 279, 284, 292, 310, 334, 336, 337, 340, 341, 342, 343, 345, 346, 347, 348, 352], "about": [0, 2, 3, 5, 7, 9, 18, 19, 20, 43, 57, 58, 336, 340, 341, 342, 346, 347, 351, 352], "philosophi": [0, 9], "capabl": [0, 1, 7, 9, 337, 340, 345, 348, 352], "beyond": 0, "api": [0, 2, 3, 5, 103, 104, 105, 140, 162, 336, 337, 346, 347, 351, 352], "check": [0, 2, 3, 4, 5, 6, 7, 9, 11, 18, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 48, 50, 71, 84, 85, 88, 98, 102, 108, 111, 118, 119, 129, 134, 141, 156, 166, 191, 195, 223, 229, 230, 235, 236, 237, 238, 239, 335, 336, 341, 342, 343, 345, 346, 347, 348, 349, 352], "paper": [0, 53, 56, 80, 81, 82, 83, 90, 93, 94, 99, 100, 105, 109, 110, 140, 160, 162, 189, 211, 220, 254, 261, 324, 340, 342, 346], "ppo": [0, 4, 8, 235, 239, 250, 263, 266, 333, 335, 339, 340, 341, 344, 350], "pendulum": [0, 3, 13, 14, 16, 17, 21, 22, 82, 83, 84, 85, 87, 88, 89, 99, 102, 108, 118, 121, 122, 128, 133, 134, 136, 143, 145, 150, 152, 154, 155, 157, 158, 164, 191, 195, 327, 335, 339, 341, 342, 344, 350, 351, 352], "your": [0, 2, 3, 7, 8, 10, 18, 32, 84, 88, 92, 97, 102, 103, 104, 108, 164, 331, 334, 335, 336, 339, 341, 342, 343, 344, 346, 349, 350, 351], "introduct": [0, 336, 339, 344, 346, 350, 352], "multi": [0, 7, 9, 28, 29, 32, 84, 88, 102, 106, 107, 108, 189, 191, 193, 195, 196, 197, 202, 203, 277, 279, 280, 281, 282, 333, 339, 340, 341, 342, 343, 344, 347, 350, 351], "agent": [0, 9, 28, 29, 97, 103, 104, 106, 107, 109, 110, 111, 152, 153, 200, 201, 202, 203, 205, 211, 220, 277, 333, 339, 344, 347, 350], "env": [0, 1, 2, 5, 6, 7, 8, 13, 14, 16, 17, 18, 19, 20, 21, 22, 32, 40, 52, 54, 56, 57, 58, 66, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 191, 195, 198, 199, 238, 264, 297, 319, 320, 321, 324, 327, 329, 330, 331, 333, 335, 339, 340, 341, 342, 343, 344, 345, 346, 348, 349, 350], "us": [0, 1, 2, 3, 5, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 64, 65, 66, 71, 72, 75, 77, 80, 81, 84, 85, 87, 88, 89, 90, 93, 94, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 114, 115, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 133, 134, 136, 140, 141, 142, 143, 145, 148, 149, 152, 153, 154, 155, 156, 157, 158, 160, 162, 164, 166, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 186, 187, 189, 190, 191, 192, 193, 194, 195, 197, 198, 199, 201, 202, 203, 205, 206, 209, 210, 211, 212, 218, 219, 220, 221, 223, 228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 242, 243, 244, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 274, 277, 278, 279, 280, 281, 282, 283, 284, 285, 287, 292, 301, 302, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 319, 320, 321, 325, 327, 331, 334, 335, 336, 337, 338, 339, 340, 341, 342, 344, 345, 346, 347, 350, 352], "pretrain": [0, 339, 344, 350], "recurr": [0, 117, 189, 190, 191, 193, 195, 214, 339, 341, 344, 349, 350], "dqn": [0, 127, 186, 229, 230, 248, 249, 251, 252, 254, 256, 257, 258, 261, 262, 264, 266, 267, 268, 269, 270, 271, 277, 322, 333, 335, 339, 344, 350], "train": [0, 1, 3, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 32, 34, 36, 39, 40, 45, 53, 59, 84, 88, 102, 103, 104, 108, 123, 131, 140, 153, 158, 160, 162, 166, 179, 181, 191, 195, 227, 231, 232, 234, 248, 249, 250, 251, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 279, 315, 317, 327, 333, 337, 339, 341, 344, 348, 349, 350, 352], "polici": [0, 1, 2, 3, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 80, 81, 84, 88, 98, 102, 108, 125, 134, 153, 171, 172, 186, 191, 195, 202, 203, 205, 212, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 242, 248, 249, 250, 251, 255, 256, 262, 263, 265, 266, 267, 268, 269, 271, 311, 317, 320, 321, 327, 329, 330, 335, 336, 337, 339, 341, 344, 348, 349, 350, 351, 352], "replai": [0, 8, 13, 14, 16, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 76, 79, 117, 118, 125, 141, 145, 154, 251, 252, 254, 255, 256, 262, 267, 269, 271, 312, 315, 325, 327, 333, 337, 339, 344, 347, 348, 350], "buffer": [0, 1, 3, 4, 8, 13, 14, 16, 32, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 79, 84, 88, 98, 102, 108, 117, 118, 122, 125, 140, 141, 145, 154, 157, 158, 160, 162, 238, 241, 251, 252, 254, 255, 256, 262, 267, 269, 271, 312, 315, 325, 327, 333, 337, 339, 344, 347, 348, 350, 352], "task": [0, 2, 3, 9, 28, 29, 40, 45, 53, 56, 82, 83, 84, 88, 91, 102, 103, 104, 105, 108, 109, 110, 140, 152, 160, 162, 255, 262, 339, 340, 341, 342, 343, 344, 346, 347, 350, 351, 352], "specif": [0, 2, 5, 8, 41, 42, 88, 109, 183, 228, 315, 333, 336, 337, 339, 342, 343, 344, 346, 349, 350], "object": [0, 3, 4, 6, 13, 14, 15, 16, 17, 18, 19, 20, 21, 26, 28, 32, 34, 36, 39, 45, 61, 62, 63, 66, 69, 73, 74, 77, 79, 84, 88, 93, 102, 108, 123, 126, 127, 136, 140, 157, 158, 160, 164, 199, 211, 220, 223, 224, 235, 238, 239, 240, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 298, 319, 320, 321, 326, 327, 331, 333, 335, 337, 339, 341, 342, 343, 344, 346, 347, 349, 350, 352], "ddpg": [0, 179, 180, 181, 182, 251, 261, 270, 333, 335, 339, 341, 344, 350], "loss": [0, 3, 8, 36, 127, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 274, 277, 278, 279, 310, 315, 322, 323, 324, 327, 336, 337, 339, 344, 347, 349, 350, 351], "trainer": [0, 248, 249, 250, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 333, 339, 340, 344, 350], "A": [0, 1, 2, 3, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 70, 73, 75, 76, 77, 78, 84, 86, 88, 90, 91, 102, 105, 108, 117, 121, 125, 131, 134, 140, 141, 143, 150, 154, 157, 158, 160, 161, 163, 164, 165, 166, 173, 175, 176, 177, 186, 189, 190, 191, 193, 194, 195, 197, 199, 200, 201, 203, 205, 206, 221, 227, 228, 229, 230, 231, 232, 235, 236, 239, 241, 242, 245, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 266, 267, 268, 269, 270, 271, 274, 277, 279, 280, 281, 282, 283, 285, 299, 300, 303, 308, 315, 317, 324, 327, 336, 339, 340, 342, 344, 346, 347, 350, 352], "exampl": [0, 1, 2, 3, 4, 9, 10, 11, 13, 14, 15, 16, 17, 18, 21, 22, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 66, 71, 72, 75, 77, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 133, 134, 136, 138, 140, 142, 143, 144, 145, 148, 150, 152, 153, 154, 155, 156, 157, 158, 160, 162, 164, 170, 173, 174, 175, 176, 177, 178, 183, 186, 189, 190, 191, 193, 194, 195, 196, 197, 199, 202, 203, 206, 209, 210, 211, 212, 220, 221, 223, 224, 225, 226, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 241, 242, 243, 248, 249, 251, 252, 254, 255, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 272, 273, 277, 279, 280, 281, 282, 285, 306, 307, 308, 309, 310, 312, 313, 314, 317, 324, 327, 335, 336, 337, 339, 340, 342, 343, 344, 345, 346, 347, 348, 350, 351, 352], "packag": [0, 6, 7, 10, 114, 333, 334, 352], "singl": [0, 3, 13, 14, 17, 18, 19, 20, 21, 32, 35, 38, 41, 42, 43, 52, 53, 54, 55, 56, 57, 58, 66, 75, 84, 87, 88, 102, 108, 109, 110, 118, 119, 140, 145, 162, 176, 177, 189, 190, 191, 193, 194, 195, 196, 197, 203, 237, 241, 250, 252, 254, 256, 257, 263, 266, 267, 271, 279, 280, 281, 282, 288, 289, 290, 291, 293, 294, 295, 296, 324, 331, 333, 340, 341, 342, 343, 345, 346, 347, 348, 349], "node": [0, 2, 18, 19, 20, 21, 22, 58, 324, 333], "distribut": [0, 2, 3, 4, 9, 10, 18, 19, 20, 21, 22, 103, 104, 134, 136, 175, 184, 185, 186, 187, 192, 199, 200, 201, 206, 209, 210, 213, 214, 217, 218, 219, 227, 228, 229, 230, 235, 239, 240, 248, 249, 250, 255, 256, 257, 262, 263, 266, 267, 268, 269, 271, 333, 337, 341, 342, 346, 347, 351, 352], "helper": [0, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 333, 340, 341, 343, 347], "compos": [0, 3, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 65, 66, 67, 68, 75, 76, 84, 88, 102, 108, 118, 144, 157, 158, 164, 233, 259, 269, 324, 333, 340, 341, 342, 343, 345, 346, 349, 351, 352], "tensorspec": [0, 3, 15, 24, 25, 26, 27, 28, 29, 30, 31, 33, 46, 47, 48, 49, 50, 84, 88, 98, 102, 108, 109, 110, 116, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128, 130, 132, 133, 134, 136, 138, 142, 143, 144, 146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 174, 214, 223, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 242, 249, 252, 255, 256, 267, 269, 271, 277, 333, 347], "from": [0, 1, 3, 4, 5, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 66, 69, 70, 71, 72, 73, 74, 75, 77, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 97, 98, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 114, 115, 117, 118, 119, 121, 123, 124, 125, 126, 127, 128, 133, 134, 136, 138, 140, 141, 142, 143, 144, 145, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 170, 173, 174, 175, 179, 180, 181, 182, 183, 186, 189, 190, 191, 192, 193, 194, 195, 197, 198, 199, 201, 202, 203, 204, 206, 209, 210, 211, 212, 218, 219, 220, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 262, 263, 264, 266, 267, 268, 269, 271, 273, 277, 278, 279, 280, 281, 282, 285, 297, 298, 306, 312, 315, 318, 319, 324, 325, 327, 328, 331, 333, 334, 335, 336, 337, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352], "human": [0, 54, 333, 347], "feedback": [0, 333, 351], "rlhf": [0, 40, 45, 59, 134, 333, 335], "envbas": [0, 3, 13, 14, 16, 17, 18, 19, 20, 21, 85, 88, 102, 108, 115, 123, 126, 135, 142, 143, 157, 158, 164, 166, 175, 198, 199, 311, 319, 320, 321, 324, 327, 329, 330, 331, 333], "gymlikeenv": [0, 87, 89, 333], "envmetadata": [0, 333], "vector": [0, 1, 8, 24, 27, 33, 80, 81, 93, 94, 97, 103, 104, 105, 109, 110, 125, 163, 179, 181, 189, 190, 193, 194, 197, 279, 282, 292, 293, 294, 295, 296, 333, 340, 341, 343, 345, 346, 347, 348, 352], "mask": [0, 1, 4, 23, 27, 30, 31, 33, 103, 104, 115, 141, 186, 200, 201, 212, 228, 229, 230, 231, 232, 236, 237, 312, 333, 341, 343, 352], "action": [0, 2, 8, 9, 13, 14, 15, 16, 17, 21, 27, 33, 40, 44, 54, 56, 57, 58, 80, 81, 82, 83, 84, 87, 88, 89, 90, 93, 94, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 121, 123, 125, 126, 127, 128, 131, 134, 135, 138, 142, 143, 145, 149, 152, 158, 163, 170, 173, 175, 178, 179, 180, 181, 182, 183, 185, 186, 187, 191, 195, 197, 198, 199, 200, 201, 202, 210, 211, 212, 214, 217, 218, 220, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 239, 242, 243, 248, 249, 251, 252, 254, 255, 256, 262, 264, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 283, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 324, 327, 331, 333, 335, 336, 337, 340, 341, 342, 345, 346, 348, 349, 351, 352], "record": [0, 32, 84, 88, 102, 108, 134, 266, 297, 298, 299, 300, 301, 302, 303, 304, 305, 327, 333, 341, 342], "domain": [0, 2, 8, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 84, 88, 102, 108, 125, 154, 170, 223, 229, 230, 235, 236, 237, 238, 239, 240, 241, 333, 342, 343, 346, 347, 351, 352], "modul": [0, 2, 3, 4, 8, 11, 32, 40, 75, 80, 81, 84, 88, 97, 98, 101, 102, 108, 114, 117, 122, 125, 127, 134, 140, 141, 153, 154, 157, 158, 160, 162, 164, 165, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 261, 262, 263, 264, 266, 267, 268, 269, 270, 271, 272, 275, 277, 279, 280, 281, 282, 283, 315, 322, 323, 327, 333, 336, 337, 341, 342, 345, 346, 347, 348, 349], "tensordict": [0, 1, 2, 3, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 61, 62, 64, 66, 69, 71, 72, 75, 76, 77, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 94, 97, 98, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 117, 118, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 136, 138, 139, 140, 141, 142, 143, 145, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 173, 174, 175, 185, 186, 191, 195, 196, 198, 199, 211, 212, 220, 221, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 271, 277, 278, 279, 280, 281, 282, 283, 297, 306, 310, 311, 312, 314, 315, 324, 333, 336, 337, 340, 341, 342, 343, 345, 346, 347, 348, 352], "actor": [0, 3, 4, 15, 21, 134, 175, 178, 179, 181, 186, 187, 199, 210, 212, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 262, 263, 264, 265, 266, 267, 268, 269, 271, 272, 277, 324, 333, 336, 341, 342, 343, 346, 348, 351], "explor": [0, 1, 165, 205, 223, 227, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 248, 311, 320, 321, 327, 333, 342, 343, 346, 347], "valu": [0, 1, 3, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 45, 46, 47, 52, 56, 59, 71, 72, 75, 84, 88, 97, 102, 108, 114, 116, 118, 119, 121, 123, 125, 126, 127, 135, 136, 140, 141, 144, 145, 146, 148, 150, 154, 155, 157, 158, 162, 164, 170, 174, 179, 180, 181, 182, 184, 186, 187, 188, 191, 192, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 209, 211, 212, 217, 218, 219, 220, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 242, 243, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 298, 306, 308, 309, 310, 311, 312, 315, 324, 327, 333, 337, 341, 345, 346, 347, 349, 351, 352], "gener": [0, 1, 2, 3, 7, 8, 9, 16, 35, 38, 40, 53, 68, 70, 84, 85, 88, 98, 101, 102, 103, 104, 106, 107, 108, 122, 123, 124, 128, 134, 136, 142, 143, 148, 149, 152, 157, 163, 174, 184, 200, 201, 209, 223, 235, 239, 243, 244, 267, 273, 279, 284, 292, 301, 315, 333, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 351, 352], "hook": [0, 32, 84, 88, 102, 108, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 212, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 242, 245, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 333], "planner": [0, 175, 199, 333], "sac": [0, 256, 267, 269, 333], "redq": [0, 267, 323, 324, 333], "iql": [0, 255, 262, 333, 346], "cql": [0, 249, 254, 333], "dt": [0, 234, 333, 347], "td3": [0, 271, 333], "a2c": [0, 248, 333], "dreamer": [0, 113, 187, 258, 259, 260, 333, 335], "checkpoint": [0, 333, 348], "builder": [0, 333, 341, 352], "logger": [0, 298, 300, 301, 302, 303, 304, 305, 309, 315, 327, 331, 333, 341], "_util": [0, 3, 11, 333], "implement_for": [0, 3, 333], "contribut": 0, "thing": [0, 3, 7, 8, 334, 342, 343, 346, 349, 352], "consid": [0, 1, 3, 8, 20, 32, 34, 36, 39, 61, 62, 77, 84, 88, 102, 108, 125, 164, 184, 202, 217, 334, 340, 347, 349], "when": [0, 1, 2, 3, 5, 8, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 38, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 65, 66, 70, 73, 74, 77, 84, 85, 88, 97, 99, 101, 102, 103, 104, 108, 109, 110, 115, 117, 118, 122, 123, 125, 126, 134, 135, 136, 140, 141, 148, 154, 157, 158, 160, 162, 163, 164, 171, 172, 175, 186, 189, 190, 193, 194, 197, 198, 199, 200, 201, 204, 212, 218, 235, 238, 239, 241, 245, 250, 252, 257, 263, 266, 269, 272, 277, 278, 279, 280, 281, 282, 297, 298, 312, 331, 334, 335, 337, 340, 341, 342, 343, 346, 347, 348, 349, 352], "debug": [0, 6, 8, 40, 334, 352], "work": [0, 2, 3, 4, 8, 11, 32, 34, 36, 38, 39, 69, 71, 72, 74, 79, 84, 87, 88, 89, 92, 102, 105, 108, 119, 134, 140, 160, 163, 164, 176, 177, 197, 230, 237, 242, 250, 263, 266, 315, 334, 335, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "habitat": [0, 3, 90, 334, 348], "lab": [0, 3, 82, 83, 90, 334], "mujoco": [0, 6, 8, 105, 334, 342, 343], "error": [0, 1, 3, 7, 10, 11, 29, 32, 84, 88, 102, 108, 111, 141, 166, 334, 340, 342, 346, 352], "solut": [0, 3, 6, 7, 9, 21, 334, 335, 337, 351], "resourc": [0, 1, 21, 90, 334, 340, 342, 346], "version": [0, 1, 3, 6, 11, 32, 34, 36, 40, 53, 58, 71, 84, 87, 88, 89, 90, 99, 100, 102, 103, 105, 108, 109, 110, 163, 226, 264, 269, 279, 282, 334, 335, 340, 342, 343, 346, 347, 348, 352], "issu": [0, 4, 5, 8, 54, 61, 62, 77, 92, 118, 141, 155, 223, 229, 230, 235, 236, 237, 238, 239, 334, 351], "index": [0, 3, 7, 8, 10, 16, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 64, 66, 67, 69, 74, 75, 76, 77, 78, 79, 84, 88, 102, 108, 109, 110, 118, 125, 173, 200, 201, 345, 346, 349, 351], "search": [0, 101, 174, 341], "page": [0, 7], "somewhat": [1, 336, 352], "equival": [1, 3, 17, 24, 27, 30, 31, 32, 33, 34, 36, 39, 45, 52, 54, 56, 57, 58, 59, 80, 81, 84, 87, 88, 89, 90, 93, 94, 99, 100, 102, 105, 108, 124, 127, 158, 186, 193, 212, 229, 230, 236, 237, 266, 312, 351, 352], "dataload": [1, 59, 70, 72, 341, 342, 349], "except": [1, 2, 3, 13, 14, 16, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 44, 46, 47, 56, 84, 88, 102, 108, 118, 129, 145, 153, 154, 155, 189, 191, 193, 195, 209, 227, 231, 232, 234, 335, 341, 349, 351, 352], "1": [1, 2, 3, 4, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 66, 71, 72, 75, 80, 81, 82, 83, 84, 85, 87, 88, 89, 93, 94, 97, 98, 101, 102, 103, 104, 106, 107, 108, 109, 110, 115, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 131, 134, 136, 138, 140, 141, 142, 143, 145, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 160, 162, 164, 170, 173, 175, 176, 177, 178, 179, 180, 182, 183, 186, 188, 189, 190, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 209, 210, 211, 213, 214, 216, 217, 218, 219, 220, 223, 224, 225, 226, 227, 228, 230, 231, 232, 234, 235, 236, 237, 238, 241, 242, 243, 245, 248, 249, 250, 251, 252, 254, 255, 256, 259, 262, 263, 265, 266, 267, 268, 269, 270, 271, 277, 278, 279, 280, 281, 282, 285, 287, 288, 289, 293, 294, 296, 306, 311, 312, 313, 324, 327, 331, 334, 335, 336, 337, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352], "thei": [1, 2, 3, 4, 8, 9, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 56, 84, 88, 97, 102, 103, 104, 108, 109, 110, 117, 129, 134, 140, 149, 157, 158, 162, 195, 196, 248, 249, 250, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 312, 315, 335, 336, 337, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "collect": [1, 2, 3, 4, 8, 13, 14, 16, 17, 18, 19, 20, 21, 22, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 70, 102, 105, 108, 118, 136, 140, 162, 166, 234, 249, 251, 254, 256, 267, 269, 271, 306, 312, 315, 317, 318, 319, 327, 337, 340, 343, 346, 347, 348, 349, 351, 352], "over": [1, 2, 3, 4, 8, 13, 14, 16, 17, 18, 19, 20, 21, 32, 38, 42, 43, 45, 51, 56, 70, 84, 88, 102, 108, 125, 136, 148, 155, 173, 221, 241, 257, 259, 264, 285, 318, 337, 340, 341, 342, 346, 347, 352], "non": [1, 3, 8, 21, 32, 34, 35, 36, 38, 39, 41, 42, 56, 84, 88, 102, 103, 104, 108, 116, 122, 130, 140, 154, 157, 158, 159, 160, 162, 173, 189, 191, 193, 195, 202, 238, 239, 248, 249, 251, 252, 254, 255, 256, 257, 258, 259, 262, 264, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 335, 340, 343, 346, 347, 349, 352], "static": [1, 11, 40, 45, 71, 72, 90, 164, 262, 347, 349], "2": [1, 2, 3, 8, 9, 10, 11, 13, 14, 16, 21, 22, 26, 28, 30, 31, 32, 35, 36, 37, 38, 41, 42, 43, 45, 56, 57, 59, 66, 71, 72, 80, 81, 84, 85, 88, 93, 94, 97, 101, 102, 103, 104, 106, 107, 108, 109, 110, 117, 119, 122, 123, 124, 125, 126, 134, 136, 138, 140, 142, 145, 148, 152, 153, 154, 157, 158, 160, 162, 164, 170, 174, 176, 177, 178, 179, 180, 181, 183, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 200, 201, 202, 203, 206, 210, 221, 228, 229, 230, 231, 232, 234, 238, 242, 243, 248, 249, 250, 251, 255, 256, 262, 263, 266, 267, 268, 269, 271, 278, 279, 280, 281, 282, 284, 285, 288, 289, 290, 291, 292, 293, 294, 295, 296, 298, 306, 335, 336, 339, 340, 341, 342, 343, 345, 346, 347, 349, 350, 351, 352], "like": [1, 2, 3, 4, 7, 21, 26, 28, 32, 35, 38, 41, 42, 45, 66, 72, 84, 88, 90, 97, 102, 103, 104, 108, 127, 156, 166, 189, 193, 203, 233, 267, 336, 340, 342, 343, 346, 347, 348, 349, 352], "being": [1, 2, 3, 7, 8, 17, 18, 20, 21, 32, 59, 84, 87, 88, 89, 90, 102, 105, 108, 117, 123, 125, 126, 135, 143, 158, 171, 172, 191, 195, 231, 234, 250, 263, 266, 269, 298, 312, 317, 329, 330, 331, 335, 340, 341, 342, 343, 346, 347, 349], "s": [1, 2, 3, 6, 7, 8, 32, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 71, 72, 80, 81, 84, 88, 92, 93, 94, 99, 102, 103, 104, 108, 109, 110, 118, 122, 140, 152, 154, 156, 157, 158, 160, 162, 164, 166, 176, 177, 191, 195, 201, 202, 203, 205, 211, 220, 224, 226, 227, 230, 231, 235, 238, 239, 242, 249, 255, 262, 264, 269, 279, 280, 281, 282, 283, 324, 335, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "accept": [1, 13, 14, 16, 17, 18, 19, 20, 21, 32, 38, 53, 54, 57, 58, 59, 84, 88, 98, 102, 108, 118, 122, 130, 140, 148, 154, 157, 158, 159, 160, 162, 221, 238, 239, 240, 269, 337, 342, 352], "two": [1, 2, 3, 4, 8, 10, 32, 40, 56, 66, 70, 72, 84, 88, 102, 108, 136, 140, 162, 182, 189, 191, 193, 195, 215, 239, 263, 274, 311, 315, 324, 336, 340, 341, 342, 343, 345, 346, 347, 349, 351, 352], "main": [1, 2, 3, 5, 20, 22, 58, 85, 239, 315, 335, 336, 340, 341, 345, 352], "argument": [1, 3, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 46, 47, 53, 54, 56, 57, 58, 59, 66, 69, 70, 71, 72, 74, 80, 81, 82, 83, 84, 87, 88, 89, 90, 93, 94, 99, 100, 102, 103, 105, 108, 109, 110, 121, 122, 140, 149, 152, 154, 156, 157, 158, 160, 162, 173, 176, 177, 189, 191, 193, 195, 197, 200, 201, 202, 203, 204, 221, 223, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 242, 243, 248, 249, 250, 251, 252, 253, 254, 255, 256, 261, 262, 263, 265, 266, 267, 268, 269, 271, 273, 277, 279, 280, 281, 282, 283, 287, 297, 308, 318, 324, 327, 328, 331, 340, 341, 342, 343, 346, 347, 349, 352], "list": [1, 6, 7, 8, 9, 13, 14, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 38, 41, 42, 44, 45, 46, 47, 49, 52, 53, 54, 55, 56, 57, 58, 63, 66, 69, 70, 71, 72, 73, 74, 82, 83, 84, 87, 88, 89, 90, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 116, 117, 121, 123, 126, 134, 136, 138, 140, 148, 150, 156, 158, 160, 162, 164, 173, 185, 191, 195, 197, 200, 201, 207, 212, 230, 236, 237, 239, 241, 242, 243, 264, 269, 276, 279, 282, 297, 311, 312, 329, 330, 335, 340, 342, 345, 347, 348, 349, 351, 352], "constructor": [1, 16, 18, 19, 20, 21, 38, 45, 56, 84, 88, 99, 102, 108, 109, 157, 248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 283, 324, 328, 331, 335, 340, 341, 342, 346, 349], "iter": [1, 11, 13, 14, 16, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 59, 66, 70, 80, 81, 84, 88, 93, 94, 102, 108, 128, 136, 149, 176, 177, 197, 202, 203, 216, 223, 229, 235, 236, 238, 240, 241, 243, 264, 276, 311, 314, 315, 324, 336, 337, 340, 342, 343, 346, 347], "execut": [1, 3, 6, 7, 8, 13, 14, 16, 18, 19, 20, 21, 32, 35, 37, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 80, 81, 84, 85, 88, 89, 90, 92, 93, 94, 98, 99, 102, 105, 108, 115, 158, 189, 191, 193, 195, 231, 240, 241, 319, 331, 335, 337, 339, 341, 342, 343, 346, 349, 350, 352], "step": [1, 2, 3, 4, 8, 13, 14, 16, 17, 18, 19, 20, 21, 32, 40, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 98, 99, 100, 102, 103, 104, 105, 108, 115, 117, 130, 133, 136, 152, 153, 154, 155, 158, 163, 173, 174, 175, 187, 189, 191, 193, 195, 196, 198, 199, 227, 231, 232, 234, 235, 239, 248, 258, 266, 278, 279, 280, 281, 282, 285, 286, 287, 297, 306, 311, 315, 337, 340, 341, 343, 345, 347, 348, 349, 351], "queri": [1, 3, 13, 14, 16, 17, 32, 34, 36, 39, 84, 88, 102, 108, 140, 157, 160, 164, 241, 340, 347, 351], "defin": [1, 2, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 56, 84, 88, 102, 108, 141, 153, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 242, 245, 252, 254, 264, 279, 280, 281, 282, 283, 297, 328, 340, 341, 343, 347, 349, 352], "number": [1, 2, 3, 8, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 27, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 66, 69, 71, 72, 77, 80, 81, 84, 87, 88, 89, 93, 94, 98, 99, 100, 101, 102, 103, 104, 108, 109, 110, 117, 118, 125, 131, 135, 136, 147, 152, 155, 164, 175, 176, 177, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197, 199, 202, 203, 206, 207, 208, 211, 213, 214, 217, 218, 219, 220, 223, 227, 228, 231, 232, 234, 235, 238, 239, 243, 247, 249, 255, 256, 258, 262, 263, 265, 267, 269, 271, 306, 308, 311, 315, 317, 318, 319, 329, 330, 331, 335, 340, 341, 342, 343, 346, 347, 348, 352], "befor": [1, 2, 3, 4, 6, 7, 10, 13, 14, 16, 17, 18, 19, 20, 21, 32, 40, 45, 55, 70, 84, 88, 102, 108, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 132, 133, 134, 135, 136, 138, 142, 143, 144, 146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 159, 160, 161, 163, 189, 191, 195, 197, 204, 205, 248, 249, 250, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 280, 281, 282, 312, 340, 342, 343, 346, 347, 349, 352], "deliv": [1, 16, 18, 19, 20, 56, 340, 341, 351], "stack": [1, 2, 3, 7, 8, 18, 20, 21, 28, 29, 50, 66, 84, 88, 97, 102, 103, 104, 108, 164, 189, 191, 193, 194, 195, 240, 241, 297, 306, 335, 341, 345, 347, 351], "user": [1, 2, 3, 5, 8, 21, 32, 52, 54, 56, 57, 58, 72, 84, 88, 102, 108, 153, 158, 183, 196, 266, 269, 328, 336, 337, 340, 341, 347, 351, 352], "reset": [1, 3, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 72, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 97, 98, 99, 100, 101, 102, 103, 104, 105, 108, 118, 127, 130, 133, 135, 140, 148, 152, 153, 154, 155, 157, 160, 163, 164, 166, 174, 189, 191, 195, 222, 234, 297, 324, 340, 341, 342, 343, 345, 346, 351], "whenev": [1, 2, 3, 32, 35, 38, 41, 42, 56, 82, 83, 87, 89, 90, 105, 109, 110, 114, 133, 158, 163, 264, 279, 280, 281, 282, 317, 335], "reach": [1, 13, 14, 16, 17, 18, 19, 20, 21, 22, 40, 70, 84, 88, 102, 108, 109, 110, 152, 227, 231, 232, 234, 340, 342, 346, 351, 352], "done": [1, 2, 3, 4, 7, 8, 13, 14, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 44, 46, 47, 52, 54, 56, 57, 58, 66, 71, 72, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 118, 123, 124, 126, 127, 128, 135, 136, 138, 142, 143, 145, 147, 149, 152, 154, 155, 157, 158, 164, 173, 174, 175, 189, 191, 195, 199, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 324, 336, 340, 342, 343, 345, 346, 347, 348, 349, 351, 352], "state": [1, 2, 3, 4, 13, 14, 16, 17, 32, 35, 38, 40, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 80, 81, 82, 83, 84, 87, 88, 89, 90, 93, 94, 98, 102, 103, 104, 105, 106, 107, 108, 117, 118, 119, 121, 127, 136, 143, 152, 153, 157, 158, 164, 173, 174, 175, 178, 183, 187, 189, 190, 191, 193, 194, 195, 196, 197, 199, 207, 210, 211, 213, 214, 220, 224, 238, 244, 248, 250, 254, 263, 264, 266, 267, 268, 269, 277, 278, 279, 280, 281, 282, 283, 331, 335, 336, 340, 341, 342, 343, 346, 347, 352], "after": [1, 2, 3, 8, 13, 14, 18, 20, 21, 26, 32, 40, 66, 80, 81, 82, 83, 84, 87, 88, 89, 90, 92, 93, 94, 99, 100, 102, 105, 108, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128, 130, 132, 133, 134, 135, 136, 138, 142, 143, 144, 146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 173, 189, 191, 195, 204, 227, 229, 231, 232, 236, 259, 269, 341, 342, 343, 346, 347, 348, 349, 352], "predefin": [1, 341, 342, 343, 349], "becaus": [1, 3, 4, 7, 34, 36, 39, 40, 84, 88, 102, 108, 127, 134, 152, 157, 163, 182, 196, 203, 223, 229, 230, 235, 236, 237, 238, 239, 340, 341, 343, 345, 346, 347, 349, 352], "potenti": [1, 2, 347, 349], "comput": [1, 3, 4, 8, 13, 16, 21, 27, 32, 40, 80, 81, 84, 88, 93, 94, 102, 108, 136, 150, 158, 161, 174, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 201, 202, 203, 206, 207, 208, 209, 210, 213, 214, 216, 218, 219, 221, 224, 227, 228, 230, 231, 232, 234, 235, 237, 239, 242, 245, 247, 248, 249, 250, 251, 252, 253, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 271, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 285, 319, 336, 340, 342, 343, 345, 346, 348, 349], "heavi": [1, 8, 349], "crucial": [1, 227, 231, 232, 234, 255, 262, 264, 340, 341, 342, 343, 346, 347, 352], "configur": [1, 8, 13, 14, 16, 17, 21, 22, 40, 134, 178, 183, 210, 264, 266, 324, 335, 340, 341, 342, 346, 347], "hyperparamet": [1, 69, 248, 249, 251, 252, 254, 255, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 340, 347, 349], "appropri": [1, 3, 4, 7, 13, 14, 16, 17, 60, 67, 75, 76, 78, 79, 102, 108, 127, 328, 331, 340, 349], "paramet": [1, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 69, 70, 73, 74, 75, 77, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 98, 99, 100, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 131, 132, 133, 134, 135, 136, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 324, 327, 328, 329, 330, 331, 335, 336, 340, 343, 346, 347, 348, 351], "take": [1, 3, 8, 23, 40, 53, 80, 81, 84, 88, 93, 94, 102, 108, 121, 152, 155, 157, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 233, 234, 235, 237, 242, 245, 247, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 306, 317, 335, 337, 340, 341, 342, 346, 347, 349, 352], "consider": [1, 3, 8, 341, 346, 349], "whether": [1, 2, 3, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 40, 41, 42, 43, 44, 46, 47, 52, 53, 54, 55, 56, 57, 58, 66, 84, 88, 98, 102, 103, 104, 108, 109, 110, 123, 126, 153, 158, 174, 176, 177, 191, 195, 197, 243, 249, 250, 251, 252, 254, 256, 257, 263, 264, 266, 267, 269, 271, 277, 279, 282, 340, 341, 342, 346, 347, 352], "should": [1, 3, 4, 5, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 66, 71, 72, 73, 75, 82, 83, 84, 87, 88, 89, 90, 97, 98, 102, 103, 104, 108, 109, 110, 118, 121, 122, 123, 124, 127, 128, 130, 134, 136, 141, 142, 143, 145, 148, 149, 152, 153, 155, 157, 158, 163, 164, 166, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 235, 237, 238, 239, 242, 245, 256, 261, 263, 264, 266, 267, 270, 278, 279, 280, 281, 282, 283, 298, 310, 311, 312, 315, 327, 329, 330, 331, 335, 337, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "occur": [1, 8, 14, 28, 29, 90, 119, 136, 141, 163, 174, 223, 229, 230, 235, 236, 237, 238, 239, 259, 349, 352], "serial": [1, 2, 3, 32, 84, 88, 102, 108, 164], "optim": [1, 2, 8, 32, 40, 80, 81, 84, 88, 102, 108, 158, 175, 199, 204, 205, 249, 264, 265, 266, 269, 310, 315, 327, 336, 337, 342, 343, 346, 347], "parallel": [1, 3, 8, 17, 87, 89, 102, 103, 104, 163, 166, 248, 328, 329, 330, 331, 341, 342, 346], "syncdatacollector": [1, 13, 14, 17, 18, 19, 20, 21, 118, 145, 327, 330, 333, 342, 343, 346, 349], "class": [1, 2, 3, 5, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 84, 85, 86, 87, 88, 89, 90, 97, 98, 101, 102, 103, 104, 105, 108, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 329, 330, 331, 335, 336, 337, 340, 341, 342, 343, 346, 349, 352], "worker": [1, 2, 13, 14, 16, 17, 18, 19, 20, 21, 22, 36, 45, 53, 59, 85, 99, 102, 108, 164, 329, 330, 331, 340, 342, 351, 352], "multisyncdatacollector": [1, 18, 19, 20, 21, 330, 333, 342, 351], "split": [1, 13, 14, 16, 17, 18, 19, 20, 21, 34, 36, 45, 52, 54, 56, 57, 58, 59, 71, 72, 97, 103, 104, 189, 193, 248, 249, 250, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 335, 337, 342, 349, 351], "workload": 1, "across": [1, 3, 8, 18, 19, 20, 21, 35, 38, 41, 42, 71, 72, 80, 81, 82, 83, 87, 89, 90, 92, 93, 94, 99, 100, 102, 105, 164, 202, 234, 317, 333, 335, 340, 346, 347], "aggreg": [1, 3, 174, 176, 177, 179, 180, 241], "result": [1, 3, 7, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 35, 36, 37, 38, 39, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 70, 71, 72, 84, 85, 88, 102, 108, 116, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128, 130, 132, 133, 134, 135, 136, 138, 142, 143, 144, 146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 166, 173, 174, 189, 191, 193, 195, 197, 202, 212, 228, 230, 231, 237, 248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 279, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 317, 335, 341, 343, 347, 348, 351, 352], "final": [1, 3, 4, 21, 34, 36, 39, 40, 163, 189, 191, 193, 195, 202, 227, 231, 232, 233, 234, 240, 279, 311, 335, 340, 341, 342, 346, 347, 352], "multiasyncdatacollector": [1, 17, 18, 19, 20, 21, 329, 333, 340, 341, 342, 351], "sever": [1, 8, 30, 32, 45, 53, 84, 88, 102, 108, 119, 121, 158, 266, 340, 342, 349, 352], "batch": [1, 3, 13, 14, 16, 17, 18, 19, 20, 21, 23, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 65, 66, 70, 71, 72, 77, 80, 81, 82, 83, 84, 87, 88, 89, 90, 93, 94, 98, 99, 101, 102, 108, 109, 110, 118, 130, 136, 138, 141, 145, 154, 158, 159, 163, 164, 174, 184, 185, 189, 190, 191, 193, 194, 195, 196, 200, 201, 202, 203, 204, 209, 211, 217, 221, 234, 238, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 283, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 298, 306, 309, 312, 313, 314, 315, 317, 329, 330, 331, 337, 341, 342, 343, 345, 346, 348, 351, 352], "gather": [1, 3, 18, 20, 21, 45, 59, 61, 62, 77, 141, 201, 209, 278, 319, 334, 340, 341, 342, 343, 346, 347, 349, 352], "continu": [1, 9, 25, 46, 72, 84, 88, 102, 103, 104, 108, 109, 110, 170, 179, 180, 181, 182, 234, 241, 248, 249, 255, 256, 262, 266, 267, 268, 269, 270, 271, 279, 284, 292, 335, 340, 342, 343, 346, 347, 349, 351, 352], "concomitantli": 1, "network": [1, 4, 8, 32, 84, 88, 97, 102, 103, 104, 108, 176, 177, 179, 180, 181, 182, 185, 187, 188, 193, 197, 202, 203, 205, 207, 208, 211, 213, 214, 215, 220, 224, 225, 226, 228, 238, 242, 249, 250, 251, 252, 254, 255, 256, 257, 261, 262, 263, 264, 266, 267, 268, 269, 270, 271, 275, 277, 279, 280, 281, 282, 283, 326, 327, 335, 336, 337, 345, 347, 352], "impli": [1, 352], "weight": [1, 4, 9, 12, 13, 14, 16, 17, 18, 19, 20, 21, 32, 35, 40, 66, 69, 80, 81, 84, 88, 102, 106, 107, 108, 122, 140, 154, 157, 158, 160, 162, 189, 190, 191, 193, 194, 195, 202, 205, 238, 248, 249, 250, 256, 259, 269, 317, 326, 335, 337, 340, 341, 342, 343, 345, 347, 349, 351], "mai": [1, 2, 3, 4, 5, 7, 8, 13, 14, 16, 17, 18, 20, 21, 28, 29, 32, 52, 54, 56, 57, 58, 84, 87, 88, 89, 90, 102, 105, 108, 134, 136, 149, 158, 159, 164, 166, 197, 202, 336, 337, 340, 341, 342, 343, 346, 347, 348, 349, 351, 352], "slightli": [1, 335, 336, 343, 347, 348, 349, 352], "lag": [1, 13, 14, 16, 17, 340, 341, 342], "therefor": [1, 3, 7, 57, 58, 84, 88, 102, 108, 145, 266, 277, 352], "although": [1, 8, 84, 88, 102, 108, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 242, 245, 337, 340, 341, 349], "fastest": 1, "price": 1, "suitabl": [1, 2], "where": [1, 2, 3, 4, 7, 8, 13, 14, 16, 17, 18, 19, 20, 21, 28, 29, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 66, 71, 72, 75, 77, 84, 88, 97, 98, 101, 102, 103, 104, 108, 115, 118, 127, 134, 140, 145, 148, 152, 153, 155, 157, 159, 162, 163, 173, 174, 189, 190, 193, 194, 200, 201, 202, 227, 231, 232, 234, 235, 238, 239, 247, 248, 249, 250, 255, 256, 257, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 278, 279, 280, 281, 282, 283, 284, 285, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 336, 337, 340, 341, 342, 345, 346, 347, 349, 352], "asynchron": [1, 9, 14, 21, 32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238, 248, 329, 341, 342], "off": [1, 2, 4, 192, 219, 229, 269, 311, 320, 335, 337, 340, 341, 342, 346, 348, 352], "curriculum": [1, 4], "For": [1, 2, 3, 4, 7, 8, 9, 10, 13, 14, 16, 17, 18, 20, 21, 32, 52, 54, 56, 57, 58, 71, 84, 88, 102, 103, 104, 108, 109, 123, 126, 130, 136, 153, 158, 163, 186, 189, 191, 193, 195, 203, 204, 224, 226, 228, 230, 236, 248, 255, 257, 262, 266, 311, 335, 337, 340, 341, 342, 343, 346, 347, 348, 349, 352], "remot": [1, 2, 18, 19, 20, 21, 102, 108, 352], "rollout": [1, 2, 3, 13, 14, 16, 21, 23, 40, 80, 81, 84, 88, 90, 91, 93, 94, 98, 99, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 118, 121, 123, 126, 127, 128, 134, 138, 142, 143, 148, 149, 150, 152, 153, 155, 166, 175, 191, 195, 199, 234, 248, 319, 335, 340, 342, 343, 348, 349, 351], "necessari": [1, 4, 6, 8, 13, 14, 16, 17, 53, 54, 56, 57, 58, 84, 88, 102, 108, 109, 110, 149, 267, 279, 280, 281, 282, 283, 336, 340, 342], "synchronis": [1, 85, 346], "either": [1, 5, 22, 32, 40, 59, 66, 84, 88, 102, 108, 152, 153, 244, 271, 302, 337, 340, 341, 343, 348, 349, 351, 352], "update_policy_weights_": [1, 12, 13, 14, 16, 17, 18, 19, 20, 21, 340, 346, 351], "update_at_each_batch": [1, 13, 14, 17, 340], "true": [1, 3, 4, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 66, 69, 70, 71, 72, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 94, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 117, 118, 119, 122, 125, 130, 133, 134, 135, 136, 140, 141, 143, 144, 147, 149, 152, 154, 156, 157, 158, 159, 160, 162, 164, 166, 170, 173, 174, 175, 176, 177, 179, 180, 181, 182, 188, 189, 190, 191, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 218, 219, 223, 224, 225, 226, 227, 229, 230, 234, 235, 236, 237, 238, 239, 240, 241, 242, 248, 249, 250, 251, 254, 255, 256, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 271, 274, 279, 280, 281, 282, 285, 288, 289, 290, 291, 293, 294, 295, 296, 297, 298, 308, 309, 311, 312, 315, 331, 335, 336, 337, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "second": [1, 3, 8, 53, 189, 191, 193, 195, 230, 250, 263, 266, 269, 314, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "devic": [1, 2, 3, 7, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 54, 56, 57, 58, 59, 61, 62, 77, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 122, 123, 124, 126, 127, 128, 134, 138, 139, 140, 142, 143, 145, 149, 152, 154, 156, 157, 158, 160, 162, 170, 173, 175, 176, 177, 178, 179, 180, 181, 182, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 199, 202, 203, 204, 205, 210, 211, 212, 220, 223, 224, 225, 226, 228, 229, 230, 234, 235, 236, 237, 238, 241, 243, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 312, 317, 324, 325, 335, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351], "oper": [1, 3, 4, 7, 8, 13, 14, 17, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 44, 45, 46, 47, 84, 88, 102, 108, 130, 134, 157, 185, 186, 190, 194, 206, 224, 225, 226, 229, 230, 233, 238, 244, 248, 250, 251, 252, 257, 263, 266, 268, 277, 278, 279, 280, 281, 282, 315, 324, 333, 337, 340, 341, 342, 343, 345, 346, 347, 352], "instanc": [1, 2, 3, 4, 7, 8, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 36, 37, 39, 43, 44, 45, 52, 56, 66, 71, 72, 83, 84, 85, 88, 98, 102, 108, 118, 136, 154, 157, 164, 170, 174, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 239, 240, 241, 242, 245, 252, 255, 256, 264, 277, 279, 280, 281, 282, 298, 302, 311, 319, 320, 321, 324, 327, 329, 330, 335, 336, 337, 340, 342, 343, 347, 349, 352], "cpu": [1, 3, 8, 10, 13, 14, 16, 18, 19, 20, 21, 24, 26, 28, 32, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 54, 56, 57, 58, 59, 61, 62, 77, 80, 81, 82, 83, 84, 87, 88, 89, 93, 94, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 122, 123, 124, 126, 127, 128, 138, 140, 142, 143, 145, 149, 152, 154, 157, 158, 160, 162, 170, 173, 175, 189, 190, 191, 193, 194, 195, 199, 204, 205, 211, 212, 220, 223, 224, 225, 226, 228, 229, 230, 235, 236, 237, 238, 241, 243, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 277, 312, 324, 335, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "slower": 1, "than": [1, 2, 3, 4, 8, 13, 14, 16, 17, 52, 56, 69, 71, 72, 74, 75, 84, 88, 92, 102, 105, 108, 143, 182, 191, 193, 195, 197, 206, 221, 223, 227, 229, 238, 243, 264, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 317, 334, 336, 340, 341, 342, 346, 347, 349, 351, 352], "one": [1, 2, 3, 4, 5, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 52, 53, 54, 55, 56, 57, 58, 60, 64, 66, 67, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 84, 85, 87, 88, 89, 90, 92, 93, 94, 97, 99, 100, 101, 102, 103, 104, 105, 108, 109, 110, 115, 118, 121, 123, 124, 125, 126, 135, 136, 140, 145, 148, 151, 153, 154, 155, 157, 158, 159, 162, 164, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 209, 210, 212, 213, 214, 216, 221, 223, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 242, 243, 245, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 262, 263, 264, 266, 267, 268, 269, 270, 271, 277, 279, 280, 281, 282, 286, 287, 308, 310, 311, 315, 319, 324, 331, 334, 335, 336, 337, 340, 341, 342, 343, 345, 346, 347, 348, 349, 352], "cuda": [1, 3, 7, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 84, 88, 90, 91, 92, 102, 108, 122, 134, 139, 140, 154, 157, 158, 160, 162, 189, 190, 193, 194, 238, 254, 307, 340, 341, 342, 343, 346, 348, 352], "multipl": [1, 2, 3, 5, 8, 13, 14, 16, 17, 18, 19, 20, 21, 27, 43, 66, 80, 81, 93, 94, 102, 108, 119, 121, 125, 135, 145, 148, 152, 157, 164, 189, 193, 195, 196, 202, 204, 205, 223, 229, 235, 236, 238, 239, 242, 250, 256, 263, 266, 267, 271, 285, 324, 331, 335, 337, 340, 341, 342, 346, 347, 349, 351], "infer": [1, 102, 108, 118, 164, 191, 195, 204, 228, 254, 340, 342, 349], "run": [1, 3, 4, 5, 6, 7, 8, 10, 13, 14, 17, 21, 32, 53, 80, 81, 82, 83, 84, 87, 88, 93, 94, 98, 99, 100, 102, 108, 135, 136, 158, 164, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 240, 241, 242, 245, 269, 311, 329, 330, 331, 334, 337, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351], "dispatch": [1, 18, 19, 20, 21, 221], "avail": [1, 3, 4, 6, 21, 53, 58, 70, 82, 83, 92, 102, 103, 104, 105, 109, 110, 117, 134, 186, 212, 235, 239, 264, 329, 330, 335, 340, 341, 342, 343, 346, 347, 349, 352], "speed": [1, 2, 4, 8, 27, 102, 108, 336, 340, 341, 342, 343, 346, 347, 349], "up": [1, 2, 3, 8, 9, 13, 14, 16, 27, 40, 52, 54, 56, 57, 58, 102, 108, 117, 155, 157, 266, 334, 335, 336, 340, 341, 342, 343, 346, 347, 349, 352], "avoid": [1, 32, 61, 62, 77, 84, 88, 102, 108, 114, 158, 164, 223, 238, 243, 250, 263, 266, 269, 318, 342, 346], "oom": [1, 61, 62, 77], "choic": [1, 2, 52, 54, 56, 57, 58, 102, 206, 335, 336, 340, 341, 346], "size": [1, 2, 3, 13, 14, 16, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 65, 66, 70, 71, 72, 73, 77, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 93, 94, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 117, 119, 123, 126, 127, 128, 130, 138, 140, 142, 143, 145, 149, 151, 152, 154, 156, 157, 158, 159, 162, 164, 170, 173, 175, 176, 177, 178, 183, 184, 186, 189, 190, 191, 193, 194, 195, 196, 197, 199, 200, 201, 202, 203, 206, 209, 210, 211, 212, 213, 214, 217, 220, 221, 223, 224, 225, 226, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 241, 243, 248, 249, 251, 252, 254, 255, 256, 262, 264, 266, 267, 268, 269, 271, 277, 278, 279, 280, 281, 282, 283, 298, 306, 312, 324, 335, 341, 342, 343, 345, 346, 347, 348, 351, 352], "pass": [1, 3, 4, 13, 14, 16, 18, 19, 20, 21, 22, 26, 28, 32, 35, 38, 40, 41, 42, 45, 53, 54, 56, 57, 58, 61, 62, 66, 75, 77, 84, 85, 86, 88, 97, 99, 102, 103, 104, 108, 109, 123, 126, 143, 157, 159, 164, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 204, 206, 207, 208, 210, 211, 213, 214, 216, 220, 221, 223, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 241, 242, 243, 245, 250, 263, 264, 266, 279, 280, 281, 282, 283, 312, 329, 330, 331, 335, 340, 341, 342, 343, 345, 346, 347, 349, 352], "ie": [1, 3, 18, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 44, 45, 46, 47, 56, 64, 72, 84, 88, 92, 101, 102, 108, 118, 130, 159, 164, 174, 191, 195, 228, 248, 250, 251, 255, 256, 262, 263, 266, 267, 268, 269, 271, 279, 280, 281, 282, 335, 336, 341, 342, 346, 349], "store": [1, 3, 8, 13, 14, 16, 17, 20, 26, 32, 34, 36, 37, 39, 41, 42, 43, 45, 53, 56, 57, 59, 61, 62, 63, 64, 77, 84, 88, 102, 108, 163, 164, 175, 196, 199, 248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 324, 333, 337, 340, 342, 343, 346, 348, 349, 352], "while": [1, 3, 7, 8, 32, 84, 88, 102, 108, 145, 158, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 242, 245, 255, 262, 263, 266, 269, 335, 340, 342, 343, 346, 347, 348, 349, 351], "wait": [1, 20, 21, 22, 343, 347], "also": [1, 2, 3, 8, 9, 11, 32, 34, 36, 39, 41, 53, 54, 56, 57, 58, 59, 61, 62, 66, 77, 84, 88, 102, 103, 104, 108, 109, 110, 114, 117, 118, 125, 136, 143, 145, 148, 149, 152, 154, 158, 189, 193, 214, 235, 240, 241, 242, 248, 249, 251, 252, 254, 255, 256, 262, 266, 269, 279, 286, 287, 335, 337, 340, 341, 342, 343, 345, 346, 347, 349, 352], "impact": [1, 56, 123, 126, 341, 343, 346], "memori": [1, 2, 3, 8, 21, 27, 32, 34, 36, 39, 45, 52, 53, 54, 56, 57, 58, 61, 84, 85, 88, 92, 102, 108, 118, 122, 140, 154, 157, 158, 160, 162, 164, 193, 194, 238, 331, 337, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "manag": [1, 8, 275, 276, 279, 280, 281, 282, 311], "kei": [1, 2, 3, 7, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 66, 69, 71, 72, 75, 84, 88, 93, 94, 102, 108, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 136, 139, 140, 141, 142, 143, 145, 148, 149, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 173, 174, 175, 185, 186, 191, 195, 198, 199, 212, 223, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 278, 279, 280, 281, 282, 283, 298, 309, 310, 311, 313, 314, 315, 319, 324, 336, 337, 340, 342, 343, 345, 346, 347, 349, 351, 352], "control": [1, 3, 5, 8, 16, 82, 83, 84, 88, 97, 102, 103, 104, 108, 125, 173, 179, 180, 181, 182, 191, 195, 198, 199, 214, 221, 234, 238, 239, 240, 248, 250, 263, 266, 270, 279, 284, 292, 335, 337, 340, 341, 342, 346, 347, 349], "which": [1, 2, 3, 4, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 44, 45, 46, 47, 52, 53, 54, 56, 57, 58, 59, 69, 70, 80, 81, 82, 83, 84, 87, 88, 89, 90, 92, 93, 94, 99, 100, 102, 105, 108, 109, 110, 118, 119, 123, 126, 131, 134, 135, 136, 140, 141, 152, 154, 155, 157, 158, 160, 166, 189, 190, 192, 193, 194, 195, 200, 201, 202, 219, 224, 225, 226, 228, 235, 238, 239, 241, 248, 249, 250, 252, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 274, 277, 279, 280, 281, 282, 306, 310, 324, 335, 336, 337, 340, 341, 342, 343, 345, 346, 347, 348, 349, 352], "storing_devic": [1, 13, 14, 16, 17, 18, 19, 20, 21, 340, 341, 346, 351], "dure": [1, 2, 3, 13, 14, 16, 17, 18, 19, 20, 36, 40, 45, 52, 53, 54, 55, 56, 57, 58, 59, 66, 69, 84, 88, 102, 103, 104, 108, 118, 121, 123, 126, 131, 138, 150, 158, 191, 195, 311, 315, 336, 340, 341, 342, 343, 346, 347, 349, 352], "heurist": [1, 4, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 234, 340, 352], "usual": [1, 2, 3, 4, 6, 7, 8, 52, 69, 80, 81, 84, 88, 93, 94, 102, 108, 205, 266, 279, 280, 281, 282, 283, 297, 324, 334, 335, 337, 340, 341, 342, 343, 346, 349, 352], "same": [1, 2, 3, 4, 11, 13, 14, 16, 18, 19, 20, 21, 28, 29, 32, 34, 36, 39, 43, 45, 52, 56, 70, 74, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 97, 99, 100, 102, 103, 104, 105, 108, 118, 123, 125, 126, 131, 135, 136, 157, 158, 164, 176, 177, 190, 191, 194, 195, 197, 200, 201, 202, 203, 228, 234, 242, 269, 340, 341, 342, 345, 346, 348, 349, 352], "storag": [1, 2, 8, 32, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 66, 70, 71, 72, 74, 75, 77, 84, 86, 88, 102, 108, 117, 118, 123, 126, 145, 333, 337, 341, 342, 343, 346, 348], "default": [1, 2, 3, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 64, 66, 69, 70, 71, 72, 75, 77, 80, 81, 82, 83, 84, 87, 88, 89, 90, 93, 94, 99, 100, 101, 102, 103, 104, 105, 108, 109, 110, 115, 116, 117, 118, 119, 123, 125, 126, 127, 130, 134, 135, 136, 138, 140, 141, 145, 147, 149, 152, 153, 154, 155, 156, 158, 159, 160, 162, 163, 164, 166, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 210, 212, 213, 214, 216, 217, 218, 219, 223, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 242, 243, 245, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 271, 273, 274, 277, 278, 279, 280, 281, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 324, 327, 331, 337, 340, 341, 342, 343, 348, 349, 351, 352], "behaviour": [1, 3, 21, 56, 88, 119, 123, 126, 136, 141, 153, 173, 191, 192, 195, 219, 311, 335, 341, 349], "besid": 1, "those": [1, 2, 3, 5, 7, 26, 28, 102, 108, 118, 123, 126, 136, 154, 155, 195, 235, 239, 240, 241, 317, 329, 330, 335, 340, 341, 346, 347, 352], "choos": [1, 97, 191, 195, 266, 335, 336, 340, 341, 342, 346, 349], "follow": [1, 2, 3, 6, 7, 8, 32, 34, 36, 37, 39, 40, 52, 55, 80, 81, 84, 88, 93, 94, 98, 101, 102, 103, 104, 106, 107, 108, 109, 110, 134, 140, 160, 176, 177, 189, 191, 193, 195, 197, 230, 236, 237, 247, 248, 249, 250, 251, 255, 256, 262, 263, 266, 267, 268, 269, 271, 315, 324, 335, 336, 337, 340, 341, 342, 343, 345, 346, 347, 349, 351, 352], "max_frames_per_traj": [1, 13, 14, 16, 17, 18, 19, 20, 21, 318, 340, 342, 351], "frame": [1, 2, 13, 14, 16, 17, 18, 19, 20, 21, 32, 118, 131, 227, 231, 232, 234, 297, 298, 308, 311, 315, 318, 319, 340, 341, 342, 343, 346, 349, 351, 352], "call": [1, 2, 3, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 65, 66, 70, 73, 74, 77, 80, 81, 82, 83, 84, 87, 88, 89, 90, 93, 94, 99, 100, 101, 102, 105, 108, 118, 121, 122, 125, 130, 133, 134, 136, 138, 139, 140, 148, 150, 154, 157, 158, 160, 162, 163, 164, 166, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 199, 202, 203, 204, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 238, 239, 241, 242, 245, 250, 263, 266, 269, 278, 279, 280, 281, 282, 297, 311, 337, 341, 342, 343, 346, 347, 349, 352], "frames_per_batch": [1, 13, 14, 16, 17, 18, 19, 20, 21, 118, 145, 318, 340, 341, 342, 343, 346, 349, 351], "each": [1, 2, 3, 4, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 23, 30, 31, 32, 40, 41, 52, 53, 56, 66, 69, 71, 72, 84, 85, 88, 102, 103, 104, 108, 109, 110, 140, 145, 148, 152, 153, 154, 155, 162, 164, 186, 189, 190, 191, 193, 195, 202, 203, 207, 211, 212, 220, 227, 229, 230, 231, 237, 241, 285, 288, 289, 290, 291, 293, 294, 295, 296, 311, 312, 329, 330, 335, 340, 341, 342, 343, 346, 347, 348, 349, 351, 352], "init_random_fram": [1, 13, 14, 16, 17, 18, 19, 20, 21, 318, 340, 341], "random": [1, 3, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 33, 40, 44, 46, 47, 56, 58, 65, 84, 88, 98, 102, 108, 125, 135, 136, 154, 166, 189, 191, 193, 195, 231, 235, 238, 239, 249, 267, 311, 319, 335, 340, 341, 342, 343, 347, 348, 349, 351, 352], "rand_step": [1, 3, 82, 83, 84, 85, 87, 88, 89, 95, 96, 98, 99, 100, 102, 108, 133, 154, 164, 347, 351, 352], "reset_at_each_it": [1, 13, 14, 16, 17, 18, 19, 20, 21, 340], "split_traj": [1, 13, 14, 16, 17, 18, 19, 20, 21, 52, 54, 56, 57, 58, 340, 341, 342], "trajectori": [1, 3, 13, 14, 16, 17, 18, 19, 20, 21, 23, 32, 41, 52, 53, 54, 56, 57, 58, 64, 71, 72, 80, 81, 84, 88, 93, 94, 102, 108, 141, 152, 157, 175, 195, 199, 234, 266, 279, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 306, 333, 336, 340, 341, 342, 343, 347, 349, 351, 352], "pad": [1, 2, 3, 23, 37, 43, 52, 54, 56, 57, 58, 118, 176, 177, 179, 180, 195, 196, 200, 201, 202, 312], "along": [1, 2, 3, 23, 28, 29, 34, 36, 39, 40, 45, 52, 54, 56, 57, 58, 62, 66, 71, 72, 77, 117, 118, 119, 136, 138, 141, 148, 156, 195, 197, 200, 201, 205, 229, 235, 238, 239, 264, 335, 340, 341, 343, 346, 347, 349], "point": [1, 2, 3, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 55, 60, 64, 67, 75, 76, 78, 79, 84, 88, 102, 108, 117, 118, 122, 140, 153, 154, 156, 157, 158, 160, 162, 198, 238, 247, 257, 315, 334, 341, 342, 345, 346, 347, 349, 352], "boolean": [1, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 44, 46, 47, 88, 141, 152, 174, 200, 201, 227, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 337, 343], "repres": [1, 2, 3, 13, 14, 16, 17, 18, 19, 20, 21, 26, 28, 41, 54, 82, 83, 84, 88, 102, 108, 109, 110, 131, 141, 164, 186, 200, 201, 212, 229, 230, 236, 237, 239, 274, 279, 312, 340, 342, 343, 346], "valid": [1, 3, 23, 34, 36, 37, 45, 59, 111, 141, 158, 176, 177, 197, 200, 201, 227, 234, 263, 279, 280, 281, 282, 312, 337, 352], "exploration_typ": [1, 13, 14, 16, 18, 19, 20, 21, 311, 333, 340, 341], "strategi": [1, 2, 16, 56, 69, 97, 201, 209, 231, 335, 337, 340, 341, 346, 349], "reset_when_don": [1, 13, 14, 16, 18, 19, 20, 21], "These": [1, 2, 7, 32, 40, 53, 58, 84, 88, 102, 108, 109, 140, 162, 335, 336, 340, 342, 346, 347, 349, 352], "tool": [1, 2, 3, 5, 343, 347, 349, 352], "backend": [1, 3, 7, 11, 18, 19, 21, 22, 84, 87, 88, 102, 108, 112, 114, 337, 340, 342, 343, 347], "gloo": [1, 18, 19, 22], "nccl": [1, 18, 19], "mpi": [1, 18, 19], "distributeddatacollector": [1, 22, 333], "rpc": [1, 20, 22], "rpcdatacollector": [1, 22, 333], "launcher": [1, 18, 19, 20, 22], "rai": [1, 21], "submitit": [1, 18, 19, 20, 22], "torch": [1, 2, 3, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 64, 66, 70, 71, 72, 75, 77, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 116, 117, 119, 122, 123, 124, 125, 126, 127, 128, 134, 136, 138, 140, 142, 143, 145, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 160, 162, 164, 170, 173, 174, 175, 176, 177, 178, 183, 184, 186, 187, 189, 190, 191, 192, 193, 194, 195, 196, 197, 199, 200, 201, 202, 203, 204, 205, 206, 209, 210, 211, 212, 217, 218, 219, 220, 221, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 246, 248, 249, 251, 252, 254, 255, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 306, 313, 314, 324, 327, 335, 336, 337, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "multiprocess": [1, 2, 3, 18, 19, 20, 85, 86, 164, 341, 342, 347, 352], "synchron": [1, 13, 19, 21, 99, 329, 330, 341, 342], "mode": [1, 6, 13, 14, 16, 18, 19, 20, 21, 32, 84, 88, 99, 102, 108, 123, 126, 153, 158, 164, 167, 171, 172, 184, 191, 192, 195, 209, 217, 218, 219, 235, 239, 264, 311, 340, 341, 343, 346, 351, 352], "find": [1, 4, 6, 7, 18, 19, 20, 35, 37, 43, 71, 72, 193, 227, 234, 309, 313, 340, 341, 346], "dedic": [1, 2, 3, 18, 19, 20, 21, 224, 225, 226, 335, 340, 345, 346], "folder": [1, 2, 109, 341], "sub": [1, 2, 3, 13, 14, 18, 19, 20, 21, 56, 71, 84, 88, 102, 108, 141, 240, 241, 306, 315, 335, 340, 341, 342, 345, 351, 352], "all": [1, 2, 3, 4, 8, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 44, 46, 47, 49, 58, 82, 83, 84, 85, 87, 88, 89, 90, 98, 102, 103, 104, 108, 109, 110, 111, 117, 118, 121, 122, 123, 124, 126, 129, 134, 135, 136, 140, 148, 150, 154, 155, 157, 158, 160, 162, 164, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 238, 239, 241, 242, 245, 259, 264, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 310, 315, 318, 329, 330, 331, 334, 335, 336, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 349, 351, 352], "variou": [1, 3, 13, 14, 16, 17, 191, 195, 248, 249, 250, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 272, 277, 329, 330, 340, 341, 342, 346, 352], "machin": [1, 7, 18, 19, 20, 32, 55, 92, 346], "One": [1, 2, 4, 8, 31, 33, 45, 80, 81, 118, 145, 160, 209, 227, 238, 242, 270, 274, 302, 340, 341, 349, 352], "wonder": 1, "why": [1, 3, 347, 352], "parallelenv": [1, 2, 3, 13, 14, 16, 17, 20, 84, 88, 99, 103, 104, 105, 108, 328, 333, 340, 341, 342, 345, 351, 352], "instead": [1, 4, 7, 8, 11, 27, 32, 56, 84, 88, 102, 108, 130, 154, 158, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 242, 245, 248, 250, 252, 255, 256, 257, 262, 263, 266, 267, 268, 269, 277, 279, 283, 287, 331, 335, 347, 349, 352], "In": [1, 2, 3, 4, 5, 7, 8, 10, 11, 17, 21, 22, 32, 52, 54, 56, 57, 58, 80, 81, 84, 88, 93, 94, 102, 103, 104, 108, 122, 123, 124, 126, 140, 145, 149, 153, 154, 156, 157, 158, 160, 162, 163, 189, 192, 193, 197, 202, 214, 218, 219, 238, 241, 247, 248, 249, 251, 252, 254, 255, 256, 262, 264, 266, 267, 268, 269, 271, 317, 329, 330, 331, 335, 336, 340, 341, 342, 343, 345, 346, 347, 348, 349, 352], "lower": [1, 2, 3, 17, 21, 25, 121, 164, 213, 214, 242, 342, 347], "io": [1, 56, 93, 94, 99, 193, 194], "footprint": [1, 2, 349], "need": [1, 2, 3, 4, 7, 8, 10, 11, 18, 19, 20, 21, 32, 34, 36, 73, 84, 88, 92, 97, 102, 103, 104, 108, 118, 121, 130, 140, 143, 155, 158, 162, 164, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 204, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 236, 237, 238, 242, 245, 247, 256, 267, 268, 269, 271, 278, 283, 298, 315, 331, 335, 336, 340, 341, 342, 343, 346, 347, 349, 351, 352], "commun": [1, 2, 3, 102, 334, 342, 352], "yet": [1, 80, 81, 93, 94, 348], "spec": [1, 2, 3, 15, 21, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 48, 49, 50, 52, 80, 81, 84, 86, 87, 88, 89, 90, 93, 94, 98, 99, 100, 102, 105, 108, 109, 110, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 132, 133, 134, 136, 138, 140, 142, 143, 144, 146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 166, 170, 174, 186, 212, 214, 223, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 241, 242, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 277, 324, 335, 340, 341, 342, 343, 345, 346, 351], "plai": [1, 3, 103, 104, 118, 341, 342, 349, 352], "role": [1, 3, 341, 352], "opposit": 1, "direct": [1, 32, 84, 88, 102, 108, 189, 193, 264, 341], "sinc": [1, 2, 3, 4, 5, 7, 32, 35, 38, 41, 42, 58, 72, 84, 88, 102, 103, 104, 105, 108, 173, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 229, 230, 231, 232, 234, 236, 237, 242, 245, 340, 341, 342, 343, 347, 348, 349, 351, 352], "faster": [1, 4, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 57, 58, 99, 279, 280, 281, 282, 343, 346], "share": [1, 3, 6, 8, 34, 36, 39, 61, 62, 63, 73, 74, 77, 85, 102, 108, 164, 191, 195, 202, 203, 224, 225, 226, 248, 250, 251, 255, 256, 262, 263, 266, 267, 268, 269, 271, 331, 333, 335, 342, 343, 345, 346, 351, 352], "among": [1, 3, 103, 104, 346], "achiev": [1, 3, 4, 32, 84, 88, 92, 102, 108, 153, 174, 312, 337, 340, 341, 342, 343, 346, 347, 352], "via": [1, 4, 7, 8, 35, 38, 41, 42, 52, 54, 55, 56, 57, 58, 88, 102, 140, 157, 162, 253, 264, 336, 337, 340, 341, 342, 343, 349, 352], "prohibit": [1, 3], "slow": [1, 3, 4, 34, 36, 39], "compar": [1, 3, 56, 311, 336, 340, 342, 346, 349, 352], "gpu": [1, 7, 8, 32, 61, 62, 77, 84, 88, 92, 102, 108, 340, 342, 343, 346, 352], "nativ": [1, 7, 9, 54, 84, 88, 102, 108, 118, 343, 349], "driver": [1, 7], "practic": [1, 3, 4, 5, 8, 192, 218, 219, 247, 334, 340, 341, 342, 343, 346, 348, 352], "mean": [1, 2, 3, 4, 7, 13, 14, 16, 18, 19, 20, 21, 34, 36, 39, 41, 64, 75, 80, 81, 88, 136, 164, 175, 184, 187, 189, 191, 193, 195, 196, 199, 217, 227, 235, 239, 279, 280, 281, 282, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 335, 336, 340, 341, 342, 346, 347, 349, 351, 352], "keyword": [1, 3, 11, 13, 14, 16, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 46, 47, 53, 54, 56, 57, 58, 59, 69, 71, 72, 74, 80, 81, 82, 83, 84, 87, 88, 89, 90, 93, 94, 99, 100, 102, 105, 108, 109, 110, 121, 122, 140, 149, 154, 156, 157, 158, 160, 162, 191, 195, 200, 201, 223, 227, 228, 229, 231, 232, 234, 235, 236, 238, 239, 242, 248, 249, 250, 251, 252, 253, 254, 255, 256, 261, 262, 263, 265, 266, 267, 268, 269, 271, 273, 277, 279, 280, 281, 282, 283, 287, 328, 340, 341, 342, 346, 349, 352], "build": [1, 3, 7, 23, 26, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 80, 81, 84, 88, 89, 90, 93, 94, 99, 102, 105, 108, 109, 110, 145, 164, 175, 191, 195, 199, 233, 235, 239, 315, 322, 323, 325, 326, 335, 337, 342, 343, 346, 347, 348, 351, 352], "given": [1, 2, 3, 13, 14, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 38, 40, 41, 42, 44, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 66, 71, 72, 84, 88, 98, 102, 108, 122, 125, 136, 140, 154, 157, 158, 160, 162, 173, 175, 186, 187, 189, 193, 199, 212, 216, 223, 229, 230, 231, 234, 237, 238, 239, 240, 241, 243, 247, 251, 252, 254, 278, 279, 280, 281, 282, 283, 285, 307, 311, 327, 335, 337, 340, 341, 342, 346, 347, 352], "mani": [1, 3, 4, 38, 80, 81, 82, 83, 84, 87, 89, 90, 93, 94, 99, 100, 105, 248, 250, 256, 263, 266, 267, 271, 335, 340, 341, 342, 346, 347, 349, 352], "eg": [1, 2, 3, 11, 34, 36, 39, 61, 62, 63, 73, 74, 77, 82, 83, 84, 87, 88, 89, 90, 92, 102, 105, 108, 125, 152, 158, 202, 228], "gymnasium": [1, 3, 5, 11, 84, 87, 88, 89, 95, 96, 102, 108, 112, 114, 128, 149, 152, 163, 341, 342, 347, 351], "other": [1, 2, 3, 4, 7, 8, 21, 22, 32, 35, 38, 41, 42, 45, 52, 54, 56, 57, 58, 61, 62, 63, 66, 69, 70, 71, 72, 73, 74, 77, 84, 87, 88, 89, 98, 102, 108, 121, 124, 125, 142, 149, 156, 160, 164, 189, 191, 195, 205, 206, 228, 230, 231, 237, 239, 248, 249, 250, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 279, 312, 324, 329, 330, 335, 337, 340, 341, 342, 343, 346, 347, 348, 349, 351, 352], "warn": [1, 3, 227, 231, 232, 234, 341], "quickli": [1, 3, 341, 346, 352], "becom": [1, 3, 4, 21, 189, 193, 346, 352], "quit": [1, 3, 102, 335, 340, 341, 342, 346, 352], "annoi": [1, 3], "By": [1, 2, 3, 33, 82, 83, 84, 87, 88, 89, 90, 102, 103, 104, 105, 108, 109, 110, 221, 239, 264, 311, 331, 340, 348, 349, 352], "filter": [1, 2, 3, 4, 45, 248, 249, 251, 255, 256, 262, 266, 267, 269], "out": [1, 2, 3, 4, 5, 9, 21, 32, 34, 36, 39, 45, 52, 56, 84, 88, 102, 103, 104, 108, 154, 166, 189, 190, 193, 200, 201, 204, 205, 223, 228, 229, 230, 234, 235, 236, 237, 238, 239, 275, 276, 337, 340, 341, 342, 343, 346, 347, 349, 351, 352], "If": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 66, 69, 70, 71, 72, 75, 77, 82, 83, 84, 85, 87, 88, 89, 90, 92, 98, 99, 100, 102, 103, 104, 105, 108, 109, 110, 112, 118, 119, 120, 121, 123, 124, 125, 126, 128, 130, 134, 135, 136, 140, 141, 144, 145, 148, 149, 153, 154, 155, 156, 157, 158, 160, 162, 164, 173, 174, 176, 177, 189, 190, 191, 193, 194, 195, 196, 197, 200, 201, 202, 203, 221, 223, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 245, 247, 248, 249, 250, 251, 252, 254, 256, 257, 258, 259, 262, 263, 264, 266, 267, 268, 269, 271, 277, 278, 279, 280, 281, 282, 283, 293, 294, 295, 296, 302, 310, 312, 315, 317, 319, 324, 327, 331, 334, 340, 341, 342, 343, 345, 346, 347, 349, 351, 352], "still": [1, 2, 3, 9, 56, 80, 81, 84, 88, 93, 94, 102, 108, 227, 263, 264, 340, 341, 343, 345, 347, 349, 352], "wish": [1, 3, 56, 114, 349], "see": [1, 3, 6, 7, 8, 9, 13, 14, 16, 17, 18, 19, 20, 21, 32, 35, 38, 41, 42, 43, 52, 53, 54, 55, 56, 57, 58, 59, 66, 71, 84, 88, 91, 99, 102, 103, 104, 105, 108, 109, 110, 122, 140, 154, 156, 157, 158, 160, 162, 165, 176, 177, 189, 192, 193, 197, 203, 204, 211, 219, 220, 224, 226, 238, 239, 312, 340, 341, 342, 343, 346, 347, 349, 352], "displai": [1, 3, 7, 315, 337, 340, 341, 346, 347], "filter_warnings_subprocess": [1, 3], "fals": [1, 3, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 66, 69, 70, 71, 72, 77, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 118, 119, 122, 123, 126, 127, 128, 130, 133, 134, 135, 136, 138, 140, 141, 142, 143, 145, 147, 149, 152, 154, 156, 157, 158, 159, 160, 162, 164, 166, 173, 174, 175, 176, 177, 179, 186, 189, 190, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 211, 212, 218, 219, 220, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 241, 242, 243, 248, 249, 250, 251, 252, 254, 255, 256, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 271, 274, 277, 279, 280, 281, 282, 288, 289, 290, 291, 293, 294, 295, 296, 308, 309, 311, 312, 313, 315, 324, 331, 335, 337, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "central": [2, 202, 340, 341, 346, 349], "part": [2, 4, 8, 32, 40, 53, 54, 56, 57, 58, 80, 84, 88, 93, 102, 108, 117, 136, 145, 148, 191, 195, 243, 306, 331, 340, 342, 343, 347, 352], "algorithm": [2, 3, 8, 9, 13, 14, 98, 131, 248, 266, 267, 268, 269, 306, 320, 333, 336, 337, 340, 341, 342, 343, 346, 348, 349, 351], "implement": [2, 3, 9, 11, 16, 32, 73, 84, 88, 99, 102, 108, 122, 123, 124, 128, 134, 142, 143, 149, 152, 157, 164, 176, 189, 190, 191, 192, 193, 194, 195, 217, 218, 219, 248, 249, 253, 254, 255, 262, 264, 265, 266, 269, 324, 335, 337, 340, 341, 342, 343, 347, 351], "wide": [2, 3, 5], "we": [2, 3, 5, 7, 9, 11, 26, 32, 34, 36, 39, 40, 42, 52, 56, 58, 70, 72, 80, 81, 84, 85, 88, 92, 93, 94, 102, 108, 118, 134, 140, 143, 160, 163, 164, 175, 195, 196, 202, 203, 248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 334, 335, 336, 337, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "give": [2, 3, 7, 41, 53, 84, 88, 98, 102, 108, 118, 334, 336, 340, 341, 346, 347, 348, 351], "abil": [2, 264, 347, 349], "veri": [2, 3, 93, 94, 341, 347, 349, 351, 352], "influenti": 2, "sampl": [2, 4, 8, 9, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 38, 40, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 64, 65, 66, 69, 70, 71, 72, 74, 75, 77, 84, 88, 98, 101, 102, 108, 117, 118, 141, 145, 167, 168, 171, 172, 175, 184, 192, 199, 200, 201, 209, 210, 213, 218, 219, 223, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 248, 249, 250, 251, 252, 254, 263, 265, 266, 271, 306, 312, 315, 318, 335, 340, 341, 342, 343, 346, 348, 351, 352], "latenc": 2, "especi": [2, 3, 7, 8, 119], "larger": [2, 4, 255, 262], "volum": 2, "lazymemmapstorag": [2, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 71, 72, 117, 118, 333, 340, 341, 343, 348, 349], "advis": [2, 53, 352], "due": [2, 3, 5, 348, 349, 352], "serialis": [2, 34, 36, 39], "memmaptensor": 2, "well": [2, 3, 8, 17, 21, 32, 35, 37, 38, 41, 42, 69, 73, 84, 88, 102, 108, 193, 213, 214, 264, 283, 340, 341, 343, 348, 349, 351, 352], "specifi": [2, 11, 13, 14, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 57, 58, 66, 84, 88, 102, 103, 104, 108, 109, 110, 123, 124, 126, 148, 151, 153, 159, 175, 193, 238, 239, 264, 270, 335, 340, 342, 343], "file": [2, 6, 7, 8, 34, 36, 39, 52, 53, 54, 56, 57, 58, 109, 297, 337, 339, 341, 349, 350], "locat": [2, 7, 34, 36, 39, 45, 58, 84, 88, 102, 108, 127, 136, 147, 192, 206, 218, 219, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 317, 340, 341, 342, 346, 349], "improv": [2, 4, 131, 248, 336, 346, 349], "failur": [2, 4], "recoveri": 2, "liststorag": [2, 35, 38, 41, 42, 333, 349], "were": [2, 7, 102, 108, 342, 349], "found": [2, 3, 6, 7, 10, 21, 26, 32, 34, 36, 39, 45, 52, 53, 54, 56, 57, 58, 71, 72, 82, 83, 84, 87, 88, 89, 92, 102, 108, 115, 118, 145, 148, 155, 164, 174, 231, 232, 235, 239, 263, 264, 266, 340, 341, 343], "rough": 2, "benchmark": [2, 3, 9, 81, 93, 94, 346], "http": [2, 5, 6, 7, 10, 18, 19, 20, 35, 43, 53, 55, 56, 57, 58, 64, 80, 81, 82, 83, 90, 92, 93, 94, 99, 100, 101, 103, 104, 105, 109, 110, 118, 140, 160, 178, 179, 180, 181, 182, 183, 186, 187, 188, 193, 199, 200, 201, 205, 207, 208, 210, 211, 213, 214, 220, 230, 234, 248, 249, 252, 253, 254, 255, 257, 258, 259, 260, 261, 262, 265, 266, 267, 268, 269, 270, 279, 284, 292, 324, 348, 351], "github": [2, 5, 6, 7, 10, 18, 19, 20, 53, 54, 56, 80, 81, 82, 83, 90, 93, 94, 99, 100, 103, 104, 105, 109, 110, 160, 351], "com": [2, 5, 6, 7, 10, 18, 19, 20, 53, 56, 57, 80, 81, 82, 83, 90, 92, 93, 94, 99, 100, 103, 104, 105, 109, 110, 348, 351], "tree": [2, 34, 36, 39, 84, 88, 102, 108], "type": [2, 3, 14, 18, 19, 20, 21, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 58, 59, 66, 84, 88, 97, 98, 101, 102, 103, 104, 108, 122, 123, 124, 127, 128, 134, 140, 142, 143, 149, 152, 154, 157, 158, 160, 162, 164, 168, 172, 176, 177, 197, 202, 203, 205, 211, 220, 227, 229, 235, 238, 239, 248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 273, 277, 285, 324, 329, 335, 340, 341, 342, 346, 347, 349, 352], "1x": 2, "lazytensorstorag": [2, 41, 42, 75, 145, 333, 342, 346, 349], "83x": 2, "3": [2, 3, 6, 7, 10, 11, 13, 14, 15, 16, 17, 21, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 71, 72, 82, 83, 84, 87, 88, 89, 90, 91, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108, 115, 118, 122, 125, 127, 128, 134, 136, 138, 140, 142, 143, 145, 148, 149, 152, 153, 154, 156, 157, 158, 160, 162, 170, 175, 176, 177, 179, 180, 183, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 199, 202, 203, 206, 209, 211, 221, 223, 224, 225, 226, 229, 230, 235, 237, 238, 241, 242, 243, 248, 249, 251, 252, 254, 255, 256, 257, 258, 259, 262, 264, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 285, 288, 289, 290, 291, 293, 294, 295, 296, 298, 314, 335, 337, 339, 340, 341, 342, 343, 346, 347, 348, 349, 350, 351, 352], "44x": 2, "between": [2, 3, 4, 5, 13, 14, 16, 17, 21, 32, 40, 56, 70, 72, 84, 88, 102, 108, 109, 110, 125, 135, 146, 158, 166, 176, 177, 189, 191, 195, 197, 202, 203, 230, 235, 239, 248, 250, 251, 254, 255, 256, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 274, 279, 311, 315, 336, 340, 341, 343, 346, 347, 352], "long": [2, 3, 13, 14, 16, 17, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 39, 44, 46, 47, 125, 193, 194, 343, 349], "sharabl": 2, "featur": [2, 3, 4, 13, 14, 16, 17, 18, 19, 20, 21, 33, 45, 54, 71, 72, 84, 88, 97, 102, 103, 104, 106, 107, 108, 118, 130, 134, 138, 154, 155, 159, 164, 176, 177, 187, 188, 189, 190, 191, 193, 194, 195, 197, 204, 205, 239, 279, 280, 281, 282, 283, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 331, 335, 340, 341, 342, 343, 347, 349, 352], "allow": [2, 3, 13, 14, 16, 17, 18, 19, 20, 21, 26, 28, 29, 32, 33, 56, 66, 69, 71, 72, 80, 81, 84, 88, 93, 94, 102, 108, 143, 173, 197, 248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 272, 274, 277, 335, 337, 340, 342, 343, 346, 347, 349, 352], "popul": [2, 3, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 133, 154, 340, 342, 343, 347, 349], "collabor": [2, 56], "rather": [2, 4, 74, 143, 340, 341, 342, 346], "incur": [2, 80, 81, 93, 94], "some": [2, 3, 4, 7, 8, 9, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 38, 44, 45, 46, 47, 52, 54, 56, 57, 58, 61, 62, 66, 75, 77, 80, 81, 84, 88, 93, 94, 102, 103, 104, 108, 109, 110, 140, 158, 160, 166, 179, 191, 195, 216, 239, 240, 241, 306, 318, 335, 337, 340, 341, 342, 343, 346, 347, 349, 351, 352], "transmiss": 2, "overhead": [2, 80, 81, 93, 94, 102, 108], "includ": [2, 3, 4, 7, 9, 21, 32, 58, 61, 62, 63, 73, 74, 77, 84, 88, 98, 102, 108, 153, 158, 164, 264, 269, 318, 335, 337, 340, 341, 342, 343, 346, 347, 349, 352], "ani": [2, 3, 5, 8, 26, 28, 32, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 66, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 84, 85, 88, 99, 102, 103, 104, 108, 109, 110, 115, 130, 140, 141, 145, 158, 160, 164, 166, 174, 176, 177, 183, 197, 205, 228, 238, 239, 240, 241, 248, 249, 251, 252, 254, 255, 256, 262, 264, 266, 267, 268, 269, 271, 279, 303, 315, 334, 340, 341, 342, 346, 347, 349, 351, 352], "subclass": [2, 3, 66, 84, 88, 102, 108, 157, 163, 166, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 238, 239, 240, 242, 245, 264, 266, 341, 343, 347, 349], "tensorstorag": [2, 333], "instanti": [2, 3, 21, 34, 36, 39, 92, 157, 203, 340, 341, 346, 347, 349, 352], "content": [2, 8, 13, 14, 16, 26, 28, 34, 35, 36, 38, 39, 41, 42, 70, 84, 87, 88, 89, 99, 102, 108, 142, 176, 177, 197, 202, 203, 235, 264, 342, 347, 351], "map": [2, 3, 8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 61, 84, 88, 97, 102, 103, 104, 106, 107, 108, 109, 110, 111, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 132, 133, 134, 136, 138, 142, 143, 144, 146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 159, 160, 161, 163, 164, 170, 186, 206, 223, 224, 225, 226, 229, 235, 236, 238, 239, 241, 242, 243, 244, 269, 277, 311, 333, 335, 336, 340, 341, 342, 343, 348], "tensor": [2, 3, 8, 13, 14, 16, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 69, 71, 72, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 93, 94, 97, 98, 101, 102, 103, 104, 106, 107, 108, 109, 110, 115, 117, 118, 119, 122, 123, 125, 126, 127, 128, 130, 133, 136, 138, 140, 141, 142, 143, 145, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 164, 170, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 209, 210, 211, 212, 215, 216, 217, 218, 219, 220, 223, 224, 225, 226, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 241, 242, 243, 245, 246, 248, 249, 251, 252, 254, 255, 256, 259, 260, 262, 264, 266, 267, 268, 269, 271, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 298, 324, 335, 337, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "writer": [2, 38, 42, 52, 53, 54, 55, 56, 57, 58, 60, 66, 67, 75, 76, 79, 333, 342], "tensordictroundrobinwrit": [2, 66, 333], "current": [2, 3, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 44, 46, 47, 72, 84, 88, 90, 99, 102, 108, 118, 141, 153, 154, 155, 157, 158, 167, 168, 173, 187, 196, 214, 234, 257, 269, 301, 337, 340, 341, 342, 343, 346, 347, 351, 352], "goe": [2, 4, 103, 104, 340, 342, 346, 352], "sampler": [2, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 73, 74, 75, 77, 141, 252, 257, 277, 333, 340, 342, 346, 349], "prioritizedsampl": [2, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 252, 257, 277, 333, 340, 349], "extend": [2, 8, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 38, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 57, 58, 60, 66, 67, 71, 72, 74, 75, 76, 78, 79, 117, 145, 312, 337, 340, 341, 342, 343, 346, 348, 349, 351], "access": [2, 3, 7, 8, 32, 35, 53, 55, 84, 88, 102, 108, 140, 160, 331, 334, 340, 346, 347, 349], "show": [2, 32, 84, 88, 102, 108, 203, 335, 340, 342, 343, 346, 347, 349, 351], "import": [2, 3, 4, 6, 10, 11, 13, 14, 15, 16, 17, 21, 22, 35, 37, 38, 40, 41, 42, 43, 45, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 64, 66, 71, 72, 75, 77, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 96, 98, 100, 102, 103, 104, 105, 106, 107, 108, 111, 112, 114, 115, 117, 118, 121, 127, 128, 133, 134, 136, 138, 140, 142, 143, 144, 145, 148, 149, 150, 152, 153, 154, 155, 157, 162, 164, 170, 173, 174, 175, 186, 189, 190, 191, 193, 194, 195, 197, 199, 202, 203, 206, 211, 212, 220, 223, 224, 225, 226, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 241, 242, 243, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 308, 311, 324, 327, 335, 336, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "tensordictreplaybuff": [2, 35, 38, 41, 52, 53, 54, 55, 56, 57, 58, 66, 71, 72, 75, 117, 118, 312, 327, 333, 340, 341, 343, 349], "mp": [2, 18, 19, 20, 85, 164], "def": [2, 3, 11, 22, 32, 84, 85, 88, 98, 102, 108, 114, 115, 123, 126, 142, 175, 186, 189, 190, 193, 194, 199, 235, 243, 249, 251, 255, 256, 262, 264, 267, 269, 271, 337, 340, 341, 345, 346, 347, 351, 352], "rb": [2, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 71, 72, 75, 118, 145, 341, 343, 346, 348, 349, 351], "updat": [2, 3, 4, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 35, 36, 39, 40, 41, 64, 84, 88, 98, 102, 103, 104, 108, 115, 123, 125, 126, 142, 152, 153, 158, 161, 164, 174, 175, 189, 191, 195, 199, 227, 231, 232, 234, 235, 236, 237, 238, 239, 248, 249, 251, 252, 254, 256, 257, 258, 261, 262, 264, 266, 267, 268, 269, 270, 271, 277, 279, 280, 281, 282, 283, 311, 315, 317, 320, 321, 326, 327, 337, 341, 342, 343, 346, 347, 349, 351, 352], "td": [2, 3, 15, 26, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 75, 80, 81, 82, 83, 84, 87, 88, 89, 93, 94, 95, 96, 102, 108, 115, 117, 119, 123, 124, 125, 126, 133, 134, 136, 145, 148, 154, 156, 158, 164, 173, 175, 186, 191, 195, 198, 199, 211, 212, 220, 223, 224, 225, 226, 228, 229, 231, 232, 234, 235, 236, 238, 241, 243, 277, 280, 281, 282, 286, 287, 288, 289, 290, 291, 293, 294, 295, 296, 297, 306, 314, 324, 335, 336, 340, 343, 346, 347, 351, 352], "10": [2, 7, 22, 26, 35, 38, 40, 41, 42, 43, 45, 61, 62, 66, 71, 72, 75, 77, 80, 81, 84, 85, 88, 93, 94, 98, 102, 103, 104, 106, 107, 108, 109, 110, 115, 117, 118, 153, 155, 156, 175, 178, 183, 189, 190, 193, 194, 196, 199, 210, 221, 231, 232, 234, 235, 242, 249, 252, 254, 256, 266, 267, 268, 271, 277, 279, 280, 281, 282, 285, 306, 337, 340, 341, 342, 343, 346, 347, 349, 351, 352], "__name__": [2, 22, 85, 341], "__main__": [2, 22, 85], "21": [2, 56, 57, 72, 103, 104, 340, 341, 345, 347], "zero": [2, 3, 4, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 41, 42, 44, 45, 46, 47, 52, 62, 71, 72, 77, 84, 88, 102, 108, 117, 119, 123, 125, 126, 136, 142, 145, 170, 173, 175, 189, 190, 191, 193, 194, 195, 196, 200, 201, 203, 211, 220, 231, 232, 234, 237, 245, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 285, 343, 351], "proc": 2, "target": [2, 4, 8, 21, 32, 84, 85, 88, 102, 108, 153, 157, 238, 239, 248, 249, 250, 251, 252, 254, 256, 257, 260, 261, 263, 264, 265, 266, 267, 268, 269, 270, 271, 277, 278, 279, 280, 281, 282, 283, 318, 326, 327, 336, 337, 343, 347], "arg": [2, 12, 14, 26, 28, 32, 61, 62, 77, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 113, 115, 122, 140, 142, 151, 154, 157, 158, 159, 161, 162, 175, 176, 177, 185, 191, 195, 197, 198, 199, 221, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 283, 305, 308, 312, 315, 331, 341], "start": [2, 3, 4, 5, 13, 21, 45, 58, 71, 72, 85, 97, 173, 310, 340, 341, 346, 347, 349, 352], "join": [2, 85, 333, 341, 342], "now": [2, 3, 7, 35, 102, 118, 203, 340, 341, 342, 343, 345, 346, 348, 349, 352], "length": [2, 17, 20, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 40, 43, 44, 45, 46, 47, 56, 59, 71, 72, 74, 84, 88, 93, 94, 102, 108, 141, 164, 175, 176, 177, 179, 181, 183, 185, 189, 193, 197, 199, 202, 203, 223, 238, 243, 306, 312, 340, 342, 343, 347, 349, 352], "20": [2, 45, 57, 71, 72, 75, 84, 88, 92, 102, 108, 153, 189, 190, 193, 194, 228, 306, 341, 342, 343, 346, 347, 351, 352], "assert": [2, 3, 6, 16, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 38, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 57, 58, 66, 88, 91, 114, 118, 121, 123, 126, 134, 143, 150, 164, 166, 170, 203, 206, 221, 279, 280, 281, 282, 306, 314, 345, 349, 352], "len": [2, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 61, 62, 66, 77, 138, 176, 177, 197, 203, 340, 347, 348, 349, 351], "_data": [2, 347], "0": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 21, 22, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 49, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 64, 66, 71, 72, 77, 80, 81, 84, 87, 88, 90, 91, 93, 94, 98, 99, 100, 102, 105, 106, 107, 108, 115, 116, 118, 119, 121, 122, 124, 125, 134, 135, 136, 140, 145, 148, 150, 153, 154, 155, 156, 157, 158, 160, 162, 163, 164, 166, 175, 176, 177, 179, 180, 182, 183, 187, 189, 191, 192, 193, 194, 195, 197, 199, 201, 202, 203, 204, 205, 206, 209, 213, 214, 217, 218, 219, 221, 223, 227, 228, 230, 231, 232, 234, 237, 238, 241, 242, 245, 248, 249, 250, 251, 252, 254, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 277, 278, 279, 280, 281, 282, 285, 286, 287, 306, 313, 327, 331, 336, 337, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352], "too": [2, 7, 13, 14, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 39, 40, 44, 46, 47, 84, 88, 102, 108, 135, 154, 192, 218, 219, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 341, 342, 347, 349, 352], "difficult": [2, 4, 102], "element": [2, 13, 14, 16, 18, 19, 20, 21, 30, 31, 33, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 64, 66, 72, 75, 77, 101, 118, 141, 150, 153, 176, 177, 189, 190, 193, 223, 227, 229, 238, 239, 243, 306, 340, 342, 349, 352], "pai": [2, 8, 340, 343], "attent": [2, 8, 340, 343, 352], "alwai": [2, 3, 20, 26, 28, 32, 59, 84, 88, 102, 108, 134, 135, 257, 264, 335, 336, 341, 342, 343, 346, 347, 349], "lead": [2, 3, 4, 8, 10, 11, 26, 28, 32, 34, 35, 36, 38, 39, 41, 42, 52, 70, 82, 83, 87, 89, 90, 154, 192, 211, 218, 219, 340, 343, 346, 347, 349, 351], "dimens": [2, 3, 16, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 40, 44, 45, 46, 47, 52, 54, 56, 57, 58, 61, 62, 71, 72, 75, 77, 82, 83, 84, 87, 88, 89, 90, 102, 108, 109, 110, 117, 118, 119, 130, 136, 138, 141, 148, 151, 156, 159, 164, 176, 177, 178, 183, 191, 193, 195, 197, 200, 201, 202, 204, 205, 210, 211, 215, 216, 217, 218, 221, 229, 248, 249, 250, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 331, 335, 340, 341, 342, 343, 346, 347, 349], "word": [2, 3, 40, 52, 54, 56, 57, 58, 264, 340, 347, 352], "creat": [2, 3, 4, 5, 6, 7, 10, 13, 14, 16, 17, 18, 19, 20, 21, 26, 28, 32, 34, 35, 36, 38, 39, 41, 42, 45, 56, 58, 59, 84, 85, 88, 92, 102, 103, 108, 109, 110, 118, 140, 157, 158, 160, 163, 164, 170, 173, 176, 177, 179, 180, 181, 182, 183, 188, 191, 195, 197, 198, 202, 203, 228, 239, 252, 257, 267, 269, 277, 298, 312, 319, 320, 321, 327, 329, 330, 335, 340, 341, 342, 343, 346, 347, 348, 349, 351, 352], "1m": [2, 56, 318, 340, 342, 343], "multidimension": [2, 41, 64, 349], "doe": [2, 3, 18, 34, 35, 36, 39, 41, 45, 52, 56, 64, 73, 74, 79, 84, 88, 102, 108, 109, 110, 183, 189, 190, 191, 193, 194, 195, 204, 221, 228, 240, 241, 248, 250, 257, 263, 266, 278, 315, 335, 337, 340, 341, 342, 343, 347, 349, 352], "howev": [2, 3, 5, 7, 32, 84, 88, 102, 108, 118, 148, 153, 158, 269, 335, 340, 341, 342, 343, 347, 349, 352], "episod": [2, 52, 56, 57, 58, 71, 72, 84, 88, 102, 108, 145, 148, 153, 175, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 341, 346], "flatten": [2, 34, 36, 39, 130, 312, 343, 346], "capac": [2, 342], "desir": [2, 3, 32, 84, 88, 102, 108, 122, 136, 138, 140, 141, 154, 157, 158, 160, 162, 171, 172, 176, 177, 197, 203, 223, 229, 230, 235, 236, 237, 238, 239, 335, 340, 346, 347], "diversifi": 2, "make": [2, 3, 4, 7, 32, 34, 36, 39, 40, 52, 54, 55, 56, 57, 58, 69, 73, 74, 79, 84, 88, 89, 92, 94, 96, 100, 102, 108, 128, 136, 140, 141, 145, 152, 160, 166, 189, 190, 193, 194, 202, 203, 204, 229, 239, 266, 279, 280, 281, 282, 312, 321, 331, 335, 336, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "offer": [2, 3, 7, 80, 81, 84, 88, 93, 94, 102, 108, 335, 341, 347, 352], "distinct": [2, 3, 66, 345], "accomplish": 2, "slicesampl": [2, 333], "slice": [2, 3, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 52, 56, 71, 72, 117], "anoth": [2, 3, 8, 34, 36, 39, 56, 84, 87, 88, 89, 92, 102, 108, 123, 124, 126, 154, 157, 197, 248, 249, 250, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 317, 335, 336, 340, 342, 343, 345, 346, 347, 352], "recommend": [2, 4, 7, 34, 36, 39, 92, 346], "__especially__": 2, "offlin": [2, 8, 13, 14, 16, 17, 18, 19, 20, 21, 53, 118, 166, 249, 254, 255, 262, 337, 348, 349, 351], "convent": [2, 3, 84, 88, 102, 108, 109, 110, 336, 340, 343, 346, 347], "requir": [2, 3, 4, 7, 8, 16, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 41, 42, 44, 45, 46, 47, 52, 54, 56, 84, 88, 92, 99, 102, 105, 108, 122, 140, 154, 157, 158, 160, 162, 197, 221, 238, 240, 241, 248, 249, 250, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 335, 337, 340, 341, 342, 343, 346, 347, 349, 352], "reshap": [2, 32, 56, 71, 191, 195, 197, 342, 346], "extens": [2, 72, 337, 349], "detail": [2, 3, 5, 6, 7, 32, 84, 88, 102, 103, 104, 108, 156, 158, 186, 189, 193, 230, 248, 257, 266, 334, 341, 345, 349], "independ": [2, 13, 14, 16, 17, 18, 19, 20, 21, 53, 157, 159, 203, 336, 337, 340, 341, 346, 349, 351], "differ": [2, 3, 4, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 40, 44, 45, 46, 47, 52, 53, 56, 69, 80, 81, 84, 88, 93, 94, 97, 102, 103, 104, 108, 118, 125, 136, 143, 158, 159, 186, 189, 190, 191, 193, 194, 195, 197, 199, 202, 203, 212, 262, 266, 274, 279, 280, 281, 285, 286, 287, 311, 315, 317, 329, 330, 335, 336, 337, 340, 341, 342, 345, 346, 347, 348, 349, 352], "congruent": 2, "shape": [2, 3, 13, 14, 16, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 52, 54, 56, 57, 58, 59, 61, 62, 66, 77, 82, 83, 84, 87, 88, 89, 93, 94, 97, 101, 102, 103, 104, 106, 107, 108, 109, 110, 117, 119, 123, 126, 127, 128, 134, 136, 138, 142, 143, 145, 149, 152, 154, 156, 164, 165, 166, 170, 173, 175, 178, 183, 184, 185, 189, 190, 191, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 206, 209, 210, 211, 212, 217, 220, 223, 224, 225, 226, 228, 229, 230, 235, 236, 237, 238, 241, 242, 243, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 274, 277, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 298, 306, 312, 315, 327, 335, 340, 341, 342, 343, 345, 346, 348, 349, 351, 352], "custom": [2, 3, 5, 32, 84, 88, 102, 108, 160, 202, 203, 242, 257, 266, 272, 331, 335, 340, 341, 342, 343, 346], "name": [2, 3, 6, 7, 11, 16, 32, 34, 36, 39, 45, 53, 55, 58, 59, 80, 82, 84, 88, 93, 97, 99, 102, 103, 104, 105, 108, 109, 110, 111, 125, 128, 143, 148, 149, 152, 158, 160, 163, 174, 191, 195, 229, 236, 248, 249, 250, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 283, 300, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 317, 324, 337, 340, 341, 342, 343, 346, 347, 352], "randomcroptensordict": [2, 340], "note": [2, 3, 4, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 35, 36, 38, 39, 41, 42, 84, 88, 102, 108, 123, 126, 164, 174, 189, 191, 193, 195, 234, 235, 239, 257, 340, 341, 345, 346, 352], "unlik": [2, 70, 109, 110, 257, 266, 341, 351], "base": [2, 3, 4, 8, 9, 12, 13, 14, 16, 17, 18, 19, 20, 21, 35, 38, 41, 42, 45, 56, 68, 75, 76, 78, 80, 81, 84, 88, 92, 93, 94, 98, 99, 100, 102, 108, 109, 145, 154, 160, 161, 202, 224, 233, 248, 249, 251, 252, 254, 255, 256, 258, 262, 266, 267, 268, 269, 271, 315, 324, 335, 336, 337, 340, 341, 343, 346, 347, 349, 352], "here": [2, 3, 4, 7, 8, 9, 10, 57, 58, 82, 83, 84, 88, 92, 102, 103, 104, 108, 118, 335, 336, 340, 341, 342, 343, 346, 347, 349, 351, 352], "stop": [2, 3, 16, 21, 40, 58, 71, 72, 84, 88, 102, 108, 342, 346, 351, 352], "signal": [2, 3, 17, 52, 54, 56, 57, 58, 71, 72, 88, 109, 110, 118, 127, 152, 155, 174, 336, 340, 342, 346, 349, 352], "isn": [2, 3, 8, 34, 36, 39, 56, 127, 229, 238, 346], "t": [2, 3, 4, 6, 7, 8, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 44, 46, 47, 56, 64, 70, 84, 85, 87, 88, 99, 100, 102, 108, 118, 123, 126, 127, 140, 144, 145, 153, 155, 162, 164, 173, 189, 193, 229, 234, 238, 270, 279, 280, 281, 282, 283, 285, 315, 317, 331, 334, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "how": [2, 3, 18, 19, 20, 32, 35, 41, 56, 64, 80, 81, 82, 83, 84, 87, 88, 89, 90, 93, 94, 99, 100, 102, 103, 104, 105, 108, 109, 110, 248, 250, 261, 263, 266, 315, 334, 335, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "our": [2, 3, 7, 8, 18, 118, 335, 340, 341, 342, 343, 345, 346, 348, 349, 351], "enjoi": [2, 3, 56], "separ": [2, 4, 8, 13, 14, 17, 18, 20, 21, 23, 53, 140, 162, 249, 251, 254, 256, 267, 269, 271, 340, 341, 346, 349, 352], "save": [2, 8, 32, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 84, 88, 102, 108, 163, 297, 315, 337, 346], "disk": [2, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 315, 337, 340, 341, 343, 349], "dump": [2, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 297], "load": [2, 6, 7, 13, 14, 16, 17, 32, 34, 35, 36, 38, 39, 40, 41, 42, 45, 52, 53, 54, 55, 56, 57, 58, 66, 83, 84, 88, 102, 108, 114, 164, 331, 337, 340, 349], "json": 2, "metadata": [2, 52, 342, 346, 352], "cannot": [2, 3, 4, 7, 22, 26, 27, 28, 31, 33, 71, 72, 84, 87, 88, 89, 92, 102, 108, 123, 126, 141, 148, 236, 341, 342, 343, 346, 347], "anticip": [2, 123, 126], "compli": [2, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 56], "structur": [2, 3, 7, 34, 35, 36, 38, 39, 40, 41, 42, 45, 75, 84, 88, 102, 108, 123, 126, 174, 202, 234, 279, 280, 281, 282, 283, 336, 340, 342, 343, 346, 347, 348, 349], "guarante": [2, 32, 34, 36, 39, 61, 62, 63, 73, 74, 77, 84, 88, 102, 108, 164, 351], "back": [2, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 44, 46, 47, 52, 163, 223, 229, 230, 235, 236, 237, 238, 239, 342, 346, 347, 349], "exact": [2, 3, 102, 193], "look": [2, 3, 5, 7, 8, 32, 84, 88, 97, 102, 103, 104, 108, 140, 141, 160, 235, 239, 240, 241, 336, 342, 343, 346, 347, 348, 349, 351, 352], "statu": [2, 3], "its": [2, 3, 4, 5, 7, 9, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 41, 44, 46, 47, 49, 66, 84, 88, 98, 102, 103, 104, 108, 109, 111, 117, 118, 127, 134, 152, 153, 157, 158, 163, 164, 176, 177, 200, 201, 202, 203, 227, 229, 235, 236, 239, 242, 248, 249, 250, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 271, 277, 315, 327, 337, 340, 341, 342, 343, 346, 347, 348, 349, 352], "prioriti": [2, 4, 35, 41, 42, 61, 62, 63, 64, 73, 74, 77, 251, 252, 254, 255, 256, 257, 262, 267, 269, 271, 277, 337, 340, 341, 349], "max": [2, 23, 33, 36, 41, 45, 59, 64, 75, 125, 155, 217, 218, 219, 228, 234, 249, 250, 256, 265, 267, 269, 340, 342, 343, 346], "heap": 2, "under": [2, 3, 4, 21, 32, 40, 52, 53, 54, 56, 57, 58, 82, 83, 84, 87, 88, 89, 90, 102, 105, 108, 223, 229, 230, 235, 236, 237, 238, 239, 264, 279, 280, 281, 282, 283, 336, 340, 341, 347, 352], "hood": [2, 21, 347], "just": [2, 3, 4, 11, 74, 80, 81, 82, 83, 84, 87, 88, 89, 90, 93, 94, 97, 99, 100, 102, 103, 104, 105, 108, 121, 174, 203, 306, 335, 337, 340, 341, 342, 343, 346, 347, 349, 351, 352], "public": [2, 55, 140, 162], "method": [2, 3, 4, 11, 13, 14, 15, 16, 17, 21, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 66, 71, 72, 73, 74, 75, 77, 84, 87, 88, 89, 90, 102, 105, 108, 118, 122, 123, 124, 127, 128, 130, 134, 136, 140, 142, 143, 144, 145, 149, 152, 154, 157, 158, 160, 162, 175, 196, 223, 224, 225, 226, 228, 229, 230, 231, 233, 235, 236, 237, 238, 239, 240, 248, 249, 251, 252, 254, 255, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 283, 297, 328, 336, 337, 338, 341, 342, 343, 347, 349, 352], "don": [2, 3, 4, 6, 7, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 118, 341, 342, 349, 351, 352], "assum": [2, 3, 6, 26, 33, 40, 41, 42, 52, 54, 56, 57, 58, 88, 102, 108, 117, 120, 130, 140, 141, 148, 154, 160, 162, 170, 191, 195, 196, 221, 242, 252, 257, 269, 277, 288, 289, 290, 291, 293, 294, 295, 296, 298, 340, 342, 343, 345, 347], "serializ": 2, "altern": [2, 4, 27, 99, 183, 200, 201, 202, 247, 340, 342, 346], "state_dict": [2, 13, 14, 16, 17, 21, 32, 34, 36, 39, 84, 88, 102, 108, 158, 164, 269, 331, 337, 340, 341, 352], "load_state_dict": [2, 13, 14, 16, 17, 21, 32, 34, 36, 39, 84, 88, 102, 108, 158, 164, 269, 337, 340], "drawback": 2, "struggl": 2, "big": [2, 342, 349, 352], "wrapper": [2, 3, 11, 15, 17, 34, 36, 39, 40, 41, 42, 80, 81, 82, 83, 84, 87, 88, 89, 90, 92, 93, 94, 95, 96, 98, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 163, 206, 221, 227, 228, 232, 234, 239, 244, 279, 303, 304, 305, 331, 333, 342, 343, 346, 348, 352], "around": [2, 5, 7, 15, 17, 41, 42, 98, 239, 279, 340, 341, 346, 352], "present": [2, 3, 32, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 57, 58, 64, 66, 70, 84, 87, 88, 102, 108, 128, 145, 149, 173, 174, 178, 179, 180, 181, 182, 188, 193, 205, 210, 234, 238, 239, 240, 241, 248, 249, 250, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 283, 331, 337, 340, 345, 346, 349, 351], "replaybuff": [2, 41, 42, 66, 78, 118, 141, 145, 252, 257, 277, 325, 327, 333, 342, 346, 348, 349, 351], "entri": [2, 3, 13, 14, 18, 19, 20, 21, 23, 26, 28, 32, 34, 36, 37, 39, 45, 49, 52, 53, 54, 55, 57, 58, 71, 72, 82, 83, 84, 87, 88, 89, 90, 102, 105, 108, 109, 110, 118, 120, 121, 123, 126, 127, 130, 133, 136, 138, 140, 143, 145, 148, 150, 152, 153, 154, 162, 164, 173, 174, 191, 200, 201, 228, 229, 236, 237, 249, 269, 279, 280, 281, 282, 335, 340, 342, 343, 346, 347, 348, 349, 352], "selecttransform": [2, 84, 88, 102, 108], "excludetransform": [2, 57, 149, 349], "promptli": 2, "virtual": [2, 3, 87], "instal": [2, 3, 5, 10, 18, 19, 20, 52, 55, 84, 88, 102, 103, 104, 106, 107, 108, 315, 334, 342, 343, 346, 352], "respons": [2, 3, 8, 315, 352], "d4rl": [2, 52, 54, 56, 57, 58], "clone": [2, 4, 8, 26, 28, 134, 142, 224, 225, 226, 238, 255, 262, 324, 333, 340, 347, 351], "repositori": [2, 7, 53, 54, 55, 58, 110], "latest": [2, 3, 10, 99, 103, 104, 312, 342, 346, 347, 351], "wheel": [2, 342], "publish": 2, "pypi": [2, 351], "openml": [2, 55, 101], "scikit": [2, 55, 101], "panda": [2, 55], "customari": [2, 335], "time": [2, 3, 4, 7, 8, 13, 14, 16, 17, 18, 20, 21, 32, 35, 38, 40, 41, 42, 53, 56, 57, 80, 81, 84, 85, 88, 93, 94, 97, 101, 102, 103, 104, 105, 108, 114, 117, 119, 141, 148, 154, 155, 164, 173, 187, 189, 193, 195, 196, 234, 250, 256, 259, 263, 264, 266, 267, 271, 279, 280, 281, 282, 283, 284, 285, 288, 289, 290, 291, 292, 293, 294, 295, 296, 315, 335, 336, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "moreov": [2, 3], "fine": [2, 84, 88, 102, 108, 134, 348], "grain": [2, 84, 88, 102, 108], "nomenclatur": 2, "compact": 2, "togeth": [2, 3, 13, 14, 16, 17, 18, 19, 20, 21, 28, 29, 40, 84, 88, 97, 102, 103, 104, 108, 118, 141, 189, 191, 193, 195, 220, 224, 225, 226, 244, 335, 341, 342, 343], "propos": [2, 118, 127, 198, 261, 270, 324, 335, 343, 349], "replaybufferensembl": [2, 69, 74, 79], "primit": [2, 3, 4, 56, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271], "onc": [2, 3, 7, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 36, 39, 56, 66, 84, 88, 102, 108, 145, 158, 227, 232, 234, 313, 337, 341, 342, 343, 347, 349, 352], "individu": [2, 4, 18, 19, 20, 21, 32, 45, 66, 84, 88, 102, 108, 340, 346], "format": [2, 17, 31, 32, 33, 56, 57, 58, 69, 84, 88, 102, 103, 108, 122, 140, 154, 157, 158, 160, 162, 238, 340, 341, 352], "dummi": [2, 324, 340, 352], "semant": [2, 28, 29, 335], "ident": [2, 3, 13, 14, 16, 32, 34, 36, 39, 99, 102, 108, 127, 202, 203, 279, 280, 281, 282, 329, 330, 341, 346], "another_kei": [2, 66], "renam": [2, 34, 36, 39, 66, 143, 145, 173, 340], "match": [2, 3, 6, 8, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 57, 58, 66, 74, 82, 83, 84, 85, 87, 88, 89, 90, 102, 108, 116, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128, 130, 132, 133, 134, 136, 138, 142, 143, 144, 146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 176, 177, 184, 191, 195, 197, 202, 203, 217, 223, 228, 229, 235, 236, 238, 239, 242, 243, 249, 256, 263, 265, 267, 269, 312, 317, 335, 340, 342, 345, 346, 347, 349, 351, 352], "resiz": [2, 3, 58, 66, 118, 341, 343, 349, 352], "imag": [2, 4, 7, 56, 120, 140, 156, 162, 197, 340, 341, 346, 348, 352], "comops": 2, "totensorimag": [2, 3, 58, 66, 118, 144, 341, 343, 349, 351, 352], "renametransform": [2, 66, 84, 88, 102, 108], "rb0": [2, 66], "in_kei": [2, 3, 13, 14, 16, 17, 21, 52, 66, 80, 81, 84, 88, 98, 102, 108, 116, 117, 118, 119, 120, 121, 123, 125, 126, 130, 132, 134, 136, 137, 138, 140, 142, 143, 144, 145, 146, 147, 148, 150, 153, 155, 156, 157, 158, 160, 162, 164, 175, 185, 191, 195, 199, 211, 220, 221, 223, 224, 225, 226, 228, 229, 235, 236, 238, 239, 241, 242, 243, 248, 249, 250, 251, 252, 254, 255, 256, 262, 263, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 297, 298, 324, 327, 335, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "pixel": [2, 3, 7, 26, 58, 66, 82, 83, 87, 89, 90, 105, 118, 120, 127, 130, 132, 136, 138, 140, 144, 156, 160, 162, 179, 207, 208, 298, 324, 335, 340, 341, 343, 348, 349, 351, 352], "next": [2, 3, 4, 8, 13, 14, 16, 26, 28, 32, 35, 38, 40, 41, 42, 52, 53, 54, 55, 56, 57, 58, 59, 66, 71, 72, 75, 80, 81, 82, 83, 84, 85, 87, 88, 89, 93, 94, 98, 102, 106, 107, 108, 109, 110, 117, 118, 123, 126, 127, 128, 133, 134, 138, 142, 143, 145, 148, 149, 152, 154, 163, 164, 170, 173, 175, 190, 191, 194, 195, 199, 214, 244, 248, 249, 251, 252, 254, 255, 256, 257, 262, 266, 267, 268, 269, 271, 277, 278, 279, 280, 281, 282, 283, 309, 311, 313, 340, 341, 343, 345, 347, 348, 349, 351, 352], "32": [2, 22, 26, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 72, 106, 107, 109, 110, 176, 177, 178, 179, 180, 183, 188, 197, 202, 203, 207, 208, 210, 211, 220, 277, 339, 340, 341, 342, 343, 347, 348, 349, 350, 351, 352], "rb1": [2, 66], "p": [2, 4, 66, 69, 85, 106, 107], "5": [2, 3, 24, 26, 28, 35, 38, 41, 42, 66, 71, 72, 85, 93, 94, 99, 106, 107, 109, 110, 117, 145, 152, 153, 175, 176, 177, 186, 187, 189, 192, 193, 196, 197, 199, 202, 203, 207, 212, 218, 219, 228, 229, 236, 242, 263, 266, 268, 271, 335, 340, 341, 346, 347, 349, 351, 352], "33": [2, 26, 32, 66, 84, 88, 102, 108, 176, 177, 197, 341, 342, 347], "out_kei": [2, 3, 13, 14, 16, 17, 21, 66, 80, 81, 84, 88, 98, 102, 108, 116, 117, 118, 119, 120, 121, 123, 126, 130, 132, 134, 136, 137, 138, 140, 142, 143, 144, 145, 146, 147, 148, 150, 153, 155, 156, 157, 160, 162, 164, 175, 185, 186, 191, 195, 199, 211, 212, 220, 221, 223, 224, 225, 226, 228, 230, 235, 236, 237, 238, 239, 241, 242, 243, 248, 249, 250, 255, 256, 262, 263, 266, 267, 268, 269, 277, 279, 280, 281, 282, 298, 311, 327, 335, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "pixels33": [2, 66], "data0": [2, 66], "randint": [2, 45, 66, 156, 349], "255": [2, 66, 156, 347, 349], "244": [2, 66, 140, 162, 347], "randn": [2, 26, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 57, 58, 61, 62, 66, 71, 72, 77, 117, 136, 170, 178, 183, 186, 189, 190, 193, 194, 196, 200, 201, 202, 206, 209, 210, 212, 223, 224, 225, 226, 228, 229, 235, 236, 238, 241, 242, 243, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 279, 280, 281, 282, 314, 335, 351, 352], "batch_siz": [2, 3, 8, 13, 14, 15, 16, 26, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 65, 66, 71, 72, 75, 77, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 93, 94, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 117, 118, 123, 126, 127, 128, 138, 142, 143, 145, 149, 152, 154, 157, 173, 174, 175, 183, 186, 191, 195, 199, 211, 212, 220, 221, 223, 224, 225, 226, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 241, 242, 243, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 277, 306, 312, 324, 335, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "data1": [2, 66], "64": [2, 3, 34, 36, 39, 56, 66, 118, 144, 179, 180, 188, 191, 195, 203, 211, 277, 340, 341, 342, 343, 345, 347, 348, 349, 351, 352], "_": [2, 8, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 85, 92, 109, 110, 119, 123, 125, 126, 134, 136, 143, 156, 164, 223, 238, 243, 247, 248, 249, 251, 255, 256, 262, 266, 267, 269, 271, 279, 280, 281, 282, 340, 341, 342, 343, 346, 347, 349, 351], "rang": [2, 3, 4, 8, 11, 27, 35, 38, 40, 41, 42, 52, 53, 54, 55, 56, 57, 58, 61, 62, 66, 75, 84, 85, 88, 102, 108, 145, 156, 164, 190, 194, 263, 271, 336, 337, 340, 342, 343, 346, 347, 349, 351], "parent": [2, 3, 21, 26, 28, 44, 66, 74, 79, 84, 88, 102, 108, 118, 119, 122, 124, 127, 130, 131, 136, 140, 148, 152, 153, 154, 155, 157, 159, 160, 224, 264, 266, 283, 340, 347, 351, 352], "basic": [2, 98, 335, 342, 352], "properti": [2, 3, 32, 34, 36, 39, 84, 88, 98, 102, 108, 157, 158, 184, 192, 204, 209, 217, 218, 219, 264, 269, 347, 349], "observ": [2, 3, 8, 13, 14, 16, 17, 21, 32, 44, 52, 54, 56, 57, 58, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 117, 118, 119, 120, 121, 122, 123, 124, 127, 128, 130, 132, 133, 134, 136, 137, 138, 142, 143, 144, 145, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 173, 178, 179, 180, 181, 182, 183, 186, 191, 195, 196, 202, 207, 208, 210, 212, 213, 223, 224, 225, 226, 228, 229, 231, 232, 234, 235, 236, 243, 244, 248, 249, 250, 251, 252, 254, 255, 256, 259, 262, 263, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 283, 298, 324, 327, 335, 337, 341, 342, 343, 345, 346, 347, 349, 351, 352], "dtype": [2, 3, 13, 14, 16, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 54, 56, 57, 58, 59, 61, 62, 64, 71, 72, 77, 80, 81, 82, 83, 84, 87, 88, 89, 93, 94, 97, 98, 101, 102, 103, 104, 106, 107, 108, 109, 110, 115, 116, 122, 123, 124, 125, 126, 127, 128, 134, 136, 138, 140, 142, 143, 145, 149, 152, 154, 156, 157, 158, 160, 162, 166, 170, 173, 174, 175, 186, 189, 190, 191, 193, 194, 195, 199, 204, 205, 211, 212, 220, 223, 224, 225, 226, 228, 229, 230, 234, 235, 236, 237, 238, 241, 243, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 285, 324, 335, 342, 343, 345, 346, 347, 348, 349, 351, 352], "input": [2, 3, 4, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 43, 44, 46, 47, 84, 88, 98, 101, 102, 103, 104, 108, 109, 110, 115, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 136, 138, 139, 140, 141, 142, 143, 145, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 173, 174, 176, 177, 179, 180, 181, 182, 185, 186, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 204, 205, 212, 213, 214, 215, 216, 221, 223, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 247, 248, 249, 250, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 278, 279, 280, 281, 282, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 309, 313, 318, 327, 335, 336, 337, 340, 341, 342, 343, 346, 347, 351, 352], "output": [2, 3, 4, 13, 14, 16, 17, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 71, 72, 82, 83, 84, 87, 88, 89, 90, 98, 101, 102, 103, 104, 105, 108, 109, 110, 116, 118, 121, 122, 123, 124, 126, 128, 134, 136, 140, 142, 143, 148, 149, 152, 155, 157, 160, 162, 163, 166, 174, 176, 177, 178, 179, 180, 183, 185, 186, 187, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 212, 221, 223, 224, 227, 228, 229, 230, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 248, 249, 250, 251, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 283, 298, 306, 335, 336, 340, 341, 342, 343, 345, 346, 347, 348, 351, 352], "send": [2, 3, 8, 351], "receiv": [2, 3, 32, 40, 84, 88, 102, 108, 157, 197, 285, 336, 340, 342, 345, 347], "spawn": [2, 3, 4, 18, 22, 92, 99, 346], "check_env_spec": [2, 3, 88, 102, 142, 333, 342, 346, 347], "saniti": [2, 3, 7, 166, 342], "utmost": 2, "techniqu": [2, 8, 341, 349], "commonli": [2, 71, 72, 352], "emploi": [2, 205], "realm": 2, "languag": [2, 40], "scarc": 2, "address": [2, 349], "subdomain": 2, "within": [2, 13, 14, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 41, 42, 44, 46, 47, 56, 84, 88, 102, 105, 108, 118, 123, 126, 127, 152, 163, 164, 174, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 242, 245, 252, 257, 277, 335, 347, 351], "facilit": [2, 3, 7, 139, 140, 160, 162, 224, 225, 226, 335, 340, 343, 347], "interact": [2, 4, 5, 7, 8, 13, 14, 16, 18, 19, 20, 21, 56, 235, 239, 340, 342, 346, 347, 352], "extern": [2, 3, 123, 126, 352], "consist": [2, 3, 32, 35, 38, 41, 42, 53, 56, 84, 88, 102, 108, 134, 163, 177, 197, 340, 341, 342, 347, 348, 352], "token": [2, 36, 37, 40, 43, 45, 59], "manner": [2, 88, 140, 160, 335, 340, 341, 342, 345, 347, 349], "handl": [3, 21, 32, 84, 88, 102, 108, 163, 164, 195, 197, 315, 329, 330, 340, 341, 342, 346, 349], "dm": [3, 340, 352], "goal": [3, 4, 153, 340, 341, 342, 343, 346, 347], "abl": [3, 97, 103, 104, 340, 342, 343, 345, 346, 347, 349, 351], "experi": [3, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 64, 166, 300, 301, 302, 303, 304, 305, 334, 341, 342, 346, 349], "even": [3, 4, 8, 14, 18, 20, 21, 61, 62, 63, 73, 74, 77, 84, 85, 88, 92, 102, 108, 174, 340, 342, 346, 347, 352], "simul": [3, 5, 7, 8, 80, 81, 90, 93, 94, 105, 109, 110, 113, 175, 199, 335, 340, 342, 346], "box": [3, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "lib": [3, 5, 6, 7, 9, 10, 13, 14, 16, 17, 21, 22, 84, 85, 88, 102, 103, 104, 106, 107, 108, 118, 121, 127, 133, 134, 136, 138, 143, 145, 148, 154, 157, 163, 164, 324, 327, 340, 341, 342, 343, 345, 346, 348, 349, 351, 352], "hope": 3, "imit": 3, "nn": [3, 13, 14, 16, 17, 21, 32, 40, 80, 81, 84, 88, 98, 102, 108, 122, 125, 127, 134, 140, 154, 157, 158, 160, 162, 175, 176, 177, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 197, 199, 201, 202, 203, 206, 211, 212, 220, 223, 224, 225, 226, 228, 229, 231, 232, 234, 235, 236, 238, 239, 240, 241, 243, 248, 249, 251, 252, 254, 255, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 324, 327, 335, 336, 340, 341, 342, 343, 345, 346, 347, 348, 351], "typic": [3, 4, 8, 32, 84, 88, 102, 108, 127, 153, 235, 249, 264, 266, 269, 335, 336, 337, 342, 346, 347], "organis": [3, 57, 341], "arbitrari": [3, 33, 84, 88, 102, 108, 335, 340, 341, 347], "nest": [3, 26, 28, 32, 34, 36, 39, 48, 61, 62, 66, 77, 84, 87, 88, 89, 102, 108, 118, 152, 155, 174, 279, 280, 281, 282, 283, 337, 341, 342, 346, 347, 349, 351], "attribut": [3, 4, 32, 34, 36, 39, 45, 56, 84, 87, 88, 89, 102, 108, 127, 140, 160, 191, 195, 239, 248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 340, 343, 347], "expect": [3, 4, 7, 26, 32, 38, 44, 45, 70, 84, 88, 98, 101, 102, 108, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128, 130, 132, 133, 134, 136, 138, 140, 142, 143, 144, 146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 159, 160, 161, 163, 166, 189, 190, 191, 193, 194, 195, 202, 203, 230, 234, 238, 241, 248, 249, 250, 251, 252, 254, 255, 256, 262, 263, 264, 266, 267, 268, 269, 271, 277, 319, 334, 335, 336, 337, 340, 342, 343, 346, 347, 349, 352], "live": [3, 12, 13, 14, 16, 17, 19, 20, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 84, 88, 98, 102, 108, 127], "actual": [3, 4, 7, 17, 52, 53, 54, 56, 57, 58, 84, 88, 102, 108, 163, 318, 336, 340, 342, 346, 347], "do": [3, 4, 7, 58, 84, 88, 102, 108, 109, 110, 141, 163, 164, 173, 203, 204, 225, 279, 337, 340, 341, 342, 343, 345, 346, 347, 349, 351, 352], "retriev": [3, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 69, 84, 87, 88, 89, 102, 108, 119, 124, 127, 136, 173, 175, 176, 199, 235, 239, 242, 248, 249, 250, 252, 263, 266, 267, 269, 271, 277, 279, 280, 281, 282, 324, 331, 337, 341, 342, 347, 352], "care": [3, 8, 84, 88, 102, 108, 157, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 242, 245, 340, 342, 346, 347, 349], "below": [3, 7, 13, 14, 16, 17, 18, 19, 20, 21, 32, 59, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 176, 177, 189, 192, 193, 197, 203, 219, 238, 312, 340, 341, 342, 343, 347], "parametr": [3, 205, 239, 249, 255, 262, 269, 340, 342], "hardwar": 3, "observation_spec": [3, 84, 88, 98, 102, 108, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 130, 132, 133, 134, 136, 138, 140, 142, 144, 148, 150, 152, 153, 154, 155, 156, 157, 159, 160, 163, 175, 191, 195, 199, 319, 327, 340, 342, 345, 346, 347, 352], "compositespec": [3, 28, 49, 84, 86, 88, 98, 102, 108, 115, 123, 124, 125, 126, 128, 134, 142, 143, 149, 152, 154, 157, 170, 174, 175, 199, 223, 227, 235, 241, 242, 333, 340, 342, 343, 346, 347, 352], "pair": [3, 32, 34, 36, 39, 52, 82, 83, 84, 88, 102, 108, 145, 154, 191, 224, 235, 239, 264, 279, 280, 281, 282, 283, 335, 336, 340, 341, 342, 345, 347, 352], "state_spec": [3, 84, 88, 98, 102, 108, 115, 175, 199, 342, 347, 352], "empti": [3, 26, 28, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 84, 88, 101, 102, 108, 123, 126, 140, 142, 155, 158, 160, 162, 302, 340, 347], "action_spec": [3, 13, 14, 15, 16, 18, 19, 20, 80, 81, 84, 88, 93, 94, 98, 102, 103, 104, 108, 115, 118, 123, 126, 134, 142, 145, 175, 186, 199, 212, 214, 223, 229, 235, 236, 249, 252, 254, 267, 269, 271, 327, 335, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "reward_spec": [3, 84, 88, 98, 102, 108, 115, 116, 121, 122, 123, 124, 126, 142, 146, 147, 148, 150, 157, 159, 175, 199, 342, 346, 347, 352], "reward": [3, 13, 14, 16, 32, 34, 39, 40, 44, 45, 54, 56, 57, 58, 59, 75, 80, 81, 82, 83, 84, 87, 88, 89, 90, 93, 94, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 110, 115, 116, 121, 122, 123, 124, 126, 127, 128, 134, 138, 142, 143, 145, 146, 147, 148, 149, 150, 152, 153, 157, 158, 159, 161, 162, 164, 170, 173, 175, 191, 199, 228, 244, 248, 249, 251, 252, 254, 255, 256, 259, 262, 264, 266, 267, 268, 269, 271, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 308, 309, 311, 313, 331, 336, 337, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "done_spec": [3, 84, 88, 102, 108, 123, 124, 126, 127, 142, 157, 174, 342, 346, 347, 352], "flag": [3, 8, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 109, 110, 234, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 335, 346, 347, 348], "section": [3, 4, 189, 193, 341, 346], "termin": [3, 7, 32, 40, 52, 54, 56, 57, 58, 82, 83, 84, 87, 88, 89, 93, 94, 102, 103, 104, 106, 107, 108, 109, 110, 127, 142, 174, 175, 191, 195, 199, 240, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 283, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "input_spec": [3, 84, 88, 98, 102, 108, 122, 123, 124, 125, 136, 138, 142, 143, 148, 149, 152, 153, 154, 157, 158, 159, 161, 347], "full_action_spec": [3, 84, 88, 102, 108, 175, 199, 346], "full_state_spec": [3, 84, 88, 102, 108, 175, 199], "lock": [3, 26, 28, 34, 36, 39, 84, 88, 102, 108, 154, 164, 347], "modifi": [3, 7, 8, 26, 28, 32, 45, 84, 88, 102, 108, 122, 130, 134, 140, 154, 157, 158, 160, 162, 228, 234, 238, 318, 324, 340, 341, 342, 346, 347], "directli": [3, 4, 8, 66, 80, 81, 84, 87, 88, 98, 102, 108, 145, 163, 264, 331, 335, 342, 346, 347, 349], "output_spec": [3, 84, 88, 102, 108, 122, 123, 124, 128, 134, 142, 143, 149, 152, 157, 158, 347], "full_observation_spec": [3, 84, 88, 102, 108, 175, 199], "full_reward_spec": [3, 84, 88, 102, 108, 142, 346], "full_done_spec": [3, 84, 88, 102, 108, 142, 174, 346], "importantli": [3, 235, 239], "4": [3, 7, 24, 26, 27, 28, 33, 34, 35, 36, 38, 39, 40, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 71, 72, 80, 81, 82, 83, 84, 88, 93, 94, 95, 96, 97, 98, 100, 102, 106, 107, 108, 115, 118, 127, 145, 152, 153, 164, 175, 176, 177, 178, 179, 180, 183, 186, 187, 188, 189, 190, 193, 194, 196, 197, 199, 202, 203, 206, 207, 208, 209, 210, 211, 212, 220, 223, 224, 225, 226, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 241, 243, 248, 249, 251, 252, 254, 255, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 297, 335, 339, 340, 341, 342, 343, 346, 347, 348, 349, 350, 351, 352], "action_s": 3, "help": [3, 4, 32, 84, 88, 102, 108, 127, 334, 336, 340, 341, 342, 343, 346], "prealloc": [3, 347], "With": [3, 93, 94, 97, 153, 337, 340, 341, 346, 349, 352], "necessarili": [3, 84, 88, 102, 108, 352], "0s": [3, 56, 154, 343], "stateless": [3, 84, 88, 102, 108, 157, 264, 340, 347, 352], "step_and_maybe_reset": [3, 84, 88, 102, 108], "partial": [3, 84, 88, 102, 108, 117, 118, 153, 154, 155, 315, 343], "step_mdp": [3, 191, 195, 333, 343, 347, 351, 352], "done_kei": [3, 84, 88, 102, 108, 127, 145, 152, 173, 346], "assign": [3, 4, 13, 14, 32, 34, 36, 39, 84, 88, 102, 108, 158, 251, 252, 254, 269, 342, 346, 349], "_reset": [3, 84, 88, 98, 102, 108, 115, 118, 123, 126, 142, 174, 175, 199], "data_": [3, 84, 88, 102, 108], "i": [3, 13, 14, 16, 17, 18, 19, 20, 21, 26, 28, 32, 35, 38, 42, 43, 61, 62, 64, 72, 77, 84, 88, 102, 108, 140, 145, 148, 158, 162, 190, 194, 206, 212, 230, 235, 237, 238, 239, 279, 280, 281, 282, 306, 318, 340, 341, 342, 343, 346, 347, 349, 351, 352], "n": [3, 6, 7, 24, 27, 32, 33, 40, 84, 88, 102, 108, 118, 125, 130, 159, 189, 190, 193, 199, 234, 239, 248, 256, 264, 278, 312, 335, 337, 341, 342, 343, 346, 349, 352], "append": [3, 8, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 84, 85, 88, 102, 108, 121, 145, 154, 163, 190, 191, 194, 195, 229, 236, 340, 341, 342, 343, 346, 347, 348, 349, 351], "set_se": [3, 13, 14, 16, 17, 21, 80, 81, 84, 88, 93, 94, 98, 102, 108, 136, 143, 148, 153, 155, 158, 347, 351, 352], "seed": [3, 13, 14, 16, 17, 21, 57, 84, 88, 98, 102, 103, 104, 108, 109, 110, 115, 123, 126, 142, 158, 166, 315], "determinist": [3, 32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 178, 187, 207, 214, 223, 232, 238, 239, 242, 249, 335, 340, 341, 343, 347, 352], "preced": [3, 196, 343], "without": [3, 7, 9, 32, 40, 52, 56, 71, 72, 84, 88, 102, 108, 109, 110, 115, 123, 126, 156, 189, 190, 193, 194, 225, 226, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 278, 279, 280, 281, 282, 283, 327, 334, 335, 340, 341, 342, 346, 347, 349, 352], "risk": [3, 141], "overlap": [3, 41], "consecut": [3, 70, 92, 195, 234, 343, 346, 352], "reproduc": [3, 118, 166, 340, 342, 346], "maximum": [3, 4, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 36, 37, 39, 40, 43, 45, 59, 61, 62, 63, 77, 84, 88, 102, 108, 125, 146, 152, 153, 155, 217, 218, 219, 242, 249, 255, 256, 262, 264, 265, 269, 312, 340, 341, 342, 343, 346, 349], "max_step": [3, 13, 84, 88, 98, 102, 108, 109, 110, 152, 346, 351, 352], "tensordictmodul": [3, 13, 14, 16, 17, 20, 21, 40, 80, 81, 98, 117, 134, 186, 191, 195, 199, 211, 212, 220, 221, 224, 225, 226, 227, 228, 229, 232, 234, 235, 236, 237, 238, 240, 241, 242, 244, 249, 251, 255, 256, 258, 259, 260, 262, 264, 267, 269, 271, 277, 278, 279, 280, 281, 282, 311, 327, 335, 340, 342, 343, 345, 346, 347, 348], "compat": [3, 7, 11, 18, 19, 32, 34, 36, 39, 52, 66, 69, 71, 72, 73, 84, 88, 90, 101, 102, 108, 118, 152, 160, 164, 189, 190, 191, 193, 194, 195, 236, 248, 249, 251, 252, 254, 255, 256, 262, 264, 266, 267, 268, 269, 271, 274, 340, 343, 349, 351], "mark": [3, 16, 58, 84, 88, 102, 108, 191, 195], "trail": [3, 164], "treat": 3, "figur": [3, 340, 342, 343, 346, 347, 352], "summar": [3, 347], "brief": [3, 342], "deliveri": 3, "design": [3, 13, 14, 32, 33, 69, 74, 79, 84, 88, 102, 108, 118, 141, 158, 228, 248, 249, 250, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 340, 341, 342, 343, 345, 346, 347, 349, 352], "metaclass": 3, "ensur": [3, 32, 35, 41, 64, 70, 84, 88, 102, 108, 118, 140, 152, 160, 164, 229, 335, 341, 342, 347, 349], "everi": [3, 8, 17, 26, 28, 32, 33, 73, 84, 88, 102, 108, 152, 153, 164, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 242, 245, 315, 337, 340, 341, 342, 343, 346, 347], "flank": [3, 343], "dual": 3, "strictli": [3, 8, 32, 84, 88, 102, 108, 158, 269, 340, 342], "refer": [3, 7, 8, 9, 21, 32, 40, 84, 87, 88, 89, 102, 108, 158, 164, 175, 186, 187, 199, 200, 201, 202, 207, 208, 213, 214, 230, 248, 257, 258, 259, 260, 266, 269, 279, 284, 292, 339, 340, 342, 346], "union": [3, 11, 13, 15, 16, 17, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 44, 46, 47, 64, 84, 88, 102, 108, 115, 125, 127, 133, 136, 140, 141, 145, 147, 149, 160, 162, 164, 173, 176, 177, 179, 180, 181, 182, 184, 186, 188, 196, 197, 200, 201, 202, 203, 204, 205, 209, 211, 212, 217, 218, 219, 220, 238, 254, 256, 261, 267, 270, 292, 298, 309, 311, 312, 320, 321, 324, 325, 327, 328, 329, 330, 331], "interpret": [3, 341], "last": [3, 4, 11, 13, 14, 16, 17, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 37, 44, 46, 47, 52, 70, 72, 80, 81, 82, 83, 84, 87, 88, 89, 90, 93, 94, 99, 100, 102, 105, 108, 117, 130, 136, 141, 153, 155, 156, 176, 177, 189, 191, 193, 195, 196, 197, 200, 201, 207, 215, 221, 227, 228, 231, 232, 239, 341, 342, 343, 346, 347, 348, 349, 351, 352], "indic": [3, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 60, 66, 67, 69, 70, 71, 72, 75, 76, 78, 79, 80, 81, 82, 83, 84, 87, 88, 89, 90, 93, 94, 99, 100, 102, 105, 108, 109, 110, 118, 119, 152, 153, 154, 155, 158, 174, 176, 177, 197, 200, 201, 203, 234, 236, 237, 245, 248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 319, 331, 334, 337, 342, 343, 347, 349, 352], "truncat": [3, 13, 14, 16, 18, 19, 20, 21, 37, 43, 45, 52, 54, 56, 57, 58, 71, 72, 82, 83, 84, 87, 88, 89, 102, 103, 104, 108, 109, 110, 127, 128, 135, 142, 145, 152, 174, 191, 195, 219, 285, 340, 342, 343, 345, 348, 349, 351, 352], "carri": [3, 21, 45, 84, 88, 102, 108, 154, 264, 341, 343, 346, 347, 349], "assess": [3, 111, 340], "split_trajectori": [3, 13, 14, 16, 17, 18, 19, 20, 21, 56, 71, 72, 333], "adjac": [3, 23, 130], "reli": [3, 189, 190, 193, 194, 248, 336, 340, 342, 347, 352], "traj_id": [3, 13, 14, 16, 23, 145, 343, 349, 351], "junction": 3, "miss": [3, 4, 6, 7, 11, 26, 32, 84, 88, 102, 108, 158, 173, 240, 241, 269, 334, 340, 343], "context": [3, 5, 8, 32, 84, 85, 88, 101, 102, 108, 154, 159, 203, 204, 228, 275, 276, 279, 280, 281, 282, 284, 292, 311, 335, 336, 340, 341, 342, 346, 347, 348, 349], "through": [3, 4, 5, 8, 11, 16, 18, 20, 21, 26, 28, 56, 80, 81, 92, 93, 94, 97, 102, 103, 104, 108, 123, 126, 141, 197, 211, 235, 239, 240, 241, 245, 279, 280, 281, 282, 335, 340, 341, 342, 345, 346, 347, 348, 349, 352], "inittrack": [3, 191, 195, 340, 343], "tutori": [3, 339, 340, 341, 343, 344, 345, 347, 348, 349, 350, 352], "inform": [3, 4, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 36, 39, 43, 56, 84, 85, 88, 91, 102, 108, 176, 177, 197, 203, 336, 337, 340, 341, 342, 343, 346, 347, 349], "scratch": [3, 8, 341, 347], "better": [3, 8, 9, 191, 195, 336, 342, 347], "intens": [3, 8], "gym3": 3, "envpool": [3, 99, 100], "interfac": [3, 91, 101, 197, 204, 335, 340, 342, 347, 349], "simultan": [3, 20, 99, 100, 102, 108, 347], "often": [3, 8, 261, 315, 340, 341, 347, 349, 352], "competit": [3, 346], "advantag": [3, 8, 188, 248, 250, 263, 266, 268, 279, 280, 281, 282, 283, 284, 286, 288, 290, 292, 293, 295, 336, 337, 340, 341, 342, 343, 346, 347, 352], "scale": [3, 4, 52, 118, 134, 136, 147, 153, 156, 187, 192, 206, 213, 214, 218, 219, 224, 225, 226, 235, 239, 241, 248, 249, 262, 266, 267, 268, 269, 313, 319, 324, 331, 335, 340, 341, 342, 343, 346, 351], "varieti": 3, "own": [3, 13, 14, 17, 22, 32, 84, 88, 102, 103, 104, 108, 341, 342, 346, 347], "As": [3, 4, 84, 88, 97, 102, 103, 104, 108, 145, 239, 279, 335, 340, 341, 342, 343, 346, 347, 348, 349, 351, 352], "inherit": [3, 84, 88, 102, 108, 198, 264, 337, 342, 346], "serialenv": [3, 84, 88, 102, 154, 333, 352], "Of": [3, 7, 334, 347, 352], "cours": [3, 4, 334, 342, 347, 352], "correspond": [3, 4, 13, 14, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 44, 46, 47, 53, 56, 58, 64, 84, 88, 98, 102, 108, 140, 154, 158, 162, 164, 191, 193, 195, 200, 201, 231, 232, 234, 235, 239, 252, 255, 256, 269, 277, 279, 280, 281, 282, 283, 340, 341, 342, 346, 347, 348], "count": [3, 85, 152, 234, 311, 315, 318, 340, 341, 342, 343, 349, 352], "make_env": [3, 102, 110, 164, 320, 321, 340, 341, 352], "gymenv": [3, 5, 13, 14, 16, 17, 21, 22, 84, 85, 88, 90, 102, 108, 118, 121, 122, 127, 133, 134, 136, 138, 143, 144, 145, 148, 150, 153, 154, 155, 157, 158, 164, 191, 195, 324, 327, 333, 335, 340, 341, 342, 343, 348, 349, 351, 352], "v1": [3, 13, 14, 16, 17, 21, 22, 52, 54, 84, 85, 87, 88, 89, 93, 94, 99, 102, 108, 118, 121, 128, 133, 134, 136, 143, 145, 148, 150, 152, 153, 154, 155, 157, 191, 195, 274, 288, 289, 290, 291, 293, 294, 295, 296, 335, 341, 343, 347, 349, 351, 352], "from_pixel": [3, 80, 81, 82, 83, 87, 89, 90, 93, 94, 105, 118, 144, 324, 340, 341, 343, 348, 349, 351, 352], "9": [3, 7, 32, 35, 38, 41, 57, 58, 72, 75, 82, 83, 97, 103, 104, 153, 164, 248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 272, 277, 336, 339, 340, 341, 342, 345, 346, 347, 348, 349, 350], "81": [3, 341, 347], "must": [3, 7, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 44, 45, 46, 47, 53, 54, 56, 57, 58, 59, 61, 62, 63, 71, 72, 73, 74, 77, 80, 84, 85, 88, 93, 102, 103, 104, 105, 108, 109, 118, 121, 127, 131, 134, 136, 138, 149, 153, 154, 155, 158, 159, 164, 176, 177, 186, 191, 195, 197, 200, 201, 202, 203, 212, 223, 229, 230, 235, 236, 237, 238, 239, 242, 243, 248, 249, 251, 252, 254, 255, 256, 257, 258, 262, 264, 266, 267, 268, 269, 270, 271, 277, 279, 280, 281, 282, 283, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 324, 340, 341, 342, 343, 345, 347, 349, 351], "print": [3, 6, 7, 13, 14, 16, 21, 22, 24, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 45, 53, 56, 58, 59, 66, 71, 72, 75, 80, 81, 82, 83, 84, 85, 87, 88, 89, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 106, 107, 108, 109, 110, 112, 114, 118, 119, 123, 124, 125, 126, 133, 136, 142, 143, 145, 148, 152, 154, 155, 156, 164, 170, 173, 174, 176, 177, 183, 186, 191, 197, 200, 201, 202, 203, 206, 209, 212, 223, 224, 225, 226, 228, 229, 231, 232, 234, 236, 238, 241, 243, 264, 324, 327, 335, 337, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "simpli": [3, 6, 34, 36, 39, 45, 74, 79, 128, 149, 163, 264, 335, 336, 340, 342, 346, 352], "b": [3, 7, 8, 23, 26, 28, 34, 36, 39, 40, 41, 42, 75, 189, 190, 193, 194, 202, 203, 204, 205, 211, 220, 242, 279, 280, 281, 282, 283, 285, 298, 335, 341, 348, 349], "c": [3, 6, 7, 26, 34, 36, 39, 41, 42, 55, 136, 156, 193, 194, 341, 349], "d": [3, 35, 53, 55, 57, 58, 59, 64, 189, 193, 235, 239, 351], "get": [3, 4, 6, 7, 8, 9, 26, 28, 34, 35, 36, 38, 39, 52, 56, 61, 62, 71, 72, 73, 74, 75, 77, 84, 85, 88, 102, 108, 115, 117, 119, 123, 125, 126, 134, 136, 141, 153, 154, 156, 164, 223, 231, 232, 235, 236, 239, 279, 280, 281, 282, 283, 302, 335, 340, 341, 342, 343, 346, 347, 349, 351, 352], "forc": [3, 6, 7, 13, 14, 18, 20, 21, 53, 54, 56, 57, 58, 341, 346, 347], "privat": [3, 84, 88, 102, 108, 163, 347, 352], "absenc": 3, "total": [3, 13, 14, 16, 17, 18, 19, 20, 21, 24, 30, 31, 33, 72, 250, 263, 266, 306, 308, 311, 315, 318, 319, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352], "unless": [3, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 56, 70, 84, 88, 102, 108, 342], "wa": [3, 5, 7, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 70, 84, 88, 102, 108, 158, 174, 193, 261, 270, 285, 336, 341, 342, 345, 349, 351], "abov": [3, 7, 32, 84, 88, 102, 108, 192, 218, 219, 247, 336, 337, 340, 342, 346, 347, 352], "deal": [3, 340, 342, 346, 349], "proper": [3, 4, 6, 7, 279, 280, 281, 282, 341, 342, 346, 349], "behav": [3, 90, 98, 189, 193, 209, 255, 262, 348], "accord": [3, 13, 14, 16, 17, 18, 19, 20, 21, 34, 36, 39, 40, 66, 69, 136, 147, 192, 204, 213, 218, 219, 277, 335, 347, 349], "develop": [3, 4, 7, 92, 340, 351], "inner": [3, 84, 88, 102, 108, 125, 337, 341, 342, 346, 352], "logic": 3, "nevertheless": [3, 342, 349], "kept": [3, 13, 14, 16, 17, 70, 72, 125, 149, 157, 166, 173, 192, 218, 219], "mind": [3, 56, 71, 72, 84, 88, 102, 108, 346], "desig": 3, "previou": [3, 4, 10, 32, 40, 41, 154, 174, 189, 193, 214, 228, 342, 343, 347, 352], "wherev": 3, "expos": [3, 105, 123, 126, 240, 341], "modif": [3, 5, 26, 28, 32, 84, 88, 102, 108, 130, 174, 264, 342, 347], "lost": [3, 8, 163], "eras": [3, 84, 88, 102, 108, 158], "intern": [3, 338], "face": [3, 5, 8, 9, 352], "NOT": [3, 141], "outsid": [3, 16, 346, 347], "keep": [3, 4, 7, 8, 14, 42, 70, 75, 102, 108, 136, 140, 162, 164, 173, 234, 308, 315, 340, 341, 342, 343, 346, 347, 349, 351, 352], "right": [3, 6, 7, 40, 196, 341, 342, 346, 347, 352], "preliminari": 3, "warranti": 3, "affect": [3, 8, 32, 84, 88, 102, 108, 157, 158, 166, 279, 280, 281, 282], "assumpt": [3, 347, 349], "made": [3, 32, 61, 62, 63, 73, 74, 77, 84, 88, 102, 108, 234, 252, 277, 340, 341, 343, 346, 348], "preclud": 3, "presenc": 3, "annihil": 3, "effect": [3, 26, 32, 56, 66, 69, 71, 72, 84, 88, 102, 108, 118, 158, 315, 340, 349, 352], "reason": [3, 4, 8, 32, 56, 84, 88, 102, 103, 104, 108, 140, 160, 195, 336, 340, 341, 342, 347, 349], "root": [3, 26, 28, 52, 53, 54, 55, 56, 57, 58, 102, 118, 155, 173, 192, 218, 219, 343, 346, 347, 348, 349, 352], "known": [3, 5, 7, 8, 286, 287, 340, 341], "advanc": [3, 21, 35, 38, 41, 42, 349], "explicitli": [3, 4, 341, 343, 346, 349], "place": [3, 13, 14, 16, 17, 26, 28, 32, 34, 36, 39, 61, 62, 66, 69, 77, 84, 85, 88, 102, 108, 109, 110, 122, 127, 140, 154, 157, 158, 160, 162, 163, 164, 174, 228, 238, 312, 317, 318, 341, 342, 346, 347, 349], "superse": 3, "pettingzoowrapp": [3, 333], "group": [3, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 84, 88, 97, 102, 103, 104, 108, 109, 110, 111, 335, 341, 342, 346], "associ": [3, 32, 34, 36, 39, 84, 88, 102, 108, 213, 331, 340, 349], "environemtn": 3, "__not__": 3, "constrain": [3, 134, 191, 195, 266], "li": 3, "fact": [3, 7, 8, 340, 342, 346, 347, 348, 349, 352], "predict": [3, 32, 40, 187, 198, 199, 228, 244, 254, 257, 259, 260, 278, 335, 340, 341], "know": [3, 4, 9, 35, 38, 41, 42, 227, 267, 311, 340, 341, 342, 343, 346, 349], "meaning": 3, "could": [3, 4, 6, 341, 342, 346, 348, 352], "perfectli": [3, 337, 340, 347], "case": [3, 4, 5, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 26, 32, 35, 41, 53, 54, 56, 57, 58, 64, 84, 88, 102, 108, 123, 124, 126, 156, 158, 166, 195, 197, 203, 235, 238, 239, 241, 242, 247, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 279, 280, 281, 282, 306, 317, 329, 330, 331, 335, 337, 340, 341, 342, 343, 346, 347, 349, 352], "meaningless": 3, "discard": [3, 45, 52, 54, 88, 160, 173, 297, 349, 352], "val": [3, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 351], "agent0": 3, "agent1": 3, "overridden": [3, 53, 54, 56, 57, 58, 84, 88, 102, 108, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 242, 245, 343], "overrid": [3, 24, 25, 26, 27, 28, 29, 30, 31, 33, 38, 44, 46, 47, 84, 88, 102, 108, 331, 335], "elimin": 3, "field": [3, 13, 14, 16, 17, 26, 32, 34, 36, 37, 39, 40, 41, 42, 43, 45, 54, 56, 57, 58, 61, 62, 77, 80, 81, 82, 83, 84, 87, 88, 89, 93, 94, 97, 98, 101, 102, 103, 104, 106, 107, 108, 109, 110, 123, 126, 127, 128, 138, 142, 143, 145, 149, 152, 154, 158, 173, 175, 186, 191, 195, 199, 211, 212, 220, 223, 224, 225, 226, 228, 229, 230, 234, 235, 236, 237, 238, 241, 243, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 277, 319, 324, 334, 335, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "bool": [3, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 66, 69, 70, 71, 72, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 94, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 118, 119, 123, 125, 126, 127, 128, 130, 134, 135, 136, 138, 140, 142, 143, 145, 147, 149, 152, 154, 156, 158, 159, 160, 162, 164, 166, 173, 174, 175, 176, 177, 179, 180, 189, 190, 191, 192, 193, 194, 195, 197, 199, 202, 203, 204, 205, 218, 219, 223, 229, 230, 234, 235, 236, 237, 238, 239, 240, 241, 242, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 271, 274, 277, 279, 280, 281, 282, 285, 288, 289, 290, 291, 293, 294, 295, 296, 297, 298, 308, 309, 311, 312, 313, 315, 324, 331, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "500": [3, 340, 341, 347, 351, 352], "uint8": [3, 34, 36, 39, 47, 56, 82, 83, 127, 138, 156, 341, 348, 349, 351, 352], "none": [3, 8, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 66, 69, 71, 72, 73, 74, 75, 77, 84, 85, 87, 88, 97, 98, 102, 103, 104, 108, 109, 110, 112, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 130, 132, 134, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 152, 153, 154, 155, 156, 157, 158, 160, 162, 164, 165, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 188, 189, 190, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 207, 208, 209, 210, 211, 212, 220, 221, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 241, 242, 243, 248, 249, 251, 252, 254, 255, 256, 257, 258, 262, 264, 265, 266, 267, 268, 269, 270, 271, 277, 278, 279, 280, 281, 282, 283, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 302, 303, 304, 309, 310, 311, 312, 313, 314, 315, 319, 320, 321, 324, 327, 329, 330, 331, 335, 337, 340, 341, 342, 343, 346, 347, 349, 351, 352], "is_shar": [3, 13, 14, 16, 26, 34, 36, 37, 39, 40, 41, 42, 43, 45, 54, 56, 57, 58, 59, 61, 62, 77, 80, 81, 82, 83, 84, 87, 88, 89, 93, 94, 97, 98, 101, 102, 103, 104, 106, 107, 108, 109, 110, 123, 126, 127, 128, 138, 142, 143, 145, 149, 152, 154, 164, 173, 175, 186, 191, 195, 199, 211, 212, 220, 223, 224, 225, 226, 228, 229, 230, 234, 235, 236, 237, 238, 241, 243, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 277, 324, 335, 342, 343, 345, 346, 347, 348, 349, 351, 352], "launch": [3, 13, 14, 18, 19, 20, 22, 53, 102, 108], "bottleneck": [3, 8], "so": [3, 4, 6, 7, 10, 32, 34, 36, 39, 40, 84, 88, 102, 108, 154, 164, 240, 241, 342, 343, 346, 347, 352], "great": [3, 7, 8, 351], "speedup": [3, 8, 352], "precis": [3, 123, 126, 173, 190, 194, 340, 342], "misspecifi": 3, "caus": [3, 7, 8, 61, 62, 77, 84, 88, 92, 102, 108, 141, 352], "breakag": 3, "rais": [3, 13, 14, 16, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 44, 46, 47, 56, 84, 88, 102, 108, 111, 118, 129, 135, 145, 153, 154, 155, 158, 166, 227, 231, 232, 234, 269, 340, 342, 346, 349], "mismatch": [3, 341], "mostli": [3, 17, 336, 349, 352], "purpos": [3, 7, 84, 88, 102, 108, 118, 189, 327, 340, 342, 343, 346, 348, 352], "want": [3, 6, 7, 8, 72, 136, 248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 335, 340, 341, 342, 343, 346, 347, 348, 349, 351, 352], "subprocess": [3, 13, 14, 85, 102, 108], "addit": [3, 4, 32, 52, 84, 88, 102, 108, 109, 122, 140, 154, 157, 158, 160, 162, 189, 227, 228, 238, 247, 264, 279, 336, 340, 341, 346, 349], "multithread": [3, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 59, 99, 100, 349], "multithreadedenv": [3, 333], "underneath": 3, "higher": [3, 4, 121, 242, 340, 341, 342, 349, 352], "restrict": [3, 341, 348, 349, 352], "flexibl": [3, 9, 99, 272, 336, 337, 349, 352], "cover": [3, 334, 342, 347, 351], "popular": [3, 335, 343, 346], "atari": [3, 4, 118, 352], "classic": [3, 98, 104, 341], "benchmark_batched_env": 3, "py": [3, 114, 211, 220, 337, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352], "pipelin": [3, 7, 335, 342], "seamlessli": [3, 347], "infrastructur": [3, 346], "view": [3, 8, 27, 32, 33, 56, 57, 84, 88, 102, 108, 115, 186, 189, 193, 197, 347, 349, 351, 352], "core": [3, 8, 324, 337, 343, 351], "decis": [3, 178, 210, 228, 253, 265, 343, 346, 349, 352], "act": [3, 4, 71, 72, 103, 104, 203, 249, 251, 262, 267, 269, 271, 343, 346], "world": [3, 5, 98, 244, 259, 346, 347, 352], "paradigm": [3, 17, 346], "decpodp": 3, "markov": [3, 352], "game": [3, 4, 5], "per": [3, 4, 13, 14, 16, 17, 18, 19, 20, 21, 53, 92, 93, 94, 102, 103, 104, 121, 148, 187, 202, 203, 231, 315, 329, 330, 340, 341, 342, 343, 346, 349, 351], "accommod": [3, 13, 14, 16, 17], "thank": [3, 340], "carrier": [3, 342, 343, 349], "particular": [3, 32, 45, 52, 53, 84, 88, 102, 108, 158, 336, 337, 341, 343, 345, 346, 349], "thu": [3, 263, 346], "hand": [3, 7, 21, 346, 347], "let": [3, 6, 7, 32, 43, 84, 88, 102, 103, 104, 108, 118, 191, 195, 202, 203, 229, 311, 336, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "understand": [3, 8, 340, 341, 346], "go": [3, 7, 97, 102, 141, 145, 228, 285, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "vma": [3, 109, 110, 346], "robot": [3, 5, 7, 56, 140, 160, 162, 346], "what": [3, 8, 35, 44, 84, 88, 102, 108, 127, 154, 173, 236, 334, 335, 336, 341, 342, 343, 346, 347, 348, 349, 351, 352], "vmasenv": [3, 333, 346], "balanc": [3, 82, 83, 340, 341, 352], "num_env": [3, 21, 87, 91, 100, 109, 110, 346], "n_agent": [3, 109, 110, 202, 203, 211, 220, 277, 346], "info": [3, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 69, 71, 72, 82, 83, 84, 87, 88, 89, 90, 102, 103, 104, 106, 107, 108, 109, 110, 160, 163, 165, 346, 349], "ground_rew": 3, "pos_rew": [3, 346], "16": [3, 32, 57, 72, 80, 81, 84, 88, 93, 94, 102, 108, 118, 340, 341, 342, 343, 347, 348, 349, 351], "style": [3, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58], "relat": [3, 4, 10, 35, 102, 130, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 341, 347], "vari": [3, 87, 89, 90, 103, 104, 105, 109, 141, 346], "creation": [3, 102, 108, 340, 352], "info_spec": [3, 102], "agent_i_action_spec": 3, "agent_i_reward_spec": 3, "agent_i_observation_spec": 3, "discretetensorspec": [3, 33, 80, 81, 84, 87, 88, 89, 90, 93, 94, 99, 100, 102, 105, 108, 115, 142, 174, 252, 255, 256, 277, 333, 342, 346, 352], "you": [3, 5, 6, 7, 8, 9, 10, 32, 43, 53, 84, 88, 92, 97, 102, 103, 104, 106, 107, 108, 109, 110, 114, 164, 193, 334, 335, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "simpl": [3, 9, 32, 33, 84, 88, 102, 108, 179, 239, 252, 254, 264, 268, 279, 335, 336, 340, 341, 342, 346, 352], "composit": [3, 26, 28, 69, 74, 79, 84, 88, 102, 108, 342, 347], "prefix": [3, 23, 32, 34, 36, 39, 45, 84, 88, 102, 108, 158, 264, 269, 297, 343, 352], "exactli": [3, 32, 84, 88, 90, 102, 108, 158, 189, 193, 269, 340, 343, 346], "action_kei": [3, 15, 84, 88, 102, 108, 115, 125, 173, 175, 198, 199, 227, 231, 232, 234, 346], "reward_kei": [3, 84, 88, 102, 108, 173, 175, 199, 309, 313, 346], "automat": [3, 5, 58, 61, 62, 66, 77, 84, 87, 88, 89, 102, 103, 104, 108, 123, 126, 136, 163, 176, 223, 235, 335, 340, 342, 346, 347, 349, 351], "sure": [3, 4, 7, 55, 73, 88, 92, 145, 229, 331, 335, 340, 342, 343, 346, 347, 349, 351, 352], "set_kei": [3, 127, 248, 250, 252, 255, 256, 257, 262, 263, 264, 266, 267, 268, 269, 277, 283, 346], "awai": [3, 342, 346], "eas": [3, 346], "leaf": [3, 26, 28, 84, 88, 102, 108, 152, 239], "would": [3, 32, 40, 84, 88, 102, 108, 189, 191, 193, 195, 197, 202, 337, 341, 342, 343, 347, 349, 352], "full": [3, 84, 88, 102, 108, 191, 195, 230, 306, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "raw": [3, 4, 40, 192, 218, 219, 341, 347], "torchvis": [3, 140, 162, 351, 352], "transformedenv": [3, 13, 84, 85, 88, 102, 108, 115, 118, 121, 122, 123, 126, 127, 128, 130, 133, 134, 135, 136, 138, 142, 143, 144, 145, 148, 149, 150, 152, 153, 154, 155, 157, 164, 191, 195, 324, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "built": [3, 5, 7, 66, 80, 81, 87, 93, 94, 101, 248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 272, 277, 325, 327, 328, 331, 340, 341, 342, 343, 349, 352], "base_env": [3, 81, 84, 88, 89, 94, 102, 108, 115, 121, 123, 125, 126, 134, 138, 142, 144, 150, 152, 154, 155, 340, 341, 342, 348, 351, 352], "appar": [3, 308], "bring": [3, 342, 352], "signific": [3, 5, 8, 342, 352], "kind": [3, 38, 44, 173, 349], "consult": 3, "interest": [3, 235, 239, 335, 341, 342, 346, 347, 352], "resize_par": 3, "easi": [3, 5, 55, 82, 83, 93, 94, 227, 231, 232, 234, 335, 336, 340, 341, 342, 346, 348, 349, 352], "graph": [3, 4, 8, 80, 81, 93, 94, 275, 276, 340, 347], "inv": [3, 121, 125, 138, 145, 150, 347], "appli": [3, 4, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 38, 41, 42, 43, 44, 46, 47, 52, 53, 54, 55, 56, 57, 58, 66, 84, 88, 102, 108, 115, 117, 118, 119, 122, 123, 124, 125, 127, 128, 129, 130, 131, 133, 134, 135, 139, 141, 142, 143, 145, 148, 149, 152, 153, 154, 155, 157, 158, 160, 161, 163, 164, 189, 193, 218, 229, 279, 310, 337, 340, 341, 342, 347, 351, 352], "revers": [3, 193], "order": [3, 16, 32, 33, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 70, 72, 84, 88, 102, 108, 123, 126, 138, 158, 223, 229, 238, 240, 241, 243, 248, 249, 251, 255, 256, 262, 266, 267, 268, 269, 271, 341, 346], "chain": [3, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 57, 58, 122, 125, 176, 177, 241, 352], "taken": [3, 84, 88, 102, 108, 144, 200, 201, 232, 336, 340, 342, 343, 346, 347], "invers": [3, 4, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 118, 123, 126, 136, 145, 246, 255, 262, 347], "in_keys_inv": [3, 121, 123, 126, 136, 137, 138, 142, 143, 145, 150, 157, 340, 345, 347, 352], "append_transform": [3, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 117, 140, 154, 160, 340, 343, 347, 351, 352], "doubletofloat": [3, 324, 340, 342, 345], "float32": [3, 13, 14, 16, 26, 34, 35, 36, 39, 40, 41, 42, 44, 45, 54, 56, 58, 61, 62, 64, 77, 80, 81, 84, 87, 88, 89, 93, 94, 98, 101, 102, 106, 107, 108, 109, 110, 123, 126, 127, 128, 136, 138, 142, 143, 145, 149, 152, 154, 156, 170, 173, 175, 186, 191, 195, 199, 211, 212, 220, 223, 224, 225, 226, 228, 229, 234, 235, 236, 237, 238, 241, 243, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 277, 324, 335, 342, 343, 345, 346, 347, 348, 349, 351, 352], "float64": [3, 32, 54, 56, 57, 82, 83, 84, 88, 102, 108, 122, 123, 126, 140, 154, 157, 158, 160, 162, 238, 345, 352], "regist": [3, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 53, 84, 87, 88, 89, 102, 108, 123, 126, 127, 158, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 242, 245, 248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 317, 337, 340, 342, 349], "manipul": [3, 4, 8, 82, 83, 140, 160, 352], "third_transform": 3, "replac": [3, 6, 7, 26, 28, 32, 56, 71, 72, 125, 127, 173, 231, 335, 349], "unexpect": [3, 32, 84, 88, 102, 108, 158, 269, 352], "behviour": 3, "fortun": [3, 343], "alreadi": [3, 8, 11, 32, 34, 36, 39, 45, 84, 88, 102, 108, 154, 174, 239, 279, 280, 281, 282, 340, 342, 346], "chang": [3, 5, 7, 32, 35, 38, 41, 42, 61, 62, 63, 70, 73, 74, 77, 84, 88, 102, 108, 122, 123, 124, 126, 128, 134, 142, 143, 149, 152, 157, 158, 164, 193, 248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 336, 340, 342, 343, 346, 347, 348, 349, 352], "happen": [3, 84, 88, 102, 108, 227, 341, 348, 352], "catfram": [3, 341], "hold": [3, 275, 276, 347, 349], "notic": [3, 118, 342, 347], "parenthood": 3, "henc": [3, 35, 141, 174, 202, 335, 340, 342, 346, 347], "transform1": 3, "transform2": 3, "transform3": 3, "last_two": 3, "isinst": [3, 347], "discret": [3, 24, 27, 30, 31, 33, 47, 84, 88, 102, 103, 104, 108, 109, 110, 125, 209, 212, 254, 255, 256, 257, 335, 341, 342, 346, 347, 352], "might": [3, 34, 36, 37, 39, 302, 334, 340, 352], "throughout": [3, 248, 249, 250, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 342, 352], "action_mask": [3, 93, 94, 103, 104, 106, 107, 115], "unavail": [3, 103, 104], "probabl": [3, 4, 8, 40, 66, 69, 184, 186, 189, 191, 193, 195, 197, 200, 201, 209, 219, 231, 235, 239, 335, 341, 351], "categor": [3, 27, 31, 33, 80, 81, 87, 89, 90, 93, 94, 99, 100, 103, 104, 105, 109, 110, 115, 127, 186, 209, 212, 229, 230, 235, 236, 237, 252, 255, 256, 277, 343], "probabilistictensordictmodul": [3, 134, 239, 240, 351], "tensordictsequenti": [3, 191, 195, 229, 231, 240, 335, 340, 343, 345, 348, 351], "maskedcategor": [3, 201, 333], "linear": [3, 13, 14, 16, 17, 21, 32, 80, 81, 84, 88, 98, 102, 108, 122, 134, 140, 154, 157, 158, 160, 162, 175, 176, 177, 186, 197, 199, 202, 203, 204, 205, 206, 212, 213, 214, 223, 224, 225, 226, 231, 232, 233, 234, 235, 236, 238, 241, 243, 248, 249, 251, 252, 254, 255, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 327, 335, 341, 345, 348, 351], "in_feat": 3, "out_feat": 3, "logit": [3, 36, 40, 200, 201, 209, 230, 235, 255, 256, 335], "dist": [3, 10, 200, 201, 209], "distribution_class": [3, 134, 224, 225, 226, 228, 235, 239, 241, 248, 249, 255, 256, 262, 266, 267, 268, 269, 335, 340, 342, 346, 351], "wrap": [3, 5, 13, 14, 16, 17, 18, 19, 20, 21, 32, 40, 54, 80, 81, 84, 88, 89, 93, 94, 100, 102, 103, 104, 108, 110, 166, 191, 195, 221, 224, 225, 226, 227, 232, 234, 236, 244, 277, 335, 340, 341, 342, 343, 346, 352], "actionmask": 3, "your_base_env": 3, "mask_kei": [3, 115, 141], "add": [3, 4, 6, 21, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 60, 66, 67, 75, 76, 78, 79, 84, 88, 102, 108, 118, 134, 191, 195, 204, 233, 248, 310, 342, 343, 346, 347, 349, 351], "enviorn": [3, 103, 104, 109, 110, 346], "itself": [3, 32, 84, 88, 102, 108, 112, 264, 342], "log": [3, 4, 8, 40, 54, 57, 184, 185, 186, 200, 201, 209, 219, 229, 230, 235, 239, 248, 249, 250, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 308, 309, 311, 315, 327, 335, 336, 337, 340, 341, 342, 346, 347, 351], "mission": 3, "irrespect": [3, 238, 239], "dmcontrol": [3, 84, 88, 102, 108, 340], "jumanji": [3, 84, 88, 93, 94, 102, 108], "natur": [3, 340, 343], "special": [3, 335, 340, 343, 352], "framework": [3, 4, 9, 22, 80, 81, 84, 88, 93, 94, 98, 102, 108, 189, 351, 352], "Its": [3, 32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 164, 238, 283], "success": [3, 54, 118, 157, 231, 341, 347, 349, 351], "been": [3, 5, 7, 8, 17, 18, 20, 21, 40, 66, 70, 84, 88, 92, 102, 108, 134, 152, 153, 157, 189, 193, 227, 232, 234, 340, 341, 342, 343, 345, 346, 347, 349, 352], "foundat": [3, 5, 103, 104, 342, 346], "inspir": [3, 347], "gone": [3, 4, 5], "sometim": [3, 343, 352], "hard": [3, 7, 82, 83, 102, 261, 341, 352], "adopt": [3, 5, 340, 352], "prefer": [3, 17, 20, 35, 38, 41, 42, 141, 149, 266, 312, 335, 342, 346, 349], "maintain": [3, 5, 9, 347], "both": [3, 7, 32, 56, 84, 85, 87, 88, 102, 103, 104, 108, 118, 143, 158, 174, 176, 177, 191, 194, 195, 197, 202, 203, 224, 225, 226, 230, 237, 248, 250, 251, 255, 256, 262, 263, 264, 266, 267, 268, 269, 271, 311, 335, 340, 342, 346, 347, 348, 349, 352], "concomittantli": 3, "problem": [3, 7, 8, 9, 16, 341, 342, 343, 346, 347, 349, 352], "decor": [3, 8, 11, 114, 264, 279, 280, 281, 282], "set_gym_backend": [3, 84, 87, 88, 102, 108, 112, 333], "relev": [3, 40, 279, 280, 281, 282, 283, 347], "gym_backend": [3, 114, 333], "env1": [3, 345], "path": [3, 6, 7, 32, 34, 35, 36, 38, 39, 41, 42, 45, 52, 53, 54, 55, 56, 57, 58, 59, 61, 66, 84, 88, 102, 108, 114, 140, 162, 199, 315, 337, 341], "venv": 3, "python3": [3, 6, 7, 10], "site": [3, 6, 7, 57, 114], "__init__": [3, 7, 98, 114, 115, 123, 126, 142, 175, 186, 189, 193, 199, 243, 249, 251, 255, 256, 262, 267, 269, 271, 337, 347, 352], "env2": [3, 345], "_env": [3, 6, 87, 352], "classic_control": 3, "pendulumenv": [3, 347], "0x15147e190": 3, "0x1629916a0": 3, "further": [3, 5, 342], "tell": [3, 4, 7, 103, 104, 340, 343, 346], "mo_gymnasium": [3, 96, 112], "handi": 3, "side": [3, 4, 352], "v0": [3, 84, 88, 90, 93, 94, 95, 96, 102, 108, 122, 158, 164, 327], "26": [3, 84, 88, 102, 108, 339, 340, 341, 342, 347, 349, 350], "fun": [3, 11, 114, 342, 346], "reveal": 4, "bug": [4, 351], "curv": 4, "won": [4, 32, 56, 84, 85, 87, 88, 99, 100, 102, 108, 140, 162, 315, 331, 341, 342], "exploit": 4, "video": [4, 9, 298, 311, 331, 346], "cv": 4, "flip": 4, "correspondingli": 4, "prescript": 4, "tune": [4, 134, 346, 348], "coeffici": [4, 40, 134, 346], "bonu": [4, 248, 250, 263, 266], "beta": [4, 35, 41, 64, 255, 262, 263, 340, 341, 349, 351], "reduc": [4, 6, 27, 75, 153, 341, 342], "downstream": [4, 340], "formul": [4, 346], "ob": [4, 8, 26, 28, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 71, 72, 75, 84, 88, 102, 108, 115, 123, 124, 126, 136, 150, 156, 170, 173, 202, 203, 236, 243, 249, 251, 255, 256, 262, 267, 269, 271, 279, 280, 281, 282, 341, 345, 347, 351, 352], "rate": [4, 164, 278, 341, 342, 346], "gradient": [4, 32, 84, 88, 102, 108, 158, 192, 201, 205, 209, 218, 219, 248, 250, 251, 255, 256, 262, 263, 264, 266, 267, 268, 269, 271, 278, 279, 280, 281, 282, 315, 340, 342, 346, 347], "norm": [4, 8, 80, 81, 315, 340, 341, 342, 346, 347], "easier": [4, 335, 340], "behavior": [4, 32, 84, 88, 102, 108, 158, 255, 262, 342, 343, 346, 347], "local": [4, 7, 10, 16, 21, 32, 84, 88, 102, 108, 158, 202, 203, 211, 220, 277, 303, 346], "optima": 4, "sens": [4, 347], "product": [4, 9, 189, 190, 193, 194, 329, 330], "sum": [4, 21, 31, 33, 75, 80, 81, 82, 83, 87, 89, 90, 93, 94, 99, 100, 105, 117, 148, 200, 201, 220, 259, 278, 285, 336, 340, 341, 342, 343, 346, 347, 352], "track": [4, 13, 14, 16, 17, 18, 19, 20, 21, 42, 70, 148, 164, 234, 303, 308, 341, 343, 346, 347, 349], "stat": [4, 136, 319, 331, 341, 342], "w": [4, 66, 118, 120, 144, 156, 189, 234, 298, 341, 343, 349], "r": [4, 32, 115, 121, 136, 150, 190, 239, 247, 278, 335, 341, 347, 352], "yield": [4, 16, 21, 32, 84, 88, 102, 108, 264, 340], "insight": 4, "auxiliari": 4, "credit": 4, "futur": [4, 32, 34, 36, 39, 84, 88, 102, 108, 140, 158, 162, 197, 248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 334, 351], "past": [4, 341, 349], "spars": [4, 343], "ineffici": 4, "ad": [4, 13, 14, 16, 32, 35, 38, 41, 42, 49, 52, 53, 54, 55, 56, 57, 58, 64, 66, 84, 88, 102, 108, 148, 158, 204, 205, 234, 248, 250, 252, 257, 263, 266, 269, 277, 341, 343, 349, 352], "intermedi": [4, 117, 191, 195, 230, 340, 348], "instrument": 4, "greatli": 4, "soccer": 4, "kick": 4, "ball": 4, "likelihood": [4, 340], "discov": 4, "score": [4, 40], "undesir": 4, "though": [4, 84, 88, 102, 108, 197, 342, 346], "unintention": 4, "valuabl": 4, "idiosyncrat": 4, "subtask": 4, "hierarch": [4, 351], "select": [4, 15, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 103, 104, 109, 110, 115, 117, 118, 119, 122, 123, 124, 126, 127, 128, 129, 130, 131, 133, 134, 135, 139, 141, 142, 143, 145, 148, 149, 152, 153, 154, 155, 157, 160, 161, 163, 164, 175, 191, 195, 229, 236, 314, 340, 349], "fall": [4, 52], "explicit": [4, 11, 45, 66, 196, 349], "mechan": [4, 32, 84, 88, 102, 108, 158, 341, 347], "curios": 4, "magnitudin": 4, "domin": 4, "smaller": [4, 34, 36, 39, 84, 88, 102, 108, 193, 255, 262, 342, 346], "addition": 4, "timestep": [4, 40, 52, 145, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 346], "realli": 4, "larg": [4, 27, 34, 36, 39, 123, 126, 160, 341, 342, 346, 349], "huge": [4, 203, 343], "std": [4, 136, 164, 206, 210, 227, 340, 352], "torchrl": [4, 5, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 333, 339, 343, 344, 345, 348, 349, 350], "initi": [4, 7, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 36, 39, 40, 84, 88, 102, 108, 117, 136, 140, 154, 157, 158, 160, 165, 175, 189, 190, 193, 194, 199, 204, 205, 227, 231, 232, 234, 248, 249, 251, 252, 254, 256, 257, 258, 262, 263, 264, 265, 266, 267, 268, 269, 271, 277, 324, 331, 341, 343, 347, 352], "estim": [4, 71, 72, 127, 134, 224, 225, 226, 248, 249, 250, 251, 252, 254, 256, 257, 258, 262, 263, 264, 265, 266, 267, 268, 269, 271, 272, 277, 279, 280, 281, 282, 283, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 336, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "encount": [4, 56, 334, 341, 347], "unseen": 4, "extrins": 4, "wrong": 4, "bonus": 4, "denser": 4, "prior": [4, 214, 259, 346], "freshli": 4, "doesn": [4, 11, 99, 123, 126], "drop": [4, 70, 72, 173], "meant": [4, 98], "encourag": [4, 102, 340, 341, 349], "measur": [4, 80, 81, 93, 94, 342], "novelti": 4, "revisit": 4, "previous": [4, 342, 352], "diminish": 4, "decreas": 4, "ideal": [4, 136, 347], "down": [4, 13, 14, 16, 17, 343], "anyth": 4, "try": [4, 7, 8, 9, 26, 28, 34, 36, 39, 341, 342, 343, 346, 347, 351, 352], "distil": 4, "nois": [4, 165, 205, 222, 234, 267, 271, 311, 331, 340], "exploratori": [4, 248, 250, 263, 266], "misalign": 4, "trade": 4, "unavoid": 4, "schedul": [4, 7, 40, 311, 342, 347], "divers": [4, 102, 108], "bootstrap": [4, 257, 280, 286, 287, 340, 343], "noisi": [4, 204, 205, 222, 335], "unstabl": [4, 192, 218, 219], "inher": 4, "stochast": [4, 134, 187, 205, 207, 214, 249, 253, 255, 256, 262, 265, 267, 269, 335, 342, 346], "enemi": 4, "variabl": [4, 7, 8, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 53, 54, 57, 58, 80, 81, 82, 83, 87, 89, 90, 93, 94, 100, 101, 105, 109, 110, 189, 190, 191, 193, 194, 195, 199, 224, 225, 226, 264, 267, 337, 341], "pomdp": [4, 349], "loos": [4, 335, 341, 342], "nonexist": 4, "architectur": [4, 183, 346], "sequenc": [4, 13, 14, 16, 17, 26, 28, 30, 31, 35, 37, 38, 40, 43, 45, 56, 59, 60, 66, 67, 69, 74, 75, 76, 78, 79, 80, 81, 82, 83, 87, 89, 90, 93, 94, 99, 100, 105, 116, 117, 118, 119, 120, 123, 125, 126, 130, 132, 136, 137, 141, 142, 143, 144, 145, 146, 147, 148, 153, 155, 156, 157, 164, 176, 177, 184, 186, 189, 193, 197, 200, 201, 202, 203, 209, 212, 216, 228, 240, 241, 253, 297, 298, 310, 311, 312, 314, 315, 324, 335, 340, 342, 343, 345, 346, 352], "lstm": [4, 194, 195, 196, 206], "rel": [4, 66, 154, 184, 217, 340, 341, 346, 349], "tend": 4, "stabl": [4, 9, 10, 101], "compens": 4, "descent": [4, 205], "1000": [4, 38, 71, 72, 84, 88, 102, 108, 118, 164, 231, 234, 235, 239, 261, 340, 341, 342, 343, 348, 349], "minimum": [4, 102, 108, 146, 187, 206, 217, 218, 219, 242, 245, 247, 249, 256, 264, 265, 269, 306, 340, 342, 346], "manual": [4, 18, 20, 21, 88, 340, 343, 349], "deviat": [4, 136, 164, 175, 187, 199, 204, 205, 227, 266, 271, 340, 346], "radic": 4, "begin": [4, 13, 14, 16, 18, 19, 20, 21, 189, 190, 193, 194], "stabil": [4, 131], "stage": [4, 340, 347], "never": 4, "prevent": [4, 26, 28, 192, 218, 219, 263, 266, 313, 349], "solv": [4, 9, 10, 334, 340, 341, 342, 346, 347, 349], "entir": [4, 56, 202, 342, 347, 349], "submit": [4, 334, 351], "suffici": [4, 340], "system": [4, 5, 342, 346, 347], "adequ": [4, 166, 342, 346], "infeas": 4, "allevi": [4, 335], "prune": 4, "fire": [4, 32, 84, 88, 102, 108], "certain": [4, 18, 20, 21, 32, 45, 84, 88, 102, 108, 114, 131, 152, 158, 190, 194, 231, 263, 335, 340, 341, 342, 346, 352], "illeg": 4, "move": [4, 21, 32, 58, 84, 88, 102, 108, 122, 124, 140, 154, 157, 158, 160, 162, 164, 173, 197, 238, 313, 340, 341, 343, 351, 352], "chess": 4, "combin": [4, 157, 341, 349], "grasp": 4, "releas": [4, 7, 10, 32, 84, 88, 102, 108, 158, 269, 351], "top": [4, 75, 80, 81, 93, 94, 175, 199], "wherein": 4, "cumul": [4, 148, 153, 175, 285, 342], "q": [4, 9, 84, 88, 102, 108, 179, 180, 181, 182, 185, 186, 188, 211, 212, 220, 226, 230, 236, 237, 249, 251, 252, 254, 255, 256, 257, 261, 262, 267, 269, 271, 277, 324, 333, 340], "flow": [4, 340, 342, 346, 347, 349], "reparameter": [4, 184, 201, 209], "soft": [4, 261, 269, 270], "critic": [4, 8, 224, 233, 248, 250, 251, 255, 256, 262, 263, 266, 267, 268, 269, 271, 340, 342], "clip": [4, 40, 121, 146, 250, 271, 315, 342, 346, 347], "oppos": [4, 45], "incorrect": 4, "thought": [4, 84, 88, 102, 108], "bound": [4, 17, 21, 25, 26, 32, 84, 88, 102, 108, 121, 135, 164, 213, 214, 223, 229, 230, 234, 235, 236, 237, 238, 239, 242, 271, 335, 340, 341, 342, 352], "region": 4, "squash": [4, 343, 351], "tanh": [4, 176, 177, 189, 190, 192, 193, 194, 197, 203, 217, 218, 219, 242, 342, 346, 347, 348, 351], "correct": [4, 34, 36, 39, 84, 88, 102, 108, 134, 318, 342, 343], "prob": [4, 200, 201, 209, 342, 346], "rememb": 4, "remap": 4, "origin": [4, 8, 13, 14, 16, 17, 34, 36, 39, 40, 92, 124, 125, 134, 140, 158, 162, 189, 235, 238, 239, 261, 264, 266, 324, 340, 345, 347, 352], "real": [5, 56, 239, 336, 343, 347], "histor": 5, "ceas": 5, "fork": 5, "farama": [5, 95, 96, 103, 104, 342, 347], "usag": [5, 7, 52, 54, 56, 57, 58, 118, 127, 191, 195, 255, 262, 269, 272, 335, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "bc": [5, 351], "break": [5, 13, 14, 16, 21, 32, 38, 42, 53, 54, 56, 57, 58, 59, 71, 72, 84, 88, 102, 108, 118, 145, 164, 341, 349, 351], "against": [5, 7, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 84, 88, 102, 108, 166, 223, 229, 230, 235, 236, 237, 238, 239, 342, 346], "13": [5, 10, 11, 71, 72, 105, 163, 340, 341, 343, 347, 348, 349], "construct": [5, 32, 35, 38, 41, 42, 66, 84, 87, 88, 102, 103, 108, 123, 126, 166, 191, 195, 214, 239, 315, 335, 341, 342, 343, 347, 349, 352], "best": [5, 9, 92, 191, 195, 346, 349, 351], "gymwrapp": [5, 84, 88, 102, 108, 128, 149, 152, 163, 333, 342, 351], "feel": [5, 334, 351], "free": [5, 7, 123, 126, 248, 259, 266, 337, 342, 346, 351], "gladli": 5, "instruct": [6, 7, 10, 22, 52, 125, 127, 340, 341, 342, 343, 346, 349], "prepar": [6, 53, 342], "conda": [6, 7, 334], "7": [6, 10, 27, 33, 35, 38, 41, 72, 84, 88, 102, 108, 153, 175, 176, 177, 196, 197, 199, 202, 285, 339, 340, 341, 346, 347, 349, 350, 351], "cmake": 6, "14": [6, 11, 58, 71, 72, 84, 88, 102, 108, 136, 339, 340, 341, 342, 343, 347, 349, 350], "activ": [6, 7, 9, 176, 177, 183, 187, 197, 202, 203, 250, 263, 266, 335, 347, 351], "sim": 6, "bullet": 6, "physic": [6, 7, 102, 105, 337, 340, 346, 347], "headless": [6, 7], "cluster": [6, 7, 8, 18, 21, 53, 334], "withbullet": 6, "forg": [6, 7], "aihabitat": [6, 90], "nightli": 6, "y": [6, 7, 101, 196, 202, 221, 340, 342, 346], "git": [6, 7, 10], "facebookresearch": [6, 53, 90], "subdirectori": 6, "verbos": 6, "export": [6, 7], "magnum_log": 6, "quiet": 6, "habitat_sim_log": 6, "remov": [6, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 44, 46, 47, 49, 84, 88, 102, 108, 142, 151, 264, 346, 352], "command": [6, 7, 10, 342, 346, 347, 352], "readm": [6, 7, 109], "md": [6, 7], "habitatenv": [6, 333], "_has_habitat": 6, "available_env": [6, 80, 81, 82, 83, 84, 87, 88, 89, 90, 93, 94, 95, 101, 102, 105, 106, 107, 108, 109, 110, 352], "startswith": [6, 336, 340], "oserror": 6, "libllvmlit": 6, "ionstal": 6, "pointer": [6, 85, 264, 340], "env_nam": [6, 80, 82, 84, 87, 88, 90, 93, 95, 99, 102, 105, 108, 340, 342, 352], "llvmlite": 6, "config": [6, 7, 140, 162, 178, 183, 210, 319, 320, 321, 324, 325, 328], "var": [6, 7, 32, 84, 88, 102, 108, 158, 264, 269], "ld_preload": [6, 7], "8": [6, 7, 38, 56, 57, 64, 71, 72, 80, 81, 82, 83, 84, 88, 102, 108, 153, 176, 177, 179, 180, 188, 197, 224, 225, 226, 235, 238, 241, 262, 339, 340, 341, 342, 343, 346, 347, 348, 349, 350, 351], "bind": 6, "deactiv": [6, 7, 229], "importerror": [6, 7, 10], "usr": [6, 7, 10], "x86_64": [6, 7], "linux": [6, 7], "gnu": [6, 7], "libopengl": [6, 7], "undefin": [6, 7, 10, 32, 84, 88, 102, 108, 158, 264, 269, 349], "symbol": [6, 7, 10], "_glapi_tls_curr": [6, 7], "link": [6, 7, 341], "mujoco_env": [6, 7], "libglvnd": [6, 7], "glx": [6, 7], "cos7": [6, 7], "reinstal": [6, 7], "xvfbwrapper": [6, 7], "sysroot": [6, 7], "lib64": [6, 7], "libgldispatch": [6, 7], "offici": [7, 52], "stand": [7, 82, 83, 345, 347, 352], "joint": [7, 341], "dynam": [7, 53, 56, 58, 255, 262, 342, 347], "contact": [7, 37], "engin": [7, 105, 347], "biomechan": 7, "graphic": 7, "anim": [7, 346], "area": 7, "demand": [7, 352], "fast": [7, 9, 80, 81, 143, 267, 340, 341, 342], "accur": [7, 52, 54, 56, 57, 58, 341, 347, 349], "articul": 7, "recent": [7, 11, 163, 352], "acquir": [7, 342], "deepmind": [7, 8, 9, 56, 82, 83, 84, 88, 102, 108, 127, 342], "whomev": 7, "licenc": 7, "incorpor": [7, 84, 88, 102, 108, 227, 231, 232, 234, 343, 347], "relianc": 7, "obsolet": 7, "seri": [7, 8, 33, 60, 67, 75, 76, 78, 79, 108, 135, 157, 298, 335, 336, 340, 341, 342, 346, 349, 352], "legaci": 7, "pro": [7, 334], "tip": [7, 334], "glfw": 7, "osmesa": 7, "egl": 7, "advic": [7, 56, 352], "sudo": [7, 334], "enabl": [7, 8, 52, 61, 62, 70, 77, 191, 195, 234, 311, 342, 346, 347, 349], "apt": [7, 346], "libglfw3": 7, "libglew2": 7, "libgl1": 7, "mesa": 7, "libosmesa6": 7, "awar": [7, 61, 62, 63, 73, 74, 77, 341, 343], "workflow": [7, 224, 225, 226], "glew": 7, "mesalib": 7, "anaconda": 7, "libgl": 7, "cos6": 7, "menpo": 7, "glfw3": 7, "mujoco_gl": 7, "pyopengl_platform": 7, "pre": [7, 22, 32, 45, 56, 62, 84, 88, 102, 108, 140, 160, 162, 352], "binari": [7, 24, 27, 33, 116, 186, 212, 229, 230, 236, 237, 252, 255, 256, 277], "setup": [7, 80, 81, 92, 93, 94], "mkdir": 7, "cd": 7, "tag": [7, 298, 303, 331], "earlier": [7, 340, 342, 343, 346, 349], "roboti": 7, "download": [7, 10, 52, 53, 54, 56, 57, 58, 92, 140, 162, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 351, 352], "html": [7, 99, 101], "wget": 7, "mujoco210": 7, "tar": [7, 53], "gz": 7, "xf": 7, "charg": [7, 13, 14, 102, 108], "obtain": [7, 40, 84, 88, 102, 108, 117, 140, 153, 162, 175, 211, 312, 340, 342, 346], "mjkei": 7, "txt": 7, "mjlib_path": 7, "home": [7, 34, 36, 45, 59], "bin": [7, 186, 230, 335], "libmujoco210": 7, "ld_library_path": 7, "mujoco_py_mujoco_path": 7, "mujoco_py_mjkey_path": 7, "reload": 7, "later": [7, 182, 235, 239, 340, 342, 349], "nvidia": [7, 92], "older": [7, 11], "hack": [7, 340], "line": [7, 32, 84, 88, 102, 108, 341, 346], "adatp": 7, "script": [7, 53, 166, 324, 327, 331, 335, 336, 337, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "unnot": [7, 141], "until": [7, 21, 155, 157, 342, 343, 346], "complet": [7, 9, 70, 88, 118, 152, 334, 336, 340, 342, 345], "mujoco_pi": 7, "trigger": 7, "cymj": 7, "linuxgpuextensionbuild": 7, "filenam": [7, 341, 349], "troubleshoot": 7, "gl": 7, "h": [7, 66, 118, 120, 144, 156, 189, 190, 191, 193, 194, 195, 199, 298, 341, 343, 349], "eglshim": 7, "fatal": 7, "No": 7, "directori": [7, 34, 36, 39, 45, 52, 53, 54, 56, 57, 58, 61, 303, 337], "devel": 7, "ubuntu": [7, 92], "libglew": 7, "dev": 7, "cento": 7, "yum": 7, "glu": 7, "38": [7, 341, 347, 348, 349], "disappear": [7, 341, 343, 345], "libstdc": 7, "6": [7, 13, 14, 16, 17, 38, 57, 58, 72, 82, 83, 102, 106, 107, 136, 138, 153, 176, 177, 184, 190, 196, 197, 202, 203, 207, 217, 235, 243, 324, 339, 340, 341, 346, 347, 349, 350, 351, 352], "glibcxx_3": 7, "29": [7, 341, 342, 347], "compil": [7, 32, 84, 88, 102, 108, 189, 190, 193, 194], "libosmesa": 7, "libgcc": 7, "Then": [7, 163, 342, 345], "filenotfounderror": 7, "errno": 7, "patchelf": 7, "fatalerror": 7, "gladloadgl": 7, "mj_env": 7, "912": 7, "glfwerror": 7, "65537": 7, "sovl": 7, "myscript": 7, "runtimeerror": [7, 8, 26, 28, 32, 84, 88, 102, 108, 135, 158, 269, 352], "job": [7, 18, 19, 20, 22], "slurm": 7, "mjrendercontext": 7, "pyx": 7, "46": [7, 80, 81, 341, 343, 347, 348], "114": [7, 343, 347, 349], "_setup_opengl_context": 7, "opengl_context": 7, "130": [7, 347], "offscreenopenglcontext": 7, "fail": [7, 22, 26, 28, 102, 115, 166], "opengl": [7, 346], "global": [7, 32, 84, 88, 102, 103, 104, 108, 211, 220, 235, 239, 277, 337, 340, 346], "cuda_visible_devic": 7, "id": [7, 23, 40, 66, 84, 87, 88, 102, 108, 234, 267, 301, 324], "slurm_step_gpu": 7, "enviro": [7, 10], "black": 7, "onscreen": 7, "101": [7, 347, 349], "correctli": [7, 32, 84, 88, 102, 108], "lgl": 7, "libegl": 7, "x11": [7, 346], "xlib": 7, "libx11": 7, "xorg": 7, "loop": [8, 13, 14, 16, 17, 34, 36, 39, 88, 173, 227, 231, 232, 234, 266, 315, 337, 340, 341, 345, 349], "sketch": [8, 337], "n_training_step": 8, "datapoint": [8, 45, 349], "onlin": [8, 13, 17, 118, 183, 210, 248, 253, 265, 266, 306, 331, 342, 343, 346, 349], "n_data_per_train": 8, "no_grad": [8, 32, 84, 88, 102, 108, 134, 189, 190, 193, 194, 279, 280, 281, 282, 342, 343, 346], "replay_buff": [8, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 312, 327, 340, 341, 342, 346, 349], "loss_fn": [8, 343, 351], "backward": [8, 32, 80, 81, 84, 88, 102, 108, 164, 189, 190, 193, 194, 248, 249, 251, 255, 256, 262, 266, 267, 268, 269, 271, 340, 342, 343, 346, 347], "zero_grad": [8, 32, 84, 88, 102, 108, 337, 340, 342, 343, 346, 347], "backpropag": [8, 80, 81, 93, 94, 248, 249, 250, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 346, 347], "differenti": [8, 45, 80, 81, 134, 279, 280, 281, 282, 343, 346, 347], "denomin": 8, "artifact": 8, "numer": [8, 38, 88, 164, 192, 218, 219, 223, 229, 230, 235, 236, 237, 238, 239, 313, 342, 349, 352], "misconcept": 8, "freed": 8, "appear": [8, 33, 56, 71, 72, 347, 349], "compuat": 8, "twice": 8, "fix": [8, 102, 154, 249, 265, 269, 341, 347, 352], "retain_graph": [8, 80, 81], "discuss": [8, 9, 346], "inplac": [8, 32, 34, 36, 39, 84, 88, 102, 108, 158, 269, 340], "accumul": 8, "onto": [8, 33, 34, 36, 39, 170, 223, 227, 229, 230, 234, 235, 236, 237, 238, 239, 343, 347], "exclud": [8, 52, 57, 84, 88, 102, 108, 118, 128, 173, 211, 346, 349], "forward": [8, 32, 84, 88, 102, 108, 115, 117, 118, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 136, 139, 140, 141, 142, 143, 145, 148, 149, 152, 153, 154, 155, 157, 160, 161, 163, 164, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 202, 203, 204, 206, 207, 208, 210, 211, 213, 214, 216, 220, 221, 227, 228, 230, 231, 232, 234, 235, 237, 238, 239, 242, 243, 245, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 283, 336, 347, 351], "submodul": [8, 32, 84, 88, 102, 108, 112, 264], "param": [8, 32, 40, 84, 88, 98, 102, 108, 122, 123, 124, 128, 134, 142, 143, 149, 152, 157, 184, 186, 217, 228, 235, 238, 241, 243, 264, 273, 276, 279, 280, 281, 282, 283, 340, 346, 347, 348, 351], "grad": [8, 32, 80, 81, 84, 88, 102, 108, 340, 342], "whose": [8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 44, 46, 47, 84, 88, 102, 103, 104, 108, 122, 140, 154, 157, 158, 160, 162, 206, 211, 238], "neg": [8, 13, 14, 16, 17, 18, 19, 20, 21, 35, 41, 64, 118, 130, 141, 159, 258, 336, 342, 346, 347], "ask": [8, 56, 71, 72, 340, 342, 343, 346, 348, 352], "much": [8, 13, 14, 35, 41, 56, 64, 102, 108, 263, 266, 342, 346, 347, 349, 352], "render": [8, 109, 311, 340, 341, 342], "upon": [8, 347], "factor": [8, 32, 145, 192, 205, 218, 219, 227, 231, 232, 234, 249, 254, 257, 258, 260, 270, 285, 340, 341, 346, 349, 352], "fit": [8, 11, 136, 336, 337, 340], "bottlneck": 8, "brax": [8, 80, 81, 84, 88, 102, 108, 143, 352], "jax": [8, 11, 80, 81, 93, 94], "improperli": 8, "item": [8, 13, 26, 28, 32, 38, 45, 59, 70, 75, 84, 88, 102, 108, 129, 158, 200, 201, 251, 252, 254, 269, 306, 336, 337, 340, 342, 343, 346, 347, 349], "underli": [8, 84, 88, 102, 108, 264, 347], "tedeiou": 8, "priorit": [8, 35, 41, 64, 251, 252, 254, 255, 256, 262, 267, 269, 271, 340, 341], "amount": [8, 234, 341, 349], "contigu": [8, 53, 56, 57, 84, 88, 102, 108, 170, 342, 346, 347, 349, 351, 352], "costli": [8, 347], "concaten": [8, 21, 30, 31, 56, 118, 119, 136, 157, 193, 197, 241, 340, 341, 346, 347, 349, 352], "constitut": [8, 341, 346, 347], "plain": 8, "profil": 8, "fulli": [8, 32, 84, 88, 102, 108, 190, 194, 341, 347, 349], "frequent": [8, 349], "program": [8, 255, 262, 352], "functorch": [8, 10], "incl": 8, "suit": [8, 83, 342, 352], "mujoco_instal": 8, "valueerror": 8, "bad": 8, "fds_to_keep": 8, "expand": [8, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 39, 44, 46, 47, 71, 72, 238, 241, 264, 346, 347, 351], "new_shap": 8, "permut": [8, 70, 138, 351, 352], "idea": [9, 267, 337, 343, 346], "introductori": 9, "intro": [9, 342, 343], "dai": [9, 351], "2022": [9, 10, 347, 351], "spin": [9, 82, 83, 352], "deep": [9, 118, 179, 180, 181, 182, 185, 234, 248, 261, 269, 270, 340], "hug": 9, "syllabu": 9, "lectur": 9, "awesom": 9, "curat": 9, "succinct": 9, "summari": [9, 136, 164, 340, 341, 342, 343], "reddit": 9, "reagent": 9, "orient": [9, 58, 352], "baselines3": 9, "tf": 9, "bandit": [9, 101], "tensorflow": [9, 200, 201], "kera": 9, "acm": 9, "dopamin": 9, "prototyp": 9, "salina": 9, "sequenti": [9, 32, 84, 88, 102, 108, 117, 134, 240, 241, 266, 335, 342, 343, 346, 347, 348, 352], "tianshou": 9, "eleg": 9, "rlpyt": 9, "rllib": 9, "industri": [9, 351], "grade": 9, "factori": [9, 43], "throughput": [9, 340], "cherri": 9, "jaxrl": 9, "space": [9, 33, 44, 84, 88, 102, 108, 121, 125, 170, 183, 186, 202, 208, 212, 223, 227, 229, 230, 232, 234, 235, 236, 237, 238, 239, 241, 242, 243, 252, 254, 255, 256, 271, 277, 335, 341, 342, 343, 346, 347, 351, 352], "mbrl": [9, 98, 335], "rlmeta": 9, "light": 9, "elegantrl": 9, "cloud": 9, "mtrl": 9, "baselin": 9, "689": [10, 347], "_torchrl": 10, "_zn8pybind116detail11type_casterin2at6tensoreve4loadens_6handleeb": 10, "colab": [10, 342, 343, 346], "notebook": [10, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 351, 352], "24": [10, 57, 72, 87, 99, 100, 341, 342, 346, 347], "11": [10, 27, 33, 45, 61, 62, 72, 77, 85, 156, 175, 199, 339, 340, 341, 342, 343, 346, 347, 349, 350], "12": [10, 57, 61, 62, 72, 77, 93, 94, 106, 107, 340, 341, 343, 346, 347, 349], "pip": [10, 55, 346, 351, 352], "pip3": [10, 342, 343, 346], "extra": [10, 32, 84, 88, 102, 108, 118, 164, 173, 335, 342, 343, 349], "url": [10, 90], "org": [10, 35, 53, 56, 58, 64, 80, 81, 82, 83, 90, 93, 94, 99, 100, 101, 105, 109, 110, 118, 140, 160, 178, 179, 180, 181, 182, 183, 186, 187, 188, 193, 199, 200, 201, 205, 207, 208, 210, 211, 213, 214, 220, 230, 234, 248, 249, 252, 253, 254, 255, 257, 258, 259, 260, 261, 262, 265, 266, 268, 269, 270, 279, 284, 292, 348], "whl": 10, "u": [10, 55, 189, 190, 193, 194, 347], "There": [10, 66, 191, 195, 335, 337, 342, 343, 346, 347, 349, 352], "upgrad": 10, "relas": 10, "lib_version_her": 10, "module_nam": [11, 264], "str": [11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 66, 75, 80, 82, 83, 84, 86, 87, 88, 89, 90, 93, 99, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 115, 118, 125, 127, 133, 134, 136, 140, 141, 144, 149, 152, 153, 158, 160, 162, 163, 164, 167, 171, 173, 174, 175, 176, 177, 179, 180, 181, 182, 185, 186, 188, 191, 195, 196, 197, 198, 199, 202, 203, 204, 205, 206, 211, 212, 220, 223, 229, 230, 235, 236, 237, 238, 239, 242, 243, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 271, 274, 277, 278, 279, 280, 281, 282, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 317, 319, 324, 325, 331, 341, 342], "callabl": [11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 38, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 66, 84, 85, 88, 98, 102, 108, 114, 127, 247, 320, 321, 329, 330, 331, 341], "from_vers": 11, "to_vers": 11, "class_method": 11, "intersect": 11, "vs": [11, 191, 195, 196, 351], "longer": [11, 341, 346, 349], "self": [11, 26, 28, 32, 34, 36, 39, 84, 88, 98, 102, 108, 115, 122, 123, 126, 140, 142, 154, 157, 158, 160, 162, 175, 186, 199, 211, 220, 227, 231, 232, 235, 238, 243, 248, 249, 251, 252, 254, 255, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 279, 280, 281, 282, 283, 337, 340, 347, 351], "x": [11, 23, 26, 32, 38, 40, 56, 72, 134, 156, 177, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 199, 202, 203, 221, 229, 235, 236, 245, 247, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 298, 315, 340, 342, 347, 349, 351], "23": [11, 57, 72, 341, 342, 347], "lambda": [11, 13, 14, 16, 17, 21, 22, 38, 84, 85, 88, 102, 108, 114, 134, 154, 221, 229, 236, 258, 260, 279, 282, 290, 291, 295, 296, 327, 336, 340, 341, 346, 349, 351, 352], "import_modul": 11, "get_class_that_defined_method": 11, "f": [11, 80, 81, 88, 93, 94, 194, 247, 279, 280, 281, 282, 283, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 340, 341, 342, 343, 346, 347, 349, 352], "otherwis": [11, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 43, 44, 45, 46, 47, 52, 59, 71, 72, 80, 81, 84, 87, 88, 89, 90, 93, 94, 97, 99, 100, 102, 103, 104, 105, 108, 109, 110, 118, 125, 136, 153, 154, 155, 158, 164, 189, 192, 193, 202, 203, 218, 219, 229, 236, 242, 249, 259, 264, 265, 269, 311, 312, 337, 340, 341, 342, 343, 347, 352], "classmethod": [11, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 39, 44, 46, 47, 84, 88, 102, 108, 160, 178, 210], "module_set": 11, "setters_dict": 11, "dict": [11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 29, 30, 32, 34, 36, 39, 57, 84, 85, 88, 99, 102, 103, 104, 108, 109, 110, 111, 134, 154, 158, 163, 164, 176, 177, 178, 179, 180, 181, 182, 183, 188, 196, 197, 210, 235, 239, 269, 302, 303, 311, 320, 321, 324, 329, 330, 331, 340, 341, 342, 352], "setter": 11, "setter_dict": 11, "copi": [11, 18, 19, 20, 21, 32, 34, 36, 39, 40, 45, 56, 84, 88, 102, 108, 143, 153, 158, 173, 191, 195, 228, 264, 269, 336, 340, 341, 343, 349], "kwd": 12, "policy_weight": [12, 13, 14, 16, 17, 19, 20], "tensordictbas": [12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 26, 28, 29, 32, 41, 42, 52, 53, 54, 55, 56, 57, 58, 84, 86, 88, 102, 108, 115, 117, 118, 119, 122, 123, 124, 127, 128, 129, 130, 133, 134, 139, 141, 142, 143, 145, 148, 149, 152, 153, 154, 155, 157, 163, 164, 173, 174, 175, 191, 195, 198, 199, 227, 228, 230, 231, 232, 234, 237, 238, 239, 248, 249, 250, 251, 252, 253, 254, 256, 257, 262, 263, 264, 265, 266, 267, 268, 269, 271, 277, 278, 279, 280, 281, 282, 283, 315, 340, 347], "udpdat": [12, 13, 14, 16, 17, 19, 20], "create_env_fn": [13, 14, 16, 17, 18, 19, 20, 21, 85, 102, 108, 340, 351], "int": [13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 71, 72, 73, 75, 76, 77, 78, 80, 81, 82, 83, 84, 87, 88, 89, 90, 93, 94, 98, 99, 100, 102, 103, 104, 105, 108, 109, 110, 117, 118, 119, 120, 125, 130, 131, 135, 136, 138, 140, 141, 144, 151, 152, 155, 158, 159, 160, 162, 166, 170, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 192, 193, 194, 196, 197, 199, 200, 201, 202, 203, 204, 205, 207, 208, 210, 211, 212, 213, 214, 216, 217, 218, 220, 221, 227, 228, 229, 230, 231, 232, 234, 235, 237, 238, 239, 248, 249, 250, 256, 258, 259, 263, 264, 265, 266, 267, 271, 284, 285, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 306, 307, 308, 311, 312, 315, 317, 324, 325, 329, 330, 331, 347], "200": [13, 14, 16, 17, 21, 32, 84, 87, 88, 89, 102, 108, 109, 110, 145, 179, 180, 187, 213, 214, 340, 343, 347], "total_fram": [13, 14, 16, 17, 18, 19, 20, 21, 118, 145, 315, 318, 327, 337, 340, 341, 342, 343, 346, 349, 351], "device_typ": [13, 16, 27, 30, 33, 176, 177, 178, 179, 180, 181, 182, 188, 197, 204, 205, 210], "create_env_kwarg": [13, 14, 16, 17, 85, 99, 102, 108, 340], "postproc": [13, 14, 16, 17, 18, 19, 20, 21, 145, 341, 349], "explorationtyp": [13, 14, 16, 20, 21, 264, 311, 340, 341, 342, 343, 351], "interactiontyp": [13, 16, 18, 19, 20, 21, 168, 172, 235, 239, 311], "exploration_mod": [13, 16, 18, 19, 20, 333, 335], "preemptive_threshold": [13, 14], "float": [13, 14, 25, 27, 32, 33, 35, 40, 41, 46, 56, 64, 66, 84, 88, 102, 108, 118, 122, 123, 126, 134, 136, 140, 145, 146, 147, 153, 154, 156, 157, 158, 160, 162, 164, 184, 187, 189, 192, 193, 197, 200, 201, 204, 205, 213, 214, 217, 219, 227, 238, 242, 245, 246, 247, 248, 249, 254, 255, 256, 259, 260, 261, 262, 265, 267, 269, 270, 271, 278, 284, 285, 286, 287, 288, 289, 290, 291, 292, 313, 340, 341, 349, 352], "num_thread": [13, 14, 34, 36, 39, 102, 108], "num_sub_thread": [13, 14, 102, 108], "datacollector": [13, 14, 16, 17, 235, 239, 266, 342], "recept": 13, "safe": [13, 14, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 223, 227, 229, 230, 234, 235, 236, 237, 238, 239, 241, 335, 351], "stepcount": [13, 84, 88, 102, 108, 109, 110, 157, 340, 341, 342, 343, 346, 351], "env_mak": [13, 14, 16, 21, 327, 352], "50": [13, 14, 16, 21, 37, 40, 58, 71, 72, 341, 342, 343, 346, 347, 348], "2000": [13, 14, 16, 45, 91, 342, 349], "enumer": [13, 14, 16, 21, 32, 38, 42, 72, 84, 88, 102, 108, 272, 336, 340, 341, 342, 343, 349, 351], "int64": [13, 14, 16, 27, 30, 34, 36, 37, 39, 40, 41, 43, 45, 54, 56, 57, 58, 59, 84, 88, 97, 101, 102, 103, 104, 106, 107, 108, 127, 138, 145, 152, 186, 212, 229, 230, 234, 235, 236, 237, 335, 342, 343, 347, 349, 351, 352], "step_count": [13, 14, 16, 84, 88, 93, 94, 102, 108, 152, 342, 343, 351], "shutdown": [13, 14, 16, 17, 21, 340, 351], "del": [13, 14, 16, 340, 342, 345, 351, 352], "randompolici": [13, 14, 16, 18, 19, 20, 22, 118, 145, 333, 349], "lifespan": [13, 14, 16, 18, 19, 20, 341], "divis": [13, 14, 16, 18, 19, 20, 56, 71, 72, 346], "endless": [13, 14, 16, 18, 19, 20], "dictionari": [13, 14, 16, 17, 18, 19, 20, 21, 26, 32, 34, 36, 39, 45, 69, 71, 72, 84, 87, 88, 89, 102, 108, 109, 110, 154, 158, 235, 239, 269, 311, 329, 330, 331, 337, 341, 342, 347, 352], "span": [13, 14, 16, 17, 18, 19, 20, 21, 56], "n_step": [13, 14, 16, 17, 18, 19, 20, 21, 32, 341, 342, 346], "ignor": [13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 37, 43, 44, 46, 47, 84, 88, 102, 108, 125, 128, 149, 156, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 200, 201, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 242, 245, 279, 349], "mainli": [13, 14, 16, 17, 18, 19, 20, 21, 40, 335, 346, 347], "round": [13, 14, 16], "closest": [13, 14, 16], "post": [13, 14, 16, 18, 19, 20, 21, 32, 54, 84, 88, 102, 108], "multistep": [13, 14, 16, 18, 19, 20, 21, 333, 341], "return_same_td": [13, 14, 16], "cautious": [13, 14, 16, 266], "whole": [13, 14, 16, 26, 28, 32, 45, 84, 88, 102, 108, 158, 235, 269, 306, 340, 342], "boolm": [13, 14], "update_policy_weight_": [13, 14], "sync": [13, 14, 18, 19, 20, 21, 317, 327, 337, 340, 351], "async": [13, 14, 18, 19, 20, 21, 163, 340, 351], "ratio": [13, 14, 40, 340, 342], "finish": [13, 14, 21, 88, 145, 352], "rest": [13, 14, 335, 342, 343, 347, 351], "earli": [13, 14, 88, 152, 351], "thread": [13, 14, 34, 36, 39, 80, 81, 93, 94, 102, 108], "equal": [13, 14, 71, 72, 99, 102, 108, 135, 136, 176, 177, 185, 189, 191, 193, 195, 197, 203, 270, 274, 306, 329, 330, 340, 342, 348], "plu": [13, 14, 40, 102, 108, 347], "safeti": [13, 14, 98, 102, 108], "harm": [13, 14, 102, 108], "ordereddict": [13, 14, 16, 17, 21, 32, 84, 88, 102, 108, 158, 164, 269, 341], "form": [13, 14, 17, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 84, 88, 102, 108, 164, 189, 191, 193, 195, 247, 248, 250, 263, 266, 315, 335, 346], "worker0": [13, 14, 17], "state_dict0": [13, 14, 17], "worker1": [13, 14, 17], "state_dict1": [13, 14, 17], "reset_idx": [13, 14, 17], "static_se": [13, 14, 16, 17, 21, 84, 88, 102, 108, 158], "integ": [13, 14, 16, 17, 23, 30, 31, 32, 33, 40, 47, 73, 84, 88, 102, 108, 127, 131, 136, 152, 176, 177, 197, 202, 203, 255, 262, 269, 349], "increment": [13, 14, 16, 17, 84, 88, 102, 108, 263], "env_fn": [13, 14, 16, 17, 85, 329, 330], "env_fn_parallel": [13, 14, 16, 17], "100": [13, 14, 16, 17, 32, 35, 38, 41, 42, 43, 52, 53, 54, 55, 56, 57, 58, 61, 62, 66, 80, 81, 84, 88, 93, 94, 102, 108, 121, 127, 136, 145, 150, 152, 202, 230, 307, 327, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "300": [13, 14, 16, 17, 71, 72, 181, 182, 347], "out_se": [13, 14, 16, 17, 352], "shut": [13, 14, 16, 17], "irrevers": [13, 14, 17], "kwarg": [14, 16, 17, 21, 25, 26, 32, 46, 52, 53, 61, 62, 66, 75, 77, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 113, 115, 122, 140, 142, 151, 154, 157, 158, 159, 161, 162, 165, 175, 176, 177, 179, 180, 181, 182, 185, 188, 191, 192, 195, 197, 198, 199, 202, 203, 209, 217, 219, 221, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 271, 273, 277, 278, 279, 280, 281, 282, 283, 298, 302, 303, 305, 308, 315, 320, 321, 324, 328, 329, 330, 336, 342, 346], "tupl": [15, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 57, 58, 66, 74, 75, 82, 83, 84, 88, 102, 108, 115, 125, 127, 133, 134, 136, 141, 149, 173, 179, 185, 186, 191, 194, 195, 196, 197, 203, 206, 210, 211, 212, 229, 230, 236, 237, 242, 248, 249, 251, 255, 256, 258, 262, 264, 266, 267, 268, 269, 271, 279, 280, 281, 282, 298, 309, 311, 313, 322, 323, 340], "rand": [15, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 38, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 57, 58, 66, 80, 81, 93, 94, 98, 115, 123, 126, 142, 175, 199, 235, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 269, 271, 347, 351, 352], "describ": [15, 44, 119, 157, 217, 218, 252, 301, 336, 340, 342, 346, 347, 352], "tensor_spec": [15, 115, 174, 255, 256, 266, 268], "boundedtensorspec": [15, 22, 26, 84, 88, 102, 108, 231, 232, 234, 235, 242, 248, 249, 251, 262, 266, 267, 269, 271, 333, 342, 346, 347, 351, 352], "cube": 15, "envcreat": [16, 22, 327, 328, 331, 333, 340, 341, 351, 352], "interruptor": 16, "_interruptor": 16, "start_collect": 16, "stop_collect": 16, "preeptiv": 16, "chunk": 16, "policy_state_dict": 16, "env_state_dict": 16, "close": [16, 17, 88, 99, 134, 248, 250, 263, 266, 340, 345, 347, 351], "pin_memori": [17, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 139, 340, 351], "regular": [17, 34, 36, 39, 69, 84, 88, 102, 108, 158, 212, 230, 236, 237, 238, 239, 257, 317, 333, 337, 340, 341, 349, 352], "mere": 17, "greater": [17, 71, 72, 191, 195, 340, 341, 351], "sent": [17, 61, 62, 77, 164], "server": 17, "postprocessor": 17, "collector_class": [18, 19, 20, 21], "collector_kwarg": [18, 19, 20, 21], "num_workers_per_collector": [18, 19, 20, 21], "slurm_kwarg": [18, 19, 20], "update_after_each_batch": [18, 20, 21], "max_weight_update_interv": [18, 19, 20, 21], "tcp_port": [18, 19, 20, 22], "deriv": [18, 19, 20, 21, 315], "string": [18, 19, 20, 32, 37, 45, 59, 84, 88, 102, 108, 114, 140, 152, 162, 191, 195, 229, 235, 236, 247, 297, 314, 324, 336, 340, 342, 343], "respect": [18, 19, 20, 32, 84, 88, 102, 108, 116, 122, 123, 126, 140, 141, 150, 154, 157, 158, 160, 162, 189, 193, 202, 214, 238, 243, 310, 342, 343, 346], "subnod": [18, 19, 20, 21], "readi": [18, 20, 21, 334, 341, 342, 345, 349], "serv": [18, 20, 21, 90, 349, 352], "fashion": [18, 20, 21, 34, 36, 39, 72], "executor": [18, 19, 20], "distributed_back": [18, 19], "ucc": [18, 19], "overwritten": [18, 20, 21, 53, 54, 56, 57, 58, 84, 88, 102, 108, 130], "seen": [18, 20, 21, 84, 88, 102, 108, 336, 340, 341, 343, 346, 349], "turn": [18, 20, 21, 34, 36, 39, 132, 159, 163, 229, 311, 336, 340, 341, 343, 347, 348], "submitit_delai": [18, 22], "former": [18, 19, 20, 35, 38, 41, 42, 52, 84, 88, 102, 108, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 242, 245, 340], "whilst": [18, 19, 20], "latter": [18, 19, 20, 32, 52, 84, 88, 102, 108, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 242, 245, 266, 329, 330], "homonym": [18, 19, 20, 347], "visit": [18, 19, 20], "facebookincub": [18, 19, 20], "tcp": [18, 19, 20, 22], "port": [18, 19, 20, 22], "10003": [18, 19, 20, 22], "worker_rank": [18, 19, 21], "update_interv": 19, "frequenc": [19, 340], "visible_devic": 20, "tensorpipe_opt": 20, "experiment": [20, 33, 235, 239], "tensorpiperpcbackendopt": 20, "_td": [21, 85], "ray_init_config": 21, "remote_config": 21, "num_collector": [21, 329, 330, 340, 341], "coordin": 21, "init": [21, 32, 84, 88, 102, 108, 340, 341, 342], "autodetect": 21, "similarli": [21, 32, 70, 74, 84, 88, 102, 108, 202, 240, 241, 255, 262, 352], "num_cpu": 21, "num_gpu": 21, "1024": [21, 183, 341, 349], "equat": [21, 56, 88, 234, 247, 250, 270, 342, 347], "exce": [21, 342, 349], "indefinit": [21, 51], "raydistributedcollector": 21, "distributed_collector": 21, "10000": [21, 315, 340, 342, 343], "add_collector": 21, "local_polici": 21, "remote_collector": 21, "stop_remote_collector": 21, "num_job": 22, "tcpport": 22, "submitit_main_conf": 22, "slurm_cpus_per_task": 22, "slurm_gpus_per_nod": 22, "slurm_partit": 22, "timeout_min": 22, "submitit_collection_conf": 22, "delai": 22, "jump": 22, "host": [22, 32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "wherea": [22, 56, 80, 81, 82, 83, 87, 89, 90, 93, 94, 99, 100, 105, 125, 264, 337], "satellit": 22, "rendezv": 22, "hang": 22, "forev": 22, "default_config": [22, 178, 183, 210, 228], "default_slurm_conf_main": 22, "default_slurm_conf": 22, "rollout_tensordict": 23, "durat": [23, 346], "meta": [23, 44, 52, 86, 90, 337, 342, 346, 349], "aren": [23, 153, 343], "int8": [24, 97, 103, 104, 116], "assert_is_in": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "belong": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 56, 163, 164, 335, 340, 346], "encod": [24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 38, 41, 42, 44, 46, 47, 80, 81, 87, 89, 90, 93, 94, 99, 100, 105, 125, 208, 209, 213, 247, 335, 341, 342, 343, 347, 349], "ndarrai": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 88, 234, 242], "ignore_devic": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "np": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 88, 242, 347], "cast": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 59, 80, 81, 82, 83, 84, 87, 88, 89, 93, 94, 99, 100, 102, 105, 108, 122, 123, 126, 134, 140, 154, 157, 158, 160, 162, 164, 238, 324, 352], "least": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 121, 352], "complient": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "singleton": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 176, 177, 197, 215, 216], "implements_for_spec": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "torch_funct": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "tensor_to_index": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "is_in": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 352], "project": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 125, 191, 193, 223, 227, 229, 230, 234, 235, 236, 237, 238, 239, 335, 351, 352], "uniform": [24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 41, 44, 46, 47, 64], "unbound": [24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 39, 44, 46, 47, 154, 170, 347, 349], "squeez": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 118, 151, 153, 176, 177, 215, 216, 340, 343, 347, 349], "dim": [24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 39, 44, 46, 47, 71, 118, 119, 138, 154, 159, 164, 194, 196, 216, 221, 331, 341, 342, 343, 347, 349], "to_numpi": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 84, 88, 102, 108], "transformed_in": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 157, 158, 206, 217, 331], "check_spec_encod": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "to_one_hot": [24, 27, 30], "hot": [24, 27, 30, 31, 33, 80, 81, 87, 89, 90, 93, 94, 99, 100, 103, 104, 105, 109, 110, 115, 125, 186, 209, 212, 229, 230, 236, 237, 248, 249, 251, 252, 254, 255, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 343], "to_one_hot_spec": [24, 27, 30], "onehotdiscretetensorspec": [24, 27, 186, 212, 229, 236, 252, 254, 255, 256, 277, 333, 335], "convert": [24, 27, 30, 31, 32, 33, 34, 36, 39, 45, 80, 81, 84, 87, 88, 89, 90, 93, 94, 99, 100, 102, 105, 108, 122, 123, 126, 140, 154, 157, 158, 160, 162, 164, 238, 247, 264, 340, 341, 342, 347, 349], "type_check": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "fill": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 88, 154, 163, 195, 343, 347, 348], "upper": [25, 69, 135], "unnam": 26, "pixels_spec": 26, "observation_vector_spec": 26, "composite_spec": 26, "observation_vector": [26, 119, 324, 340], "td_project": 26, "absent": [26, 28, 52, 84, 88, 102, 108], "is_empti": [26, 28, 347], "include_nest": [26, 28], "leaves_onli": [26, 28], "itemsview": 26, "immedi": [26, 28, 32, 84, 88, 102, 108, 278, 346], "children": [26, 28, 32, 84, 88, 102, 108], "keysview": [26, 28], "reflect": [26, 28, 89, 103, 104, 163, 173, 264, 318, 341, 342, 343, 346], "lock_": [26, 28], "recurs": [26, 28, 32, 48, 49, 84, 88, 102, 108, 264], "succeed": [26, 28], "selected_kei": [26, 28, 149, 340], "unlock_": [26, 28], "unlock": [26, 28, 34, 36, 39], "valuesview": 26, "onehottensorspec": [27, 80, 81, 87, 89, 90, 93, 94, 99, 100, 105], "action_valu": [27, 33, 185, 186, 212, 229, 230, 236, 237, 256, 264, 277, 335, 343], "arang": [27, 33, 186, 201, 229, 306, 335, 349], "argmax": [27, 186, 212, 230, 237], "chosen_action_valu": [27, 33, 211, 212, 220, 236, 237, 277, 335, 343], "outcom": [27, 33, 184, 217], "lazi": [28, 29, 49, 50, 84, 88, 102, 108, 109, 110, 140, 160, 176, 204, 240, 241, 340, 341, 345, 349, 352], "represent": [28, 29, 32, 84, 88, 102, 108, 140, 160, 162, 340, 347, 348, 352], "drawn": [28, 29, 154, 231, 235, 239, 342, 346], "lazystackedtensordict": [28, 84, 88, 98, 102, 108, 345, 351], "heterogen": [28, 29, 97, 103, 104, 166, 202, 203, 340, 341], "thrown": [29, 32, 84, 88, 102, 108, 349], "nvec": [30, 31], "cardin": [30, 31, 186, 212, 229, 230, 237, 342], "ax": [30, 204, 205], "m": [30, 32, 84, 88, 102, 108, 125, 239, 335, 341, 347], "ts": [30, 31], "multionehotdiscretetensorspec": [30, 252, 255, 256, 277, 333], "use_regist": [31, 33], "to_categor": [31, 33], "to_categorical_spec": [31, 33], "multidiscretetensorspec": [31, 333], "gamma": [32, 145, 199, 248, 249, 251, 252, 254, 256, 257, 258, 260, 262, 264, 266, 267, 268, 269, 271, 272, 273, 277, 278, 279, 280, 281, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 327, 336, 340, 341, 342, 346, 351], "sutton": [32, 336, 346], "1988": 32, "tempor": [32, 191, 195, 199, 280, 281, 286, 287], "44": [32, 341, 347, 348], "discount": [32, 56, 85, 145, 249, 254, 257, 258, 260, 278, 279, 280, 281, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 336, 341, 342, 346], "ahead": [32, 352], "add_modul": [32, 84, 88, 102, 108], "child": [32, 84, 88, 102, 108], "fn": [32, 37, 84, 88, 102, 108, 206, 329, 330], "init_weight": [32, 84, 88, 102, 108], "fill_": [32, 84, 88, 102, 108, 341, 343, 352], "net": [32, 84, 88, 102, 108, 196, 203, 248, 249, 255, 256, 262, 266, 267, 268, 269, 324, 327, 341, 347, 348, 351], "in_featur": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 176, 177, 179, 180, 181, 182, 196, 197, 203, 204, 205, 224, 238, 252, 254, 351], "out_featur": [32, 84, 88, 98, 102, 108, 122, 140, 154, 157, 158, 160, 162, 175, 176, 177, 179, 180, 181, 182, 187, 188, 191, 195, 196, 197, 199, 202, 203, 204, 205, 224, 229, 238, 252, 254, 335, 340, 343, 351], "bia": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 176, 177, 187, 189, 190, 191, 193, 194, 195, 197, 203, 204, 205, 206, 231, 232, 234, 238, 245, 246, 247, 264, 269, 336, 340, 341, 342, 343, 346, 351], "requires_grad": [32, 80, 81, 84, 88, 102, 108, 134], "bfloat16": [32, 84, 88, 102, 108], "datatyp": [32, 84, 88, 102, 108, 349], "member": [32, 84, 88, 102, 108, 264], "xdoctest": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238, 264, 269], "skip": [32, 84, 88, 102, 108, 131, 158, 166, 235, 239, 264, 269, 279, 280, 281, 282, 297, 298, 308, 311, 340, 341, 342, 347], "buf": [32, 84, 88, 102, 108], "20l": [32, 84, 88, 102, 108, 264], "1l": [32, 84, 88, 102, 108, 264], "5l": [32, 84, 88, 102, 108, 264], "__call__": [32, 37, 84, 88, 102, 108, 239, 337], "doubl": [32, 46, 84, 88, 102, 108, 122, 123, 124, 126, 140, 154, 157, 158, 160, 162, 238, 252, 257, 261, 267, 270, 277, 340, 341, 342, 343, 352], "eval": [32, 84, 88, 102, 108, 158, 164, 340, 341, 342], "evalu": [32, 84, 88, 102, 108, 158, 184, 200, 201, 209, 219, 267, 320, 321, 341, 342], "dropout": [32, 84, 88, 102, 108, 158, 189, 191, 193, 195, 197, 343], "batchnorm": [32, 84, 88, 102, 108, 158], "disabl": [32, 84, 88, 102, 108, 158, 192, 219, 340], "comparison": [32, 84, 88, 102, 108, 158, 264, 340, 341], "similar": [32, 56, 84, 88, 102, 103, 104, 108, 122, 140, 154, 157, 158, 160, 161, 162, 164, 224, 226, 235, 238, 239, 336, 340, 341, 342, 343, 347, 352], "confus": [32, 84, 88, 102, 108, 158], "extra_repr": [32, 84, 88, 102, 108], "shift": [32, 245, 279, 280, 281, 282, 342], "nontermin": 32, "original_reward": 32, "newli": [32, 84, 88, 102, 108], "OR": 32, "get_buff": [32, 84, 88, 102, 108], "throw": [32, 34, 36, 39, 84, 88, 102, 108, 352], "docstr": [32, 84, 88, 102, 108], "get_submodul": [32, 84, 88, 102, 108], "explan": [32, 84, 88, 102, 108], "qualifi": [32, 84, 88, 102, 108], "referenc": [32, 84, 88, 102, 108], "attributeerror": [32, 84, 88, 102, 108], "invalid": [32, 84, 88, 102, 108, 111, 200, 201], "resolv": [32, 84, 88, 102, 108], "someth": [32, 84, 88, 97, 102, 108, 334, 341, 342, 347, 352], "get_extra_st": [32, 84, 88, 102, 108, 164], "set_extra_st": [32, 84, 88, 102, 108, 164], "picklabl": [32, 84, 88, 102, 108, 164], "pickl": [32, 84, 88, 102, 108, 164], "get_paramet": [32, 84, 88, 102, 108], "sai": [32, 84, 88, 102, 108, 202, 348, 352], "net_b": [32, 84, 88, 102, 108], "net_c": [32, 84, 88, 102, 108], "conv": [32, 84, 88, 102, 108, 176, 177, 341], "conv2d": [32, 84, 88, 102, 108, 177, 202, 351], "kernel_s": [32, 84, 88, 102, 108, 176, 177, 179, 180, 202, 207, 341, 351], "stride": [32, 84, 88, 102, 108, 176, 177, 179, 180, 188, 202, 341, 351], "diagram": [32, 84, 88, 102, 108], "degre": [32, 84, 88, 102, 108], "named_modul": [32, 84, 88, 102, 108], "o": [32, 84, 88, 102, 108, 194], "transit": [32, 52, 56, 72, 84, 88, 102, 108, 244, 340, 343, 347, 349], "half": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238, 340], "ipu": [32, 84, 88, 102, 108], "strict": [32, 34, 36, 39, 84, 88, 102, 108, 158, 269], "descend": [32, 84, 88, 102, 108, 158, 269], "persist": [32, 84, 88, 102, 108, 158, 173, 269], "enforc": [32, 70, 84, 88, 102, 108, 158, 240, 269, 347], "preserv": [32, 84, 88, 102, 108, 158, 269], "missing_kei": [32, 84, 88, 102, 108, 158, 269], "unexpected_kei": [32, 84, 88, 102, 108, 158, 269], "namedtupl": [32, 84, 88, 102, 108, 158, 269], "duplic": [32, 70, 84, 88, 102, 108, 252, 257, 264, 277], "l": [32, 84, 88, 102, 108, 189, 193, 278, 342, 347], "idx": [32, 84, 88, 102, 108], "named_buff": [32, 84, 88, 102, 108], "remove_dupl": [32, 84, 88, 102, 108, 264], "prepend": [32, 84, 88, 102, 108, 264], "running_var": [32, 84, 88, 102, 108], "named_children": [32, 84, 88, 102, 108], "conv4": [32, 84, 88, 102, 108], "conv5": [32, 84, 88, 102, 108], "memo": [32, 84, 88, 102, 108], "named_paramet": [32, 84, 88, 102, 108, 134, 264], "register_backward_hook": [32, 84, 88, 102, 108], "removablehandl": [32, 84, 88, 102, 108], "deprec": [32, 84, 88, 102, 108, 158, 167, 171, 185, 232, 248, 250, 252, 255, 256, 257, 262, 263, 266, 267, 268, 269, 277, 279, 280, 281, 282, 287, 352], "favor": [32, 84, 88, 102, 108, 342], "register_full_backward_hook": [32, 84, 88, 102, 108], "register_buff": [32, 84, 88, 102, 108], "running_mean": [32, 84, 88, 102, 108], "alongsid": [32, 84, 88, 102, 108, 346], "num_featur": [32, 84, 88, 102, 108], "register_forward_hook": [32, 84, 88, 102, 108, 186, 212], "with_kwarg": [32, 84, 88, 102, 108], "always_cal": [32, 84, 88, 102, 108], "posit": [32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 82, 83, 84, 88, 102, 108, 130, 131, 151, 152, 155, 158, 159, 206, 269, 336, 342, 346, 347, 349], "signatur": [32, 74, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238, 336, 340, 347], "register_module_forward_hook": [32, 84, 88, 102, 108], "regardless": [32, 84, 88, 102, 108, 250, 263, 266], "register_forward_pre_hook": [32, 84, 88, 102, 108], "invok": [32, 84, 88, 102, 108], "And": [32, 84, 88, 102, 108], "forward_pr": [32, 84, 88, 102, 108], "register_module_forward_pre_hook": [32, 84, 88, 102, 108], "grad_input": [32, 84, 88, 102, 108], "grad_output": [32, 84, 88, 102, 108], "subsequ": [32, 84, 88, 102, 108, 343], "technic": [32, 84, 88, 102, 108, 341, 343], "caller": [32, 84, 88, 102, 108], "register_module_full_backward_hook": [32, 84, 88, 102, 108], "register_full_backward_pre_hook": [32, 84, 88, 102, 108], "backward_pr": [32, 84, 88, 102, 108], "register_module_full_backward_pre_hook": [32, 84, 88, 102, 108], "register_load_state_dict_post_hook": [32, 84, 88, 102, 108], "incompatible_kei": [32, 84, 88, 102, 108], "clear": [32, 53, 84, 88, 92, 102, 108, 307], "register_modul": [32, 84, 88, 102, 108, 337], "alia": [32, 84, 88, 102, 108], "register_paramet": [32, 84, 88, 102, 108], "register_state_dict_pre_hook": [32, 84, 88, 102, 108], "keep_var": [32, 34, 36, 39, 84, 88, 102, 108, 158, 269], "requires_grad_": [32, 84, 88, 102, 108], "autograd": [32, 84, 88, 102, 108, 158, 269], "freez": [32, 84, 88, 102, 108], "finetun": [32, 84, 88, 102, 108], "gan": [32, 84, 88, 102, 108], "share_memori": [32, 84, 85, 88, 102, 108, 340], "share_memory_": [32, 84, 88, 102, 108, 351], "destin": [32, 34, 36, 39, 84, 88, 102, 108, 117, 123, 124, 126, 158, 160, 164, 173, 269, 298], "averag": [32, 84, 88, 102, 108, 158, 164, 234, 258, 259, 269, 313, 340, 342], "shallow": [32, 84, 88, 102, 108, 158, 269, 343], "pleas": [32, 54, 84, 88, 102, 103, 104, 108, 118, 155, 158, 269, 334], "detach": [32, 84, 88, 102, 108, 158, 264, 269, 279, 280, 281, 282, 340], "non_block": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238, 343], "memory_format": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "channels_last": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "complex": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238, 340, 341], "integr": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 182, 191, 195, 199, 238, 335, 346, 347, 348], "unchang": [32, 84, 88, 102, 108, 122, 125, 140, 154, 157, 158, 160, 162, 231, 238, 312, 340, 349], "tri": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "pin": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "4d": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "ignore_w": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "1913": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "3420": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "5113": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "2325": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "torch_doctest_cuda1": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "gpu1": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "1914": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "5112": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238, 347], "2324": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "float16": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 190, 194, 238], "cdoubl": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "3741": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "j": [32, 35, 64, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238, 337], "2382": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "5593": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238, 347], "4443": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "complex128": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "6122": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "1150": [32, 84, 88, 102, 108, 122, 140, 154, 157, 158, 160, 162, 238], "to_empti": [32, 84, 88, 102, 108], "dst_type": [32, 84, 88, 102, 108], "xpu": [32, 84, 88, 102, 108], "set_to_non": [32, 84, 88, 102, 108], "unidimension": 33, "keepdim": 33, "user_regist": 33, "priori": 33, "definit": [33, 73, 202], "uniqu": [33, 71, 72, 118, 127, 153, 154, 155, 349], "discretebox": [33, 84, 88, 102, 108, 342, 346, 352], "chosen_data": [34, 59], "rewarddata": [34, 59, 333], "rejected_data": [34, 59], "from_dataset": [34, 36, 59], "dataset_nam": [34, 36, 40, 45, 59, 101], "max_length": [34, 36, 37, 43, 45, 59], "550": [34, 36, 40, 45, 59, 71, 72, 347], "root_dir": [34, 36, 45, 59], "from_disk": [34, 36, 45, 59], "num_work": [34, 36, 45, 59, 99, 102, 108, 340, 341], "carperai": [34, 36, 40, 45], "openai_summarize_comparison": [34, 36, 45], "sequen": [34, 36], "cach": [34, 36, 45, 52, 53, 54, 56, 57, 58, 59, 71, 84, 88, 102, 108, 123, 126, 140, 158, 162, 307, 348], "load_from_disk": [34, 36, 45, 59], "load_dataset": [34, 36, 45, 59], "attention_mask": [34, 36, 37, 39, 40, 43, 45, 59], "memorymappedtensor": [34, 36, 45, 61, 348], "92534": 34, "input_id": [34, 36, 37, 39, 40, 43, 45, 59], "end_scor": [34, 39, 40, 59], "sub_data": [34, 36], "from_dict": [34, 36, 39, 45], "batch_dim": [34, 36, 39, 45, 331], "determin": [34, 35, 36, 39, 41, 52, 64, 84, 88, 102, 108, 109, 110, 140, 162, 202, 234, 341, 346], "input_dict": [34, 36, 39], "exclusinv": [34, 36, 39], "__maximum__": [34, 36, 39], "toler": [34, 36, 39, 80, 81, 82, 83, 87, 89, 90, 93, 94, 99, 100, 105, 184, 217], "sie": [34, 36, 39], "input_td": [34, 36, 39], "from_tensordict": [34, 36, 39], "non_tensordict": [34, 36, 39], "_no_default_": [34, 36, 39], "getattr": [34, 36, 39], "tensorclass": [34, 36, 39, 59, 61, 62, 77], "from_flatten": [34, 36, 39], "attemptedli": [34, 36, 39], "memmap": [34, 36, 39, 61, 102, 108, 164, 312, 349], "copy_exist": [34, 36, 39], "return_earli": [34, 36, 39], "mimic": [34, 36, 39, 84, 88, 102, 108], "cross": [34, 36, 39, 175], "anymor": [34, 36, 39, 158, 238], "tensordictfutur": [34, 36, 39], "deepli": [34, 36, 39], "insid": [34, 36, 39, 102, 352], "memmap_": [34, 36, 39, 164], "memmap_lik": [34, 36, 39], "contentless": [34, 36, 39], "1_000_000": [34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 71, 340, 343], "alloc": [34, 36, 39, 62, 200, 201, 340], "setattr": [34, 36, 39], "tent": [34, 36, 39, 45], "to_tensordict": [34, 36, 39, 343], "unbind": [34, 36, 39, 191, 195], "alpha": [35, 41, 64, 176, 177, 202, 249, 256, 265, 267, 269, 340, 349, 351], "ep": [35, 41, 64, 164, 234, 250, 270, 313, 340, 341, 343], "1e": [35, 41, 64, 164, 184, 187, 206, 217, 340, 341, 342, 346], "08": [35, 41, 64, 340, 341, 342, 347], "collate_fn": [35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 349, 351], "prefetch": [35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 59, 340, 341, 343, 349], "schaul": [35, 64], "quan": [35, 64], "antonogl": [35, 64], "silver": [35, 64], "2015": [35, 64], "arxiv": [35, 53, 56, 58, 64, 80, 81, 82, 83, 93, 94, 99, 100, 105, 109, 110, 118, 140, 160, 178, 179, 180, 181, 182, 183, 186, 187, 188, 193, 199, 205, 207, 208, 210, 211, 213, 214, 220, 230, 234, 248, 249, 252, 253, 254, 255, 257, 258, 259, 260, 261, 262, 265, 266, 269, 270, 279, 284, 292, 348], "ab": [35, 53, 56, 58, 64, 80, 81, 82, 83, 93, 94, 99, 100, 105, 109, 110, 117, 140, 160, 164, 178, 183, 187, 188, 193, 199, 205, 207, 208, 210, 211, 213, 214, 220, 248, 249, 252, 253, 254, 255, 258, 259, 260, 261, 262, 265, 266, 269, 348], "1511": [35, 64, 188], "05952": [35, 64], "expon": [35, 41, 64], "\u03b1": [35, 41, 64], "delta": [35, 41, 64, 189, 193, 217, 235, 239, 333, 336], "null": [35, 41, 64, 116], "max_siz": [35, 38, 41, 42, 61, 62, 63, 73, 77], "1_000": [35, 38, 41, 42, 349], "merg": [35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 347], "mini": [35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 346], "decid": [35, 38, 41, 42, 351], "meth": [35, 38, 41, 42, 264, 347], "incompat": [35, 38, 41, 42, 349], "drop_last": [35, 38, 41, 42, 70, 72], "return_info": [35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 349], "tensordictprioritizedreplaybuff": [35, 333, 351], "simplifi": [35, 347, 349], "manual_se": [35, 38, 41, 42, 53, 57, 58, 71, 72, 80, 81, 84, 88, 102, 108, 115, 125, 136, 145, 148, 153, 155, 200, 201, 209, 223, 230, 231, 232, 234, 242, 248, 249, 251, 255, 262, 269, 346, 347, 351, 352], "_weight": [35, 41, 349, 351], "arrai": [35, 40, 84, 88, 102, 108, 127, 189, 190, 193, 194, 340, 349], "update_prior": [35, 64, 312, 337, 341, 349, 351], "36278465": 35, "tempfil": [35, 38, 41, 42, 45, 52, 53, 54, 55, 56, 57, 58, 66, 327, 340, 341, 349], "tqdm": [35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 315, 340, 342, 343, 346, 347], "randomsampl": [35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 333, 340], "td_error": [35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 251, 252, 254, 255, 256, 257, 262, 264, 267, 269, 271, 277, 340, 349, 351], "update_tensordict_prior": [35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66, 340, 349, 351], "temporarydirectori": [35, 38, 41, 42, 45, 52, 53, 54, 55, 56, 57, 58, 66, 340, 341, 349], "tmpdir": [35, 38, 41, 42, 45, 52, 53, 54, 55, 56, 57, 58, 66, 340, 341], "rb_load": [35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66], "cursor": [35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66], "insert_transform": [35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 66], "insert": [35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 58, 60, 66, 67, 75, 76, 78, 79, 159], "prompt_rindex": [36, 37, 40], "label": [36, 37, 40, 45, 340, 349], "os": [36, 45, 59, 341], "cpu_count": [36, 45, 59], "promptdatatldr": 36, "116722": 36, "prompt": [37, 40], "return_tensordict": [37, 43], "recip": [37, 84, 88, 102, 108, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 242, 245], "text": [37, 40, 43, 54, 189, 190, 193, 194, 234, 342], "tensodict": [37, 43], "orign": [37, 43], "valid_sampl": 37, "identifi": 37, "eough": 37, "toknen": 37, "meet": 37, "criterion": 37, "autotoken": [37, 43, 45], "from_pretrain": [37, 40, 43], "gpt2": [37, 40, 43, 45, 178, 183, 210], "pad_token": [37, 43], "eos_token": 37, "enough": [37, 349], "inde": [37, 125, 342, 347], "roundrobinwrit": [38, 42, 52, 53, 54, 55, 56, 57, 58, 333], "Not": [38, 80, 81, 93, 94], "ref_model": 40, "reward_model": [40, 244], "kl_coef": 40, "max_new_token": 40, "score_clip": 40, "kl_schedul": 40, "klcontrollerbas": 40, "num_step": 40, "causal": 40, "sentenc": 40, "frozen": [40, 134], "kl": [40, 134, 259, 263], "penalti": [40, 263], "strai": 40, "far": [40, 192, 218, 219, 347, 352], "calcul": [40, 145, 189, 254], "gpt2rewardmodel": 40, "get_dataload": [40, 333], "promptdata": [40, 333], "gpt2lmheadmodel": 40, "dl": 40, "block_siz": [40, 59], "tensorclass_typ": [40, 59], "openai_summarize_tldr": 40, "config_class": 40, "model_path": 40, "rollout_from_model": 40, "rollout_from_data": 40, "600": [40, 347, 349], "reward_kl": [40, 134], "reward_raw": 40, "sample_log_prob": [40, 224, 225, 226, 235, 239, 241, 266, 324, 342, 346, 351], "create_rollout_td": 40, "log_prob": [40, 184, 200, 201, 209, 219, 239], "log_ratio": 40, "replic": 40, "rindex": 40, "multipli": [40, 189, 193, 249, 250, 256, 263, 265, 266, 267, 269, 313, 340], "term": [40, 134, 193, 194, 204, 205, 247, 248, 256, 317, 341, 342, 346], "subtract": [40, 153], "ve": [40, 340, 343], "eo": 40, "limit": [40, 84, 88, 98, 102, 108, 118, 134, 340, 341, 343, 346, 347], "generation_config": 40, "generationconfig": 40, "ti": [40, 288, 289, 290, 291, 293, 294, 295, 296, 341], "log_probs_gen": 40, "logprobs_of_label": 40, "priority_kei": [41, 42, 252, 255, 256, 257, 262, 264, 267, 269, 271, 277, 349, 351], "reduct": [41, 64, 75], "prioritizedreplaybuff": [41, 333, 351], "min": [41, 64, 75, 217, 218, 219, 228, 234, 249, 250, 256, 265, 267, 269, 341, 342, 346], "median": [41, 64, 75, 93, 94, 235, 239], "include_info": [41, 42, 52, 53, 54, 55, 56, 57, 58], "kw": [42, 67, 76], "int32": [42, 56, 71, 93, 94, 170], "huggingfac": [43, 53, 58, 233], "co": [43, 127, 347], "doc": [43, 90, 93, 94, 101, 105, 341, 346], "pad_trunc": 43, "am": 43, "worri": 43, "me": 43, "reassur": 43, "ok": 43, "tokenizer_fn": 45, "tensordicttoken": [45, 333], "pre_tokenization_hook": 45, "valid_s": 45, "tokenizer_class": 45, "tokenizer_model_nam": 45, "tokein": 45, "condit": [45, 153, 229, 230, 236, 237, 247, 340, 347, 349], "elementwis": 45, "vocabulari": 45, "loader": [45, 342], "185068": 45, "dataset_to_tensordict": 45, "data_dir": 45, "nestedkei": [45, 71, 72, 84, 88, 102, 108, 115, 116, 117, 118, 119, 120, 121, 123, 125, 126, 127, 128, 130, 132, 133, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 160, 164, 173, 174, 227, 228, 231, 232, 234, 239, 252, 277, 298], "valid_mask_kei": 45, "conver": 45, "undergon": 45, "preprocess": [45, 53, 341], "batch_dimens": 45, "filder": 45, "data_memmap": 45, "exclus": [48, 49, 56, 71, 72, 130, 189, 191, 193, 195, 200, 201, 229, 230, 236, 237, 270, 271, 279, 280, 281, 282, 283, 331, 335], "recurse_through_entri": 49, "recurse_through_stack": 49, "consolid": 49, "dataset_id": [52, 53, 54, 56, 57, 58], "from_env": 52, "use_truncated_as_don": 52, "direct_download": 52, "terminate_on_end": 52, "env_kwarg": [52, 57, 58, 329, 330, 340], "reconstruct": [52, 71, 72, 259, 340, 352], "recov": [52, 54, 56, 57, 58, 71, 72, 227, 232, 234, 240, 255, 262, 345], "regard": [52, 54, 56, 57, 58, 186, 230, 248, 257, 266, 340, 342, 347], "get_dataset": 52, "qlearning_dataset": 52, "fewer": 52, "left": [52, 56, 122, 123, 124, 128, 134, 140, 142, 143, 149, 152, 155, 157, 160, 162, 231, 341, 342], "possess": 52, "unexpectedli": 52, "traj_split": 52, "observationnorm": [52, 164, 331, 340, 341, 342, 343, 351], "maze2d": 52, "umaz": 52, "128": [52, 56, 72, 80, 81, 93, 94, 180, 183, 341, 343, 347, 348, 349], "loc": [52, 134, 136, 147, 192, 206, 218, 219, 224, 225, 226, 235, 239, 241, 248, 249, 262, 266, 267, 268, 269, 319, 324, 331, 335, 340, 341, 342, 343, 346, 351], "gen": 53, "dgrl": 53, "accompani": [53, 152], "gap": 53, "2312": 53, "05742": 53, "gen_dgrl": 53, "procgen": 53, "available_dataset": [53, 54, 56, 57, 58, 71, 72], "bigfish": 53, "bossfight": 53, "categori": [53, 335, 337], "1m_e": 53, "1m_": 53, "comma": 53, "npy": 53, "extract": [53, 233, 340, 342], "mmap": [53, 57, 58], "minut": [53, 340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "internet": [53, 58], "connect": [53, 58], "minari": [54, 56], "currenrtli": 54, "minari_data": 54, "door": 54, "28": [54, 202, 341, 347], "39": [54, 93, 94, 339, 340, 341, 343, 346, 347, 349, 350], "door_body_po": 54, "qpo": 54, "30": [54, 135, 213, 214, 341, 342, 346, 347], "qvel": 54, "dua": 55, "graff": 55, "2017": 55, "uci": 55, "archiv": 55, "ic": 55, "edu": 55, "ml": 55, "sklearn": [55, 101], "adult_num": [55, 101], "adult_onehot": [55, 101], "mushroom_num": [55, 101], "mushroom_onehot": [55, 101], "covertyp": [55, 101], "shuttl": [55, 101], "magic": [55, 101], "shuffl": [56, 70, 72, 346], "num_slic": [56, 71, 72], "slice_len": [56, 71, 72], "stream": 56, "strict_length": [56, 71, 72], "embodi": [56, 348], "22": [56, 71, 72, 163, 341, 343, 347, 348], "institut": 56, "demonstr": [56, 342, 346, 347, 352], "527": [56, 347], "skill": 56, "160266": 56, "websit": 56, "googl": [56, 57, 80, 81, 342, 343, 346], "open_x_embodi": 56, "2310": [56, 105], "08864": 56, "nontensordata": 56, "language_instruct": 56, "get_non_tensor": 56, "refin": [56, 248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277], "neither": [56, 347], "nor": 56, "shorter": [56, 71, 72], "insuffici": 56, "chosen": [56, 109, 110, 153, 154, 211, 212, 220, 237, 324, 335], "__will": 56, "change__": 56, "untouch": [56, 122, 123, 124, 128, 134, 142, 143, 149, 152, 157], "randomli": [56, 70, 135, 136, 154, 231, 235, 239, 346, 347, 349], "crop": [56, 120, 141, 298], "modal": [56, 340], "Be": [56, 71, 72], "cmu_stretch": 56, "is_init": [56, 58, 117, 133, 191, 195, 234, 343], "language_embed": 56, "512": [56, 188, 341, 347, 349], "lift": 56, "green": 56, "garbag": 56, "lid": 56, "roboset": 57, "h5": [57, 58], "roboh": [57, 105], "fk1": 57, "v4": [57, 88, 102, 144, 288, 289, 290, 291, 293, 294, 295, 296, 340, 342, 348], "expert": 57, "fk1_microopenrandom_v2d": 57, "concis": 57, "17": [57, 72, 102, 324, 340, 341, 342, 343, 347, 349], "18": [57, 72, 106, 107, 109, 110, 203, 340, 341, 343, 346, 347, 348, 349, 352], "15": [57, 72, 84, 88, 102, 108, 228, 234, 258, 339, 340, 341, 346, 347, 349, 350], "19": [57, 71, 72, 75, 340, 341, 347], "75": [57, 341, 346, 347, 348], "totensor": 58, "image_s": 58, "v": [58, 164, 189, 190, 193, 194, 224, 255, 262, 269, 335, 340, 341], "npz": 58, "2206": [58, 99, 100], "04779": [58, 249, 254], "vd4rl": 58, "detect": 58, "squar": [58, 120, 192, 218, 219, 298], "rectangular": [58, 176, 177], "walker_walk": 58, "64px": 58, "height": [58, 120, 144], "veloc": [58, 82, 83, 84, 88, 102, 108, 118, 346, 347, 352], "infinit": [59, 109, 110, 349], "three": [59, 335, 337, 342, 346, 347, 349, 352], "block": [59, 60, 79, 335, 343], "pairwisedataset": [59, 333], "256": [59, 183, 341, 342, 346, 347], "immut": [60, 84, 88, 102, 108, 143, 158], "piec": [60, 67, 76, 78, 79, 340, 341, 342, 346, 347, 349], "scratch_dir": [61, 340, 349], "mistak": [61, 62, 77], "myclass": [61, 62, 77], "foo": [61, 62, 77, 228, 349, 352], "bar": [61, 62, 77, 228, 308, 309, 311, 315, 337, 341], "attach": [61, 62, 63, 73, 74, 77, 341], "entiti": [61, 62, 63, 73, 74, 77], "auto": [62, 77, 163, 234, 249, 256, 265, 267, 269, 271, 336, 346], "zero_": [62, 77, 170], "max_capac": [64, 340, 349], "uniformli": [65, 264, 352], "storageensembl": [66, 69], "samplerensembl": 66, "writerensembl": [66, 74], "sample_from_al": [66, 69], "num_buffer_sampl": [66, 69], "ensembl": [66, 69, 74, 79, 238, 267], "forbidden": 66, "collat": 66, "0x13a2ef430": 66, "0x13a2f9310": 66, "interpol": [66, 144, 341, 343], "interpolationmod": [66, 343], "bilinear": [66, 144, 343], "0x13a2f9220": 66, "0x13a2f9f70": 66, "0x13a2d9b50": 66, "0x13a2f95b0": 66, "0x128648260": 66, "roundrobin": [67, 76], "buffer_id": [69, 74], "consum": [70, 72, 341, 342, 346, 349], "incomplet": [70, 72], "fresh": 70, "caution": [70, 166, 352], "haven": [70, 348], "remain": [70, 117, 124, 125, 134, 153, 205], "draw": [70, 231], "end_kei": [71, 72], "traj_kei": [71, 72], "cache_valu": 71, "truncated_kei": [71, 72, 145, 152], "slicesamplerwithoutreplac": [71, 333], "Will": [71, 99, 298], "320": [71, 72, 82, 83, 341, 347, 352], "700": [71, 72], "robosetexperiencereplai": [71, 72, 333], "dataid": [71, 72], "__len__": 73, "rank_kei": 75, "rank": [75, 175], "samplerwithoutreplac": [75, 333, 342, 346, 349], "get_insert_index": 75, "convers": [80, 81, 93, 94, 336], "2106": [80, 81, 253], "13281": [80, 81], "categorical_action_encod": [80, 81, 87, 89, 90, 93, 94, 99, 100, 105], "frame_skip": [80, 81, 82, 83, 87, 88, 89, 90, 93, 94, 95, 96, 99, 100, 105, 131, 308, 311, 318, 337, 340, 341, 342, 351], "repeat": [80, 81, 82, 83, 87, 89, 90, 93, 94, 99, 100, 105, 175, 342, 346, 347], "allow_done_after_reset": [80, 81, 82, 83, 87, 89, 90, 93, 94, 99, 100, 105], "availalb": [80, 81, 93, 94], "ant": [80, 81, 84, 88, 91, 102, 108, 348], "87": [80, 81, 341, 347, 348], "acrobot": [80, 81, 82, 83, 352], "fetch": [80, 81, 82, 83, 134, 348, 349, 352], "advant": [80, 81, 93, 94], "report": [80, 81, 93, 94], "short": [80, 81, 93, 94, 102, 166, 193, 194, 341, 342, 346], "timer": [80, 81, 93, 94], "timeit": [80, 81, 93, 94], "310": [80, 81, 347], "00": [80, 81, 339, 340, 341, 342, 343, 346, 347, 348, 350], "ms": [80, 81, 93, 94], "268": [80, 81, 347], "433": [80, 81, 347], "80": [80, 81, 340, 341, 342, 346, 347, 348], "27": [80, 81, 339, 340, 341, 343, 346, 347, 348, 349, 350], "213": [80, 81, 347], "8605": [80, 81], "pipelineenv": 81, "get_environ": 81, "dm_control": [82, 83, 340, 345, 352], "2006": [82, 83, 249, 254, 347], "12983": [82, 83], "task_nam": [82, 84, 88, 102, 108], "pixels_onli": [82, 83, 87, 89, 90, 105, 340, 341, 351, 352], "cheetah": [82, 83, 84, 88, 102, 108, 340, 352], "240": [82, 83, 347, 351, 352], "swingup": [82, 83, 352], "swingup_spars": [82, 83, 352], "ball_in_cup": [82, 83, 352], "catch": [82, 83, 352], "cartpol": [82, 83, 84, 88, 102, 108, 118, 148, 153, 341, 343, 349, 352], "balance_spars": [82, 83, 352], "three_pol": [82, 83, 352], "two_pol": [82, 83, 352], "finger": [82, 83, 352], "turn_easi": [82, 83, 352], "turn_hard": [82, 83, 352], "fish": [82, 83, 352], "upright": [82, 83, 341, 352], "swim": [82, 83, 352], "hopper": [82, 83, 352], "hop": [82, 83, 352], "humanoid": [82, 83, 345, 352], "walk": [82, 83, 341, 345, 352], "run_pure_st": [82, 83, 352], "bring_bal": [82, 83, 352], "bring_peg": [82, 83, 352], "insert_bal": [82, 83, 352], "insert_peg": [82, 83, 352], "point_mass": [82, 83, 352], "reacher": [82, 83, 352], "swimmer": [82, 83, 352], "swimmer6": [82, 83, 352], "swimmer15": [82, 83, 352], "walker": [82, 83, 352], "dog": [82, 83, 352], "trot": [82, 83, 352], "humanoid_cmu": [82, 83, 352], "lqr": [82, 83, 352], "lqr_2_1": [82, 83, 352], "lqr_6_2": [82, 83, 352], "quadrup": [82, 83, 352], "escap": [82, 83, 352], "stacker": [82, 83, 352], "stack_2": [82, 83, 352], "stack_4": [82, 83, 352], "continuousbox": [84, 88, 102, 108, 170, 342, 346, 347, 351, 352], "unboundedcontinuoustensorspec": [84, 88, 98, 102, 108, 115, 123, 126, 142, 154, 170, 175, 199, 223, 238, 241, 243, 268, 333, 342, 343, 346, 347, 352], "sort": [84, 88, 102, 108, 234], "depth": [84, 88, 98, 102, 108, 175, 176, 177, 179, 180, 181, 182, 187, 188, 197, 199, 202, 203, 207, 208, 229, 335, 341, 345, 346], "another_act": [84, 88, 102, 108], "mutabl": [84, 88, 102, 108], "batch_lock": [84, 86, 88, 102, 108, 154, 158, 347], "done_keys_group": [84, 88, 102, 108], "outer": [84, 88, 102, 108, 337, 340, 341, 352], "another_don": [84, 88, 102, 108], "empty_cach": [84, 88, 102, 108, 158], "fake_tensordict": [84, 88, 102, 108, 341], "fake": [84, 88, 102, 108, 340, 341], "afterward": [84, 88, 102, 108, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 242, 245, 352], "silent": [84, 88, 102, 108, 176, 177, 178, 179, 180, 181, 182, 183, 185, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 202, 203, 206, 207, 208, 210, 213, 214, 216, 221, 227, 228, 230, 231, 232, 234, 237, 242, 245], "braxenv": [84, 88, 102, 108, 143, 333], "envnam": [84, 88, 102, 108], "pipeline_st": [84, 88, 102, 108], "attibut": [84, 88, 102, 108], "speak": [84, 88, 102, 108, 340], "rand_act": [84, 88, 97, 102, 103, 104, 108], "register_gym": [84, 88, 102, 108], "entry_point": [84, 88, 102, 108], "info_kei": [84, 88, 102, 108], "reward_threshold": [84, 88, 102, 108], "nondeterminist": [84, 88, 102, 108], "max_episode_step": [84, 87, 88, 89, 102, 108], "order_enforc": [84, 88, 102, 108], "autoreset": [84, 88, 102, 108], "disable_env_check": [84, 87, 88, 99, 100, 102, 108], "apply_api_compat": [84, 88, 102, 108], "nasium": [84, 88, 102, 108], "scope": [84, 88, 102, 108, 352], "dmcontrolenv": [84, 88, 102, 108, 333, 340, 345, 352], "dmc": [84, 88, 102, 108], "removeemptyspec": [84, 88, 102, 108], "threshold": [84, 88, 102, 108, 231, 249, 250, 342], "learnt": [84, 88, 102, 108, 327, 340, 342], "knowledg": [84, 88, 102, 108], "checker": [84, 87, 88, 99, 100, 102, 108], "stepapicompat": [84, 88, 102, 108], "concept": [84, 88, 102, 108, 341, 349], "deem": [84, 88, 102, 108, 109, 110], "envgym": [84, 88, 102, 108], "0855": [84, 88, 102, 108], "0215": [84, 88, 102, 108], "0881": [84, 88, 102, 108], "0412": [84, 88, 102, 108], "1101": [84, 88, 102, 108], "0080": [84, 88, 102, 108], "0254": [84, 88, 102, 108], "0424": [84, 88, 102, 108], "9609e": [84, 88, 102, 108], "02": [84, 88, 102, 108, 339, 340, 341, 342, 343, 346, 347, 348, 350], "9776e": [84, 88, 102, 108], "04": [84, 88, 92, 102, 108, 340, 341, 347, 348], "6347e": [84, 88, 102, 108], "03": [84, 88, 102, 108, 136, 339, 340, 341, 342, 347, 348, 350], "3842e": [84, 88, 102, 108], "5338e": [84, 88, 102, 108], "3064e": [84, 88, 102, 108], "0381e": [84, 88, 102, 108], "6656e": [84, 88, 102, 108], "05": [84, 88, 102, 108, 339, 340, 341, 342, 343, 347, 348, 350], "0204e": [84, 88, 102, 108], "action_spac": [84, 88, 102, 108, 127, 186, 212, 229, 230, 236, 237, 248, 249, 251, 252, 254, 255, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 343], "0833": [84, 88, 102, 108], "0275": [84, 88, 102, 108], "0612": [84, 88, 102, 108], "0770": [84, 88, 102, 108, 347], "1256": [84, 88, 102, 108, 347], "0082": [84, 88, 102, 108], "0186": [84, 88, 102, 108], "0476": [84, 88, 102, 108], "2221": [84, 88, 102, 108], "2256": [84, 88, 102, 108], "5930": [84, 88, 102, 108], "6937": [84, 88, 102, 108], "5865": [84, 88, 102, 108], "5479": [84, 88, 102, 108], "0187": [84, 88, 102, 108], "6825": [84, 88, 102, 108, 347], "5224": [84, 88, 102, 108], "0018": [84, 88, 102, 108, 347], "cattensor": [84, 88, 102, 108, 324, 340, 345, 347, 352], "1005": [84, 88, 102, 108], "0335": [84, 88, 102, 108], "0268": [84, 88, 102, 108, 347], "0133": [84, 88, 102, 108], "0627": [84, 88, 102, 108], "0074": [84, 88, 102, 108, 347], "0488": [84, 88, 102, 108, 347], "0353": [84, 88, 102, 108], "0075": [84, 88, 102, 108, 347], "0069": [84, 88, 102, 108, 347], "0098": [84, 88, 102, 108, 347], "0058": [84, 88, 102, 108, 347], "0033": [84, 88, 102, 108, 347], "0157": [84, 88, 102, 108], "0004": [84, 88, 102, 108, 347], "0381": [84, 88, 102, 108], "0452": [84, 88, 102, 108], "11355747": [84, 88, 102, 108], "04257728": [84, 88, 102, 108], "00408397": [84, 88, 102, 108], "04155852": [84, 88, 102, 108], "0389733": [84, 88, 102, 108], "01409826": [84, 88, 102, 108], "0978704": [84, 88, 102, 108], "08808327": [84, 88, 102, 108], "03970837": [84, 88, 102, 108], "00535434": [84, 88, 102, 108], "02353762": [84, 88, 102, 108], "05116226": [84, 88, 102, 108], "02788907": [84, 88, 102, 108], "06848346": [84, 88, 102, 108], "05154399": [84, 88, 102, 108], "0371798": [84, 88, 102, 108], "05128025": [84, 88, 102, 108], "dydact": [84, 88, 102, 108], "gym_env": [84, 88, 102, 108, 351], "_step": [84, 88, 102, 108, 115, 123, 126, 130, 142, 143], "reset_kei": [84, 88, 102, 108, 118, 148, 153, 154, 155], "multitask": [84, 88, 102, 108], "multiag": [84, 88, 97, 102, 103, 104, 108, 174, 203, 211, 220, 277], "another_reward": [84, 88, 102, 108], "callback": [84, 88, 102, 108, 346], "auto_reset": [84, 88, 102, 108, 347], "auto_cast_to_devic": [84, 88, 102, 108, 346], "break_when_any_don": [84, 88, 102, 108, 346], "return_contigu": [84, 88, 102, 108, 166, 345], "soon": [84, 88, 102, 103, 104, 108], "ndim": [84, 88, 102, 108], "concomitt": [84, 88, 102, 108], "workspac": [84, 88, 102, 108], "prevail": [84, 88, 102, 108, 148, 174], "creator": [85, 320, 321, 329, 330, 331], "substitut": [85, 153, 164], "vecnorm": [85, 331], "env_creat": [85, 340], "test_env1": 85, "observation_count": [85, 352], "test_env2": 85, "sleep": [85, 352], "ps": 85, "p1": 85, "p2": 85, "9934": 85, "env_str": 86, "accross": [87, 89], "registri": 87, "asyncvectorenv": 87, "involv": [87, 89, 90, 105], "pixel_observ": [87, 89, 90, 105], "pixelobservationwrapp": [87, 89, 90, 105], "al": [87, 89, 127, 138, 175, 352], "adventur": [87, 89, 352], "ram": [87, 89, 349, 352], "v5": [87, 89, 100, 127, 138, 352], "airraid": [87, 89, 352], "alien": [87, 89, 352], "time_limit": 87, "timelimit": [87, 109, 110], "default_info_dict_read": [87, 88, 89, 102], "reader": [87, 88, 89, 102, 341], "set_info_dict_read": [87, 88, 89, 102], "info_dict": [87, 88, 89, 102], "auto_register_info_dict": [87, 88, 89, 102], "info_dict_read": [88, 102], "put": [88, 109, 110, 164, 331, 335, 341, 342, 343, 347], "succe": [88, 102], "halfcheetah": [88, 102, 144, 324, 340], "register_info_dict": 88, "read_act": 88, "read_don": 88, "interrupt": [88, 285], "nonsens": 88, "fallback": 88, "broken": [88, 166], "read_ob": 88, "dictat": [88, 235, 239, 266, 340, 347], "read_reward": 88, "baseinfodictread": 88, "hoc": [88, 102], "dict_read": 88, "my_info_kei": 88, "some_env": 88, "vecenv": 89, "vectorenv": 89, "placehold": [90, 127, 158], "secur": 90, "habitat3": 90, "ai": [90, 348], "habitatrenderpick": 90, "isaacgym": [91, 92], "isaacgymwrapp": [91, 333], "isaacgymenv": [92, 333], "webpag": 92, "isaac": 92, "essenc": 92, "instadeepai": [93, 94], "2306": [93, 94], "09884": [93, 94], "snake": [93, 94], "grid": [93, 94, 298], "bodi": [93, 94], "body_st": [93, 94], "fruit_posit": [93, 94], "col": [93, 94], "row": [93, 94], "head_posit": [93, 94], "tail": [93, 94], "game2048": [93, 94], "maze": [93, 94], "cleaner": [93, 94], "cvrp": [93, 94], "multicvrp": [93, 94], "minesweep": [93, 94], "rubikscub": [93, 94], "knapsack": [93, 94], "sudoku": [93, 94], "tsp": [93, 94], "connector": [93, 94], "v2": [93, 94, 106, 107, 274, 288, 289, 290, 291, 293, 294, 295, 296, 324, 343], "mmst": [93, 94], "graphcolor": [93, 94], "partli": [93, 94], "scrambl": [93, 94], "robotwarehous": [93, 94], "tetri": [93, 94], "binpack": [93, 94], "jobshop": [93, 94], "0x1fca91910": 93, "122": [93, 94, 347, 352], "40": [93, 94, 340, 341, 342, 346, 347, 348], "0x1ff9baee0": 93, "134": [93, 94, 347], "0x1ff9ba7c0": 93, "172": [93, 94, 347], "31": [93, 94, 341, 347, 348], "rubric": [94, 136, 241], "mo": [95, 96], "minecart": [95, 96], "mo_gym": 96, "qualnam": 97, "marl": [97, 111, 118, 155, 202, 346], "leverag": [97, 103, 104, 340, 346, 352], "neural": [97, 103, 104, 176, 177, 215, 238, 335, 341, 342, 343, 346, 347, 352], "group_map": [97, 103, 104, 109, 110, 111], "constructiuon": [97, 103, 104], "premad": [97, 103, 104, 109, 110, 277], "all_in_one_group": [97, 111], "agent_0": [97, 103, 104, 111], "agent_1": [97, 103, 104, 111], "agent_2": [97, 103, 104, 111], "agent_3": 97, "one_group_per_ag": [97, 103, 104], "environn": 98, "constraint": [98, 342, 346], "mymbenv": [98, 175, 199], "world_model": [98, 175, 199, 259], "super": [98, 115, 123, 126, 142, 175, 186, 199, 243, 249, 251, 255, 256, 262, 267, 269, 271, 340, 347, 351], "hidden_observ": [98, 175, 199], "mlp": [98, 175, 176, 177, 179, 180, 181, 182, 191, 195, 196, 199, 203, 224, 229, 252, 254, 324, 335, 341, 345, 348, 351], "worldmodelwrapp": [98, 175, 199], "activation_class": [98, 175, 176, 177, 179, 180, 181, 182, 187, 188, 197, 199, 202, 203, 341, 346, 351], "relu": [98, 175, 183, 199, 206, 247], "activate_last_lay": [98, 175, 182, 197, 199], "run_type_check": 98, "sail": [99, 100], "sg": [99, 100], "10558": [99, 100], "less": [99, 221, 329, 330, 336, 342, 343, 349, 351], "readthedoc": 99, "en": 99, "python_interfac": 99, "envpoolmixin": 100, "env_bas": 100, "task_id": 100, "pong": [100, 138, 352], "env_typ": 100, "gym_reset_return_info": 100, "envpool_env": 100, "www": [101, 200, 201], "fetch_openml": 101, "106": [101, 347], "my_env_fun": [102, 108], "custom_attribute_list": [102, 108], "custom_attribut": [102, 108], "custom_method_list": [102, 108], "custom_method": [102, 108], "deploi": [102, 108], "slight": [102, 108, 341], "share_individual_td": [102, 108], "shared_memori": [102, 108], "policy_proof": [102, 108], "ll": [102, 108, 189, 190, 193, 194, 340, 341, 342, 343, 346, 352], "hidden": [102, 108, 117, 187, 189, 190, 191, 193, 194, 195, 196, 207, 208, 213, 214, 224, 225, 226, 228, 238, 241, 250, 263, 266, 335, 343, 345, 351], "introduc": [102, 108, 189, 191, 193, 195, 234, 340], "stringent": [102, 342, 346], "inter": 102, "penv": 102, "tensordictprim": [102, 343], "reward_ctrl": 102, "reward_run": 102, "x_posit": 102, "x_veloc": 102, "env_fix": 102, "drastic": [102, 349], "influenc": 102, "rule": [102, 123, 126, 239, 335, 342], "thumb": [102, 342], "suppos": [102, 311, 337, 352], "scenario": [102, 109, 110, 340, 346, 347], "myenv": [102, 123, 126], "update_kwarg": [102, 108], "pettingzoo": [103, 104], "pet": [103, 104], "zoo": [103, 104], "guid": [103, 104, 106, 107, 153, 334, 340, 346], "__": [103, 104], "aecenv": [103, 104], "use_mask": [103, 104], "dead": [103, 104], "compulsori": [103, 104], "adversary_0": [103, 104], "adversari": [103, 104], "marlgroupmaptyp": [103, 104, 109, 110, 111, 333], "vectoris": [103, 104, 189, 190, 193, 194], "sisl": 103, "multiwalker_v9": 103, "return_st": [103, 104], "categorical_act": [103, 104, 106, 107, 109, 110], "n_piston": [103, 104], "pistonball_v6": [103, 104], "piston": [103, 104], "piston_0": [103, 104], "piston_1": [103, 104], "piston_20": [103, 104], "aec": [103, 104], "tictactoe_v3": [103, 104], "player": [103, 104], "player_1": [103, 104], "player_2": [103, 104], "butterfli": 104, "parallel_env": [104, 340, 351, 352], "vikashplu": 105, "wiki": 105, "06828": 105, "smacv2": [106, 107], "starcraft": [106, 107], "challeng": [106, 107, 347, 348], "10gen_terran": [106, 107], "10gen_zerg": [106, 107], "10gen_protoss": [106, 107], "3m": [106, 107], "8m": [106, 107, 348], "25m": [106, 107], "5m_vs_6m": [106, 107], "8m_vs_9m": [106, 107], "10m_vs_11m": [106, 107], "27m_vs_30m": [106, 107], "mmm": [106, 107], "mmm2": [106, 107], "2s3z": [106, 107], "3s5z": [106, 107], "3s5z_vs_3s6z": [106, 107], "3s_vs_3z": [106, 107], "3s_vs_4z": [106, 107], "3s_vs_5z": [106, 107], "1c3s5z": [106, 107], "2m_vs_1z": [106, 107], "corridor": [106, 107], "6h_vs_8z": [106, 107], "2s_vs_1sc": [106, 107], "so_many_banel": [106, 107], "bane_vs_ban": [106, 107], "2c_vs_64zg": [106, 107], "old": [106, 107, 263, 352], "smac": [106, 107], "map_nam": [106, 107], "176": [106, 107, 347], "battle_won": [106, 107], "dead_al": [106, 107], "dead_enemi": [106, 107], "episode_limit": [106, 107], "322": [106, 107, 347], "Or": [106, 107, 202], "procedur": [106, 107], "distribution_config": [106, 107], "n_unit": [106, 107], "n_enemi": [106, 107], "team_gen": [106, 107], "dist_typ": [106, 107], "weighted_team": [106, 107], "unit_typ": [106, 107], "marin": [106, 107], "maraud": [106, 107], "medivac": [106, 107], "exception_unit_typ": [106, 107], "start_posit": [106, 107], "surrounded_and_reflect": [106, 107], "map_x": [106, 107], "map_i": [106, 107], "capability_config": [106, 107], "88": [106, 107, 340, 341, 347], "131": [106, 107, 347], "starcraft2env": 107, "proroklab": [109, 110], "vectorizedmultiagentsimul": [109, 110], "2207": [109, 110], "03530": [109, 110], "basescenario": 109, "descript": [109, 341, 342], "perfrom": [109, 110], "defaultt": 109, "continuous_act": [109, 110, 346], "repositiori": 109, "horizon": [109, 110, 175, 199, 342], "sparsiti": 109, "agent_nam": [109, 110, 111], "agent_names_to_indices_map": [109, 110], "unbatched_action_spec": [109, 110, 346], "unbatched_observation_spec": [109, 110], "unbatched_reward_spec": [109, 110], "het_spec": [109, 110], "het_specs_map": [109, 110], "distinguish": [109, 110], "flock": [109, 110], "agent_collision_rew": [109, 110], "agent_distance_rew": [109, 110], "ca": 111, "environment4": 111, "get_group_map": 111, "sumbodul": 112, "model_bas": [113, 175, 199], "adapt": [115, 152, 263, 340, 347], "masker": 115, "binarydiscretetensorspec": [115, 252, 255, 256, 277, 333], "maskedenv": 115, "ones_lik": 115, "scatter": 115, "unsqueez": [115, 118, 119, 156, 159, 196, 340, 343, 346, 347], "_set_se": [115, 123, 126, 142, 347], "biner": 116, "transform_reward_spec": [116, 121, 122, 123, 124, 128, 134, 142, 143, 146, 147, 149, 150, 152, 157, 159], "tensordictmodulebas": [117, 221, 229, 236, 343], "burn_in": 117, "burn": 117, "date": [117, 301], "retur": 117, "burnt": 117, "grumodul": 117, "gru_modul": [117, 191], "input_s": [117, 189, 190, 191, 193, 194, 195, 196, 343], "hidden_s": [117, 189, 190, 191, 193, 194, 195, 196, 343], "set_recurrent_mod": [117, 191, 195, 343], "burn_in_transform": 117, "gru": [117, 190, 191], "num_lay": [117, 189, 191, 193, 195, 207, 208], "86": [117, 341, 347], "3008": [117, 341], "37": [117, 339, 340, 341, 342, 346, 347, 350], "0344": 117, "padding_valu": [118, 200, 201], "as_invers": 118, "account": [118, 200, 201, 335, 341, 343, 349, 352], "movement": 118, "pdf": [118, 178, 179, 180, 181, 182, 186, 210, 230, 234, 257, 267, 270, 279, 284, 292, 324], "1312": [118, 341], "5602": 118, "constant": [118, 136, 153, 337, 340, 342, 343, 352], "unsqueezetransform": [118, 347, 349], "consumpt": 118, "followin": 118, "pictur": 118, "pixels_trsf": [118, 349], "grayscal": [118, 341, 343, 349, 352], "data_exclud": [118, 349], "transform_observation_spec": [118, 119, 120, 121, 122, 123, 124, 127, 128, 130, 132, 133, 134, 136, 138, 142, 143, 144, 148, 149, 150, 152, 153, 154, 155, 156, 157, 159, 160, 163, 347], "del_kei": [119, 160, 345, 347], "unsqueeze_if_oor": 119, "observation_posit": 119, "observation_veloc": 119, "delet": 119, "key1": [119, 306, 314], "key2": [119, 306, 314], "center": [120, 298], "width": [120, 144], "out_keys_inv": [121, 123, 126, 136, 137, 138, 142, 143, 150, 157, 347], "scalar": [121, 146, 180, 182, 204, 205, 227, 231, 232, 234, 245, 248, 249, 250, 256, 257, 258, 259, 260, 261, 262, 263, 264, 266, 267, 268, 269, 270, 271, 277, 279, 280, 281, 282, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 335, 341, 347], "permit": [121, 130, 159], "rewardsc": [122, 158, 340, 341, 343], "rewardclip": 122, "transformed_env": [122, 157, 158], "transform_env_devic": [122, 124, 157], "transform_input_spec": [122, 123, 124, 125, 136, 138, 142, 143, 148, 152, 153, 154, 157, 159, 161], "transform_output_spec": [122, 123, 124, 128, 134, 142, 143, 149, 152, 157], "transformfull_done_spec": [122, 123, 124, 128, 134, 142, 143, 149, 152, 157], "dtype_in": 123, "dtype_out": 123, "scan": [123, 126, 240, 241], "resp": [123, 126], "not_transform": [123, 126], "constructedw": [123, 126], "orig_devic": 124, "unspecifi": 124, "transform_done_spec": [124, 157], "num_actions_effect": 125, "max_act": 125, "include_forward": 125, "dimension": [125, 191, 195, 279, 284, 292, 346], "num_act": [125, 256], "action_out": 125, "_call": [125, 130, 347], "eol_kei": 127, "life": 127, "lives_kei": 127, "eol_attribut": 127, "unwrap": 127, "breakout": 127, "210": [127, 138, 340, 347, 352], "160": [127, 138, 341, 347, 352], "eol_transform": 127, "eol": 127, "dqnloss": [127, 248, 249, 251, 254, 256, 257, 258, 261, 262, 264, 266, 267, 268, 269, 270, 271, 272, 277, 322, 333, 336, 341, 343], "register_kei": 127, "loss_or_advantag": 127, "lossmodul": [127, 315, 326, 327, 333], "valueestimatorbas": [127, 264, 333], "excluded_kei": 128, "finit": [129, 349], "first_dim": 130, "last_dim": 130, "allow_positive_dim": [130, 159], "th": [130, 159, 189, 193, 347], "frameskip": 130, "repeatedli": [131, 342, 346], "init_kei": 133, "tracker": 133, "coef": 134, "pi_curr": 134, "pi_0": 134, "overfit": 134, "probabilist": [134, 235, 333, 342, 351], "get_dist": [134, 239, 240], "mod": [134, 191, 195, 242, 343], "normalparamextractor": [134, 335, 342, 346], "probabilisticactor": [134, 224, 225, 226, 228, 248, 249, 253, 255, 256, 262, 265, 266, 267, 268, 269, 271, 335, 340, 342, 346], "tanhnorm": [134, 224, 225, 226, 235, 241, 248, 249, 262, 266, 267, 268, 269, 271, 333, 342, 346, 351], "n_ob": [134, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271], "n_act": [134, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271], "return_log_prob": [134, 224, 225, 226, 235, 239, 241, 268, 335, 342, 346, 351], "apply_": 134, "copy_": [134, 340], "formulat": 134, "diverg": [134, 191, 195, 235, 239, 259, 263], "noop": [135, 351], "trial": 135, "op": [135, 163, 227, 231, 232, 317, 343], "standard_norm": [136, 147, 340, 341, 343], "affin": [136, 147], "layer": [136, 164, 176, 177, 179, 180, 187, 189, 190, 191, 193, 194, 195, 197, 202, 203, 204, 205, 207, 208, 215, 216, 222, 233, 242, 335, 341, 342, 343, 348], "normal": [136, 164, 176, 177, 192, 197, 200, 201, 206, 218, 219, 227, 235, 239, 250, 263, 266, 311, 313, 331, 335, 337, 343, 346, 352], "set_default_tensor_typ": 136, "doubletensor": 136, "isclos": 136, "next_ob": [136, 279, 280, 281, 282, 351], "init_stat": [136, 340, 341, 342, 343], "3752e": 136, "01": [136, 234, 245, 250, 263, 266, 339, 340, 341, 343, 346, 347, 348, 350], "5087e": 136, "9294e": 136, "9636": 136, "5608": 136, "6408": 136, "num_it": [136, 341, 342], "reduce_dim": [136, 340, 341, 342, 343], "cat_dim": [136, 340, 341, 342, 343], "keep_dim": [136, 341, 343], "statist": [136, 164, 268, 331, 340, 341, 342, 352], "approach": [136, 340, 342, 352], "gaussian": [136, 154, 175, 199, 204, 205, 210, 227, 342], "empir": [136, 175, 199, 235, 239, 340, 342, 346], "3d": [136, 176], "third": [136, 230, 346], "reorder": 138, "in_keys_in": 138, "channel": [138, 156, 202, 207, 208, 341], "r3m": [140, 348], "resnet": [140, 160, 162], "visual": [140, 160, 162, 342, 347], "embed": [140, 160, 161, 162, 211, 223, 224, 225, 226, 238, 243, 348], "ego4d": [140, 160, 162], "univers": [140, 160, 162], "suraj": [140, 160], "nair": [140, 160], "aravind": [140, 160], "rajeswaran": [140, 160], "vikash": [140, 160, 162], "kumar": [140, 160, 162], "chelsea": [140, 160], "finn": [140, 160], "abhinav": [140, 160], "gupta": [140, 160], "2203": [140, 160, 199, 348], "12601": [140, 160, 348], "_init": [140, 160, 340], "snippet": [140, 160, 340], "resnet50": [140, 162, 348], "model_nam": [140, 160, 162, 301], "resnet34": 140, "resnet18": 140, "r3m_vec": [140, 348], "feed": [140, 162, 264, 335, 340, 346, 349], "stack_imag": [140, 162], "tread": [140, 162], "separet": [140, 162], "hub": [140, 162, 348], "resnet50_weight": [140, 162], "imagenet1k_v1": [140, 162], "download_path": [140, 162], "tensor_pixels_kei": [140, 162], "dest": [140, 160, 162, 238], "sub_seq_len": 141, "sample_dim": [141, 340], "primarili": 141, "hesit": 141, "request": 141, "robust": 141, "mix": [141, 211, 220, 277, 340, 346], "improp": 141, "dummyenv": 142, "another_oth": 142, "other_reward": 142, "create_copi": 143, "stuff": 143, "newnam": 143, "84": [144, 340, 341, 343, 347], "r2g": 145, "99": [145, 164, 199, 260, 273, 278, 285, 327, 339, 340, 341, 342, 347, 350, 351, 352], "reward_to_go": 145, "bernoulli_": 145, "9010": 145, "9404": [145, 285], "9701": [145, 285], "9900": [145, 285], "0000": [145, 155, 231, 232, 242, 285, 342, 343, 347, 351], "crash": 145, "clamp_min": 146, "clamp_max": 146, "clip_min": 146, "clip_max": 146, "episode_": 148, "reward1": 148, "reward2": 148, "episode_reward": [148, 346], "keep_reward": 149, "keep_don": 149, "sign": [150, 279], "logical_or": 150, "squeeze_dim": 151, "step_count_kei": 152, "update_don": 152, "accordingli": [152, 153, 193, 236, 343], "disjunct": 152, "recognis": 152, "target_return": 153, "primer": [154, 343], "default_valu": [154, 343], "unit": [154, 175, 187, 189, 190, 207, 208, 213, 214, 342], "transfomedenv": 154, "mykei": 154, "__unless": 154, "exists__": 154, "pool": 155, "increas": [155, 234, 346], "10th": 155, "0216": 155, "1149": 155, "1990": 155, "2749": 155, "3281": 155, "9290": 155, "3702": 155, "8978": 155, "from_int": 156, "shape_toler": 156, "permuat": 156, "ri": 156, "principl": 157, "cattransform": 157, "notabl": 157, "rewardsum": [157, 346], "cache_spec": 158, "set_missing_toler": 158, "keyerror": 158, "unsqueeze_dim": [159, 347], "danger": 159, "vc1": 160, "vc1_vec": 160, "small": [160, 340, 342, 346, 352], "untrain": 160, "make_noload_model": 160, "naiv": 160, "vip": [161, 162, 348], "toward": 162, "implicit": [162, 255, 262, 349], "jason": 162, "ma": 162, "shagun": 162, "sodhani": 162, "dinesh": 162, "jayaraman": 162, "osbert": 162, "bastani": 162, "ami": 162, "zhang": 162, "vip_vec": 162, "final_nam": 163, "sb3": 163, "terminal_obs_read": 163, "truli": [163, 351], "till": 163, "did": [163, 285, 341, 342, 349, 352], "nan": 163, "shared_td": 164, "decai": [164, 227, 231, 232, 270, 313, 340, 341, 343, 352], "9999": [164, 347], "0001": [164, 187, 206, 342, 347], "fly": [164, 263, 336, 342, 347, 349, 352], "to_observation_norm": 164, "underflow": [164, 313], "build_td_for_shared_vecnorm": 164, "memmori": 164, "queue": [164, 349], "td_share": 164, "state_dim": [165, 178, 183, 210, 213, 214, 228], "action_dim": [165, 178, 179, 181, 183, 210, 228, 340, 345], "gsde": [165, 267, 331], "func": 165, "gsdemodul": 165, "check_dtyp": 166, "discrep": [166, 248, 250, 251, 252, 263, 266, 268, 277], "imposs": 166, "probabilistictdmodul": [171, 172, 197, 235, 239, 278, 311], "next_tensordict": 173, "keep_oth": [173, 347], "exclude_reward": 173, "exclude_don": 173, "exclude_act": 173, "next_": 173, "funtion": 173, "write_full_fals": 174, "leav": [174, 340], "_terminated_or_trunc": 174, "entropi": [175, 248, 249, 250, 255, 256, 262, 263, 265, 266, 267, 269, 271, 346], "botev": 175, "et": 175, "2013": 175, "cem": 175, "plan": [175, 198, 199], "varianc": [175, 192, 206, 218, 219, 336, 340, 342, 346], "k": [175, 189, 190, 193, 194], "maximis": [175, 179, 181, 199, 335, 340, 341, 342, 346], "modelbasedenv": [175, 199], "planning_horizon": [175, 199], "optim_step": [175, 199, 341], "mpc": [175, 198, 199], "num_candid": [175, 199], "candid": [175, 199], "top_k": [175, 199], "modelbasedenvbas": [175, 198, 199, 333], "safemodul": [175, 198, 224, 226, 239, 248, 249, 255, 256, 262, 266, 267, 268, 269, 271, 320, 321, 327, 333, 351], "num_cel": [176, 177, 179, 180, 181, 182, 187, 188, 191, 195, 197, 202, 203, 224, 341, 342, 343, 346, 351], "elu": [176, 177, 179, 180, 181, 182, 187, 188, 202, 341, 351], "activation_kwarg": [176, 177, 197], "norm_class": [176, 177, 179, 180, 197], "norm_kwarg": [176, 177, 197], "bias_last_lay": [176, 177, 179, 180, 181, 182, 188, 197], "aggregator_class": [176, 177, 179, 180, 341, 343, 351], "squashdim": [176, 177, 179, 202, 351], "aggregator_kwarg": [176, 177, 179, 180, 341, 343], "squeeze_output": [176, 177, 179, 180, 341, 343], "convolut": [176, 177, 179, 180, 202, 215], "produc": [176, 177, 197, 203, 209, 224, 226, 228, 298, 342, 343, 349, 352], "cell": [176, 177, 189, 190, 191, 193, 194, 195, 197, 202, 203, 342], "kernel": [176, 177, 188, 196, 202], "cnet": [176, 177], "conv3d": 176, "34": [176, 177, 197, 340, 341, 343, 347], "35": [176, 177, 197, 339, 341, 347, 348, 350, 352], "transformer_config": [178, 210, 228], "decisiontransform": [178, 210], "dtconfig": [178, 183, 210], "2202": [178, 183, 210, 265], "05607": [178, 183, 210, 265], "return_to_go": [178, 183, 210, 228], "conv_net_kwarg": [179, 180], "mlp_net_kwarg": [179, 180, 181], "use_avg_pool": [179, 180], "WITH": [179, 180, 181, 182, 234, 270], "1509": [179, 180, 181, 182, 199, 234, 252, 261, 270, 347], "02971": [179, 180, 181, 182, 234, 270], "convnet": [179, 202, 343, 351], "ndims_in": 179, "avgpool": [179, 180], "adaptiveavgpool2d": [180, 341, 343], "400": [181, 182, 346, 347, 349], "mlp_net_kwargs_net1": 182, "mlp_net_kwargs_net2": 182, "decion": 183, "desdescrib": 183, "n_embd": 183, "n_layer": [183, 189, 193], "n_head": 183, "n_inner": 183, "n_posit": 183, "resid_pdrop": 183, "attn_pdrop": 183, "gpt2config": 183, "atol": [184, 217], "06": [184, 217, 340, 341, 342, 346, 347, 348], "rtol": [184, 217], "batch_shap": [184, 217], "event_shap": [184, 217], "absolut": [184, 217, 340], "densiti": [184, 200, 201, 209, 219], "mass": [184, 200, 201, 209, 219, 347], "rsampl": [184, 201, 209, 239], "sample_shap": [184, 200, 201, 209], "dqnet": 185, "atom": 185, "softmax": [185, 201, 209, 229, 230], "var_num": [186, 212, 229, 230, 237], "action_value_kei": [186, 212, 229, 230, 236, 237, 264, 277], "action_mask_kei": [186, 212, 229, 230, 231, 232, 236, 237], "perspect": [186, 230, 257, 342], "1707": [186, 230, 257, 266], "06887": [186, 230, 257], "mult": [186, 203, 212, 229, 230, 236, 237], "tensordict_modul": [186, 189, 190, 193, 194, 212, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 248, 249, 251, 255, 256, 262, 266, 267, 268, 269, 271, 335], "nbin": [186, 229, 335], "customdistributionalqv": 186, "log_softmax": [186, 229], "from_modul": [186, 235, 238, 241, 243], "one_hot": [186, 201, 212], "qvalue_actor": [186, 212, 229, 236, 335], "to_modul": [186, 235, 238, 241, 243], "std_bia": 187, "std_min_val": 187, "belief": [187, 207, 213, 214], "1912": [187, 258, 259, 260], "01603": [187, 258, 259, 260], "softplu": [187, 206, 245, 246, 247], "out_features_valu": 188, "cnn_kwarg": [188, 341], "mlp_kwarg": [188, 196, 341], "duel": 188, "cnn": [188, 202, 341, 351], "06581": 188, "batch_first": [189, 191, 193, 195, 343], "bidirect": [189, 193, 343], "cudnn": [189, 190, 193, 194, 343], "vmap": [189, 190, 193, 194, 221, 238, 241, 351], "rnn": [189, 190, 193, 194, 343], "device_count": [189, 190, 193, 194, 340, 341, 343, 348, 352], "els": [189, 190, 193, 194, 207, 335, 337, 340, 341, 342, 343, 346, 347, 348], "n_in": [189, 190, 193, 194], "n_out": [189, 190, 193, 194], "h0": [189, 190, 193, 194], "h1": [189, 190, 193, 194], "call_gru": [189, 190], "h_out": [189, 190, 193, 194], "batched_cal": [189, 190, 193, 194], "gate": [189, 190, 193], "r_t": 189, "sigma": [189, 190, 192, 193, 194, 210, 218, 219, 227, 234, 342], "w_": [189, 190, 193, 194], "ir": [189, 190], "x_t": [189, 193], "b_": [189, 190, 193, 194], "hr": [189, 190, 193], "h_": [189, 190, 193], "z_t": 189, "iz": [189, 190], "hz": [189, 190], "n_t": 189, "odot": [189, 190, 193, 194], "hn": [189, 190, 193], "h_t": [189, 193], "sigmoid": [189, 190, 193, 194], "hadamard": [189, 190, 193, 194], "multilay": [189, 193], "_t": [189, 193, 346, 347], "ge": [189, 193], "bernoulli": [189, 193], "b_ih": [189, 190, 193, 194, 195], "b_hh": [189, 190, 193, 194, 195], "seq": [189, 191, 193, 195, 343, 345], "h_0": [189, 193, 194], "unbatch": [189, 193], "pack": [189, 193, 342, 352], "pack_padded_sequ": [189, 193], "pack_sequ": [189, 193], "num": [189, 193], "_layer": [189, 193], "_size": [189, 190, 193, 194], "h_n": [189, 193], "packedsequ": [189, 193], "weight_ih_l": [189, 193], "learnabl": [189, 190, 193, 194], "w_ir": 189, "w_iz": 189, "w_in": 189, "num_direct": [189, 193], "weight_hh_l": [189, 193], "w_hr": 189, "w_hz": 189, "w_hn": 189, "bias_ih_l": [189, 193], "b_ir": 189, "b_iz": 189, "b_in": 189, "bias_hh_l": [189, 193], "b_hr": 189, "b_hz": 189, "b_hn": 189, "bias": [189, 190, 193, 194, 245, 336, 340], "mathcal": [189, 190, 193, 194], "sqrt": [189, 190, 193, 194, 234], "frac": [189, 190, 193, 194, 342], "seq_len": [189, 193], "subtli": 189, "matrix": [189, 193, 204, 205], "contrast": [189, 261, 349], "hx": [189, 190, 193, 194], "lstmcell": [190, 195], "gru_cel": 190, "z": 190, "weight_ih": [190, 194], "weight_hh": [190, 194], "bias_ih": [190, 194], "bias_hh": [190, 194], "rocm": [190, 194], "embedd": [191, 195, 196], "grucel": [191, 238], "proj_siz": [191, 193], "python_bas": [191, 195], "recurrent_st": [191, 343], "custom_kei": [191, 195], "recurrent_mod": [191, 195], "rs": [191, 340], "gru_module_train": 191, "policy_train": [191, 195], "traj_td": [191, 195], "policy_infer": [191, 195], "td_inf": [191, 195], "assert_clos": [191, 195], "upscal": [192, 218, 219], "tanh_loc": [192, 218, 219], "event_dim": [192, 217, 218], "ultim": [192, 218, 219], "poor": [192, 218, 219], "explos": [192, 218, 219], "switch": [192, 219], "formula": [192, 218, 219, 248, 250, 263, 266, 336, 342], "c0": [193, 194], "c1": [193, 194], "call_lstm": [193, 194], "c_out": [193, 194], "i_t": 193, "ii": [193, 194], "hi": [193, 194], "f_t": 193, "hf": [193, 194], "g_t": 193, "ig": [193, 194], "hg": [193, 194], "o_t": 193, "ho": [193, 194], "c_t": 193, "c_": 193, "forget": 193, "consequ": 193, "1402": 193, "1128": 193, "c_0": [193, 194], "proj": 193, "c_n": 193, "w_ii": 193, "w_if": 193, "w_ig": 193, "w_io": 193, "w_hi": 193, "w_hf": 193, "w_hg": 193, "w_ho": 193, "b_ii": 193, "b_if": 193, "b_ig": 193, "b_io": 193, "b_hi": 193, "b_hf": 193, "b_hg": 193, "b_ho": 193, "weight_hr_l": 193, "_revers": 193, "analog": 193, "cn": 193, "lstm_cell": 194, "h_1": 194, "c_1": 194, "time_step": [194, 196], "cx": 194, "trust": 195, "correspont": 195, "recurrent_state_h": [195, 343], "recurrent_state_c": [195, 343], "triplet": [195, 236, 237], "lstm_modul": 195, "rs_h": 195, "rs_c": 195, "hidden0": 195, "hidden1": 195, "lstm_kwarg": 196, "next_observ": [196, 248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 345], "2d": [196, 346], "hidden0_in": 196, "hidden1_in": 196, "hidden0_out": 196, "hidden1_out": 196, "single_bias_last_lay": 197, "layer_class": 197, "layer_kwarg": 197, "perceptron": 197, "seamless": 197, "lazylinear": [197, 335, 342, 347, 348, 351], "42": [197, 248, 249, 251, 255, 262, 269, 340, 341, 343, 347], "noisylinear": [197, 204, 333, 341], "noisylazylinear": [197, 333], "At": [198, 231, 341, 342, 343, 345, 347, 348], "mpcplanner": 198, "tensordict_out": [198, 352], "mppi": 199, "covari": 199, "william": [199, 268], "aldrich": 199, "theodor": 199, "01149": 199, "hansen": 199, "wang": 199, "su": 199, "04955": 199, "valueoper": [199, 224, 225, 226, 248, 249, 250, 251, 255, 256, 262, 263, 266, 267, 268, 269, 271, 327, 335, 340, 342], "tdlambdaestim": [199, 333, 340], "value_net": [199, 252, 254, 268, 279, 280, 281, 282, 342], "adv": 199, "lmbda": [199, 273, 279, 282, 284, 290, 291, 292, 295, 296, 336, 340, 342, 346], "95": [199, 273, 340, 341, 342, 343, 347], "value_network": [199, 251, 252, 254, 255, 257, 262, 269, 279, 280, 281, 282, 336, 340, 342], "temperatur": [199, 249, 255, 262], "neg_inf": [200, 201], "inf": [200, 201], "api_doc": [200, 201], "tf_agent": [200, 201], "event": [200, 201, 209, 288, 289, 290, 291, 293, 294, 295, 296, 349], "unnorm": [200, 201, 209], "sparse_mask": [200, 201], "dens": [200, 201], "0831": [200, 201], "1203": [200, 201], "0928": [200, 201], "1972": [200, 201], "grad_method": [201, 209], "reparamgradientstrategi": [201, 209], "passthrough": [201, 209], "proxi": [201, 209, 336], "relaxedonehot": [201, 209], "zeros_lik": [201, 347], "sample_non_valid": 201, "centralis": [202, 203, 346], "share_param": [202, 203, 346], "basi": [202, 349], "homogen": [202, 203, 346], "agent_network": [202, 203], "modulelist": [202, 203, 324, 351], "lazyconv2d": [202, 351], "2592": [202, 341], "decentralis": [202, 346], "n_agent_input": [203, 346], "n_agent_output": [203, 346], "toech": 203, "centalis": 203, "shown": [203, 335, 345, 346, 349], "std_init": [204, 205], "initialize_paramet": 204, "isol": [204, 264], "1706": [205, 220], "10295v3": 205, "induc": 205, "aid": 205, "scale_map": 206, "biased_softplus_1": 206, "scale_lb": [206, 213, 214], "exp": [206, 247], "module_norm": 206, "decod": 207, "1803": [207, 208, 211], "10122": [207, 208], "rnn_hidden": 207, "latent": 208, "excacli": 209, "inres": 210, "mu": [210, 234, 342], "state_shap": [211, 277], "mixing_embed_dim": [211, 277], "qmix": [211, 346], "mixer": [211, 220, 277], "monoton": 211, "hyper": 211, "11485": 211, "qmixerloss": [211, 220], "qmix_vdn": [211, 220], "eventu": [211, 343, 347], "vdn": [211, 220], "greedi": [212, 230, 231, 232, 237, 341, 343], "hidden_dim": [213, 214], "posterior": [213, 259], "rssm": [213, 214, 259], "1811": [213, 214], "04551": [213, 214], "obs_embed": 213, "rnn_hidden_dim": 214, "dream": 214, "tanhtransform": 218, "decomposit": 220, "05296": 220, "hide": [221, 342, 346], "satisfi": [221, 335], "vmap_dim": 221, "lam": 221, "sample_in": 221, "sample_in_td": 221, "vm": 221, "translat": [223, 235], "character": [223, 229, 235, 236, 238, 349], "overflow": [223, 229, 230, 235, 236, 237, 238, 239], "td_modul": [223, 224, 225, 226, 235, 238, 239, 241, 243, 351], "3635": 223, "0340": 223, "1476": 223, "3911": [223, 347], "1664": [223, 341, 347], "5455": 223, "2247": 223, "4583": 223, "2916": 223, "2160": 223, "5337": 223, "5193": 223, "grad_fn": [223, 231, 232, 351], "addmmbackward0": 223, "actorvalueoper": [224, 335], "get_policy_oper": [224, 225, 226, 250, 263, 266, 335], "standalon": [224, 225, 226], "tdmodul": [224, 225, 226, 327], "get_critic_oper": 224, "common_oper": [224, 226], "policy_oper": [224, 225, 226], "value_oper": [224, 225, 226], "normalparamwrapp": [224, 225, 226, 235, 241, 248, 249, 255, 256, 262, 266, 267, 268, 269, 271, 333, 351], "module_hidden": [224, 226], "td_module_hidden": [224, 226], "module_act": [224, 226], "td_module_act": [224, 225, 226], "module_valu": [224, 225, 226], "td_module_valu": [224, 225, 226], "state_action_valu": [224, 243, 249, 255, 269, 278, 324, 327, 335, 340, 351], "td_clone": [224, 225, 226], "tensordictmodulewrapp": [224, 320, 321, 327], "get_policy_head": [224, 225, 226], "safesequenti": [224, 225, 226, 277], "head": [224, 226, 250, 263, 266], "get_value_head": [224, 225, 226], "get_value_oper": [224, 225, 226, 250, 263, 266], "action_modul": 225, "state_valu": [225, 226, 243, 250, 255, 263, 266, 267, 269, 279, 280, 281, 282, 284, 286, 288, 290, 292, 293, 295, 335, 340, 342, 346], "qualiti": [226, 335], "actorcriticoper": [226, 250, 263, 266, 335], "embeddig": 226, "refet": 226, "actorcriticwrapp": [226, 335, 340], "po": [227, 232], "sigma_init": 227, "epsilon": [227, 231, 232, 234, 270, 313, 341, 342, 343], "sigma_end": 227, "annealing_num_step": [227, 231, 232, 234, 340, 341, 343], "captur": [227, 231, 232, 234], "omiss": [227, 231, 232, 234], "ommit": [227, 231, 232, 234, 349], "inferec": 228, "set_tensor_kei": 228, "dt_inference_wrapp": 228, "baz": 228, "inference_context": 228, "obs_dim": 228, "tanhdelta": [228, 333, 340], "dtactor": 228, "actor_modul": [228, 351], "dist_class": 228, "dist_kwarg": 228, "distribution_kwarg": [228, 235, 239, 342, 346], "inference_actor": 228, "sequence_length": 228, "mask_context": 228, "out_act": 228, "qvaluemodul": [229, 236, 277, 343], "distributionaldqnnet": 229, "make_log_softmax": 229, "my_action_valu": [230, 237], "chanc": 230, "thid": 230, "eps_init": [231, 232, 234, 341, 343], "eps_end": [231, 232, 234, 341], "explorative_polici": [231, 232, 234], "9055": [231, 232, 347], "9277": [231, 232], "6295": [231, 232], "2532": [231, 232], "addbackward0": [231, 232], "lmheadmodel": 233, "actor_head": [233, 250, 263, 266], "base_model": 233, "lm_head": 233, "ornstein": 234, "uhlenbeck": 234, "ou": [234, 340], "correl": 234, "noise_t": 234, "noise_": 234, "theta": [234, 342, 347], "sigma_t": 234, "sigma_": 234, "anneal": 234, "ou_prev_nois": 234, "ou_step": 234, "x0": 234, "sigma_min": 234, "n_steps_ann": 234, "is_init_kei": 234, "_ou_prev_nois": 234, "_ou_step": 234, "default_interaction_typ": [235, 239], "interaction_typ": [235, 239], "set_interaction_typ": [235, 239], "cache_dist": [235, 239], "n_empirical_estim": [235, 239], "compound": 235, "compositedistribut": 235, "categ": 235, "distribution_map": 235, "chose": 237, "functionalmodul": 238, "functionalmodulewithbuff": 238, "td_fmodul": 238, "td_function": 238, "td_state": 238, "params_repeat": 238, "td_vmap": [238, 241], "random_sampl": [238, 239], "suppli": 239, "fist": 239, "log_prob_kei": [239, 346], "probabilistictensordictsequenti": [240, 248, 250, 263, 266, 268, 320, 321, 351], "partial_toler": [240, 241, 345], "who": [240, 241], "AND": [240, 241], "tensordictsequenci": 241, "tensordictsequ": 241, "safeprobabilisticmodul": [241, 335], "spec1": 241, "net1": 241, "module1": 241, "td_module1": 241, "spec2": 241, "module2": 241, "td_module2": 241, "clamp": [242, 259, 315, 347], "boundari": [242, 342, 346], "resolut": 242, "simplest": [242, 340, 342, 343, 346, 349, 352], "9944": 242, "9991": 242, "3020": 242, "2299": [242, 347], "5418": 242, "2989": 242, "6849": 242, "3169": 242, "2690": 242, "9649": [242, 347], "5686": 242, "8602": 242, "0315": 242, "8455": [242, 347], "6027": 242, "4746": 242, "7843": 242, "7782": 242, "2111": 242, "5115": 242, "4687": 242, "5760": 242, "custommodul": 243, "cat": [243, 249, 251, 262, 267, 269, 271, 351], "imaginari": 244, "imagin": 244, "transition_model": 244, "get_reward_oper": 244, "get_transition_model_oper": 244, "min_val": [245, 247], "_bia": 245, "invert": [246, 342], "surject": 247, "expln": 247, "biased_softplu": [247, 333], "beggin": 247, "biased_softplus_": 247, "syntax": [247, 340], "met": [247, 347], "1602": 248, "01783v2": 248, "entropy_bonu": [248, 250, 263, 266, 342], "favour": [248, 250, 263, 266], "samples_mc_entropi": [248, 250, 263, 265, 266], "mont": [248, 250, 263, 266, 340], "carlo": [248, 250, 263, 266, 340], "entropy_coef": [248, 250, 263, 266, 342, 346], "critic_coef": [248, 250, 263, 266, 342], "loss_critic_typ": [248, 250, 263, 266, 268, 342], "l1": [248, 250, 251, 252, 256, 263, 266, 267, 268, 271, 274, 277, 335, 340], "l2": [248, 250, 251, 252, 253, 254, 256, 259, 260, 263, 266, 267, 268, 271, 274, 277, 340], "smooth_l1": [248, 249, 250, 251, 252, 255, 256, 262, 263, 266, 267, 268, 269, 271, 274, 277, 342], "separate_loss": [248, 250, 251, 255, 256, 262, 263, 266, 267, 268, 269, 271], "propag": [248, 250, 251, 255, 256, 262, 263, 266, 267, 268, 269, 271, 279, 280, 281, 282, 342, 346], "advantage_kei": [248, 250, 263, 266, 268, 279, 280, 281, 282], "value_target_kei": [248, 250, 263, 266, 268, 279, 280, 281, 282, 342], "value_target": [248, 250, 263, 266, 268, 279, 280, 281, 282, 342, 346], "loss_crit": [248, 266, 342, 346], "loss_entropi": [248, 266, 342, 346], "loss_object": [248, 266, 342, 346], "recur": [248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 279, 280, 281, 282, 283], "next_reward": [248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 279, 280, 281, 282], "next_don": [248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 279, 280, 281, 282], "next_termin": [248, 249, 251, 252, 254, 255, 256, 262, 266, 267, 268, 269, 271, 279, 280, 281, 282], "loss_obj": 248, "sacloss": [248, 261, 270, 333], "select_out_kei": [248, 249, 251, 255, 256, 262, 266, 267, 269, 271], "essenti": [248, 249, 250, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 269, 271, 277, 341, 347, 349], "make_value_estim": [248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 272, 277, 336, 340, 341, 346], "value_typ": [248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 273, 277, 340], "valueestim": [248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 273, 277, 333, 336, 340, 346], "hyperparam": [248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 340], "enum": [248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 273, 277, 340], "default_value_estim": [248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 340], "default_value_kwarg": [248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 333, 340], "dqn_loss": [248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 272, 277], "td1": [248, 249, 251, 252, 254, 256, 257, 258, 262, 264, 266, 267, 268, 269, 271, 277, 340], "conserv": [249, 254], "actor_network": [249, 251, 253, 255, 256, 262, 265, 267, 269, 271, 340], "qvalue_network": [249, 255, 256, 262, 267, 269, 271], "loss_funct": [249, 251, 252, 253, 254, 255, 256, 262, 267, 269, 271, 274, 277, 340], "alpha_init": [249, 256, 265, 267, 269], "min_alpha": [249, 256, 265, 267, 269], "max_alpha": [249, 256, 265, 267, 269], "fixed_alpha": [249, 256, 265, 267, 269], "target_entropi": [249, 256, 265, 267, 269], "prod": [249, 265, 269], "n_action": [249, 252, 254, 265, 269], "delay_actor": [249, 251, 269, 271], "delay_qvalu": [249, 256, 267, 269, 271], "min_q_weight": 249, "max_q_backup": 249, "backup": 249, "deterministic_backup": 249, "num_random": 249, "with_lagrang": 249, "lagrang": 249, "lagrange_thresh": 249, "valueclass": [249, 251, 255, 256, 262, 267, 269, 271], "qvalu": [249, 255, 256, 262, 267, 269, 271, 324], "loss_actor": [249, 251, 255, 256, 262, 267, 268, 269, 271, 310, 340, 351], "loss_alpha": [249, 256, 267, 269], "loss_alpha_prim": 249, "loss_qvalu": [249, 255, 256, 262, 267, 269, 271], "clip_epsilon": [250, 342, 346], "normalize_advantag": [250, 263, 266, 346], "value_kei": [250, 263, 266, 279, 280, 281, 282, 340], "somemodul": [250, 263, 266], "someactor": [250, 263, 266], "value_head": [250, 263, 266], "somevalu": [250, 263, 266], "loss_modul": [250, 261, 263, 264, 266, 270, 315, 326, 327, 336, 337, 340, 341, 342, 346, 349], "ppoloss": [250, 263, 333], "delay_valu": [251, 252, 254, 257, 268, 269, 277, 341, 343], "loss_valu": [251, 255, 262, 268, 269, 340, 342, 346, 351], "pred_valu": [251, 271, 340, 351], "pred_value_max": [251, 340, 351], "target_valu": [251, 267, 271, 278, 336, 340, 351], "target_value_max": [251, 340, 351], "qvalueactor": [252, 254, 277, 335, 341, 343], "double_dqn": 252, "06461": [252, 261], "mult_one_hot": [252, 255, 256, 277], "loss_val": [252, 254, 336, 340, 342, 343, 346, 349], "01345": 253, "distanc": [254, 263, 274, 278, 279, 346], "loss_cql": 254, "dcql_loss": 254, "2110": [255, 262], "06169": [255, 262], "num_qvalue_net": [255, 256, 262, 267, 269, 271], "expectil": [255, 262], "tau": [255, 262, 270, 340, 341], "antmaz": [255, 262], "sticht": [255, 262], "onehotcategor": [255, 256, 333], "target_entropy_weight": 256, "disctount": 257, "distributionalqvalueactor": [257, 335], "input_tensordict": [257, 340], "actor_model": 258, "value_model": [258, 260], "model_based_env": 258, "dreamerenv": [258, 333], "imagination_horizon": 258, "unrol": [258, 284, 285, 288, 289, 290, 291, 292, 293, 294, 295, 296], "discount_loss": [258, 260], "lambda_kl": 259, "lambda_reco": 259, "lambda_reward": 259, "reco_loss": 259, "reward_loss": 259, "free_nat": 259, "nat": 259, "delayed_clamp": 259, "global_averag": 259, "value_loss": 260, "fake_data": 260, "ddpgloss": [261, 270, 327, 333, 340, 351], "td3loss": [261, 270, 333], "value_network_update_interv": 261, "loss_value_diff": 262, "diff": 262, "old_polici": 263, "new_polici": 263, "apart": [263, 346], "dtarg": 263, "samples_mc_kl": 263, "analyt": 263, "decrement": 263, "loss_": [264, 310, 336, 340], "equip": [264, 343], "gh": 264, "_acceptedkei": 264, "dataclass": [264, 324], "_forward_value_estimator_kei": 264, "alter": [264, 335], "value_estim": [264, 279, 280, 281, 282, 283, 336, 340, 346], "myloss": 264, "action2": 264, "convert_to_funct": [264, 340], "expand_dim": 264, "create_target_param": [264, 340], "compare_against": [264, 340], "_param": 264, "expans": 264, "resampl": 264, "_target_param": 264, "blend": 264, "upcom": [264, 288, 289, 290, 291, 293, 294, 295, 296, 340], "proxim": [266, 342, 346], "optimis": [266, 311, 342, 346], "flavour": [266, 346, 351], "clipppoloss": [266, 333, 342, 346], "klpenppoloss": [266, 333], "regularis": 266, "06347": 266, "gae": [266, 333, 336, 340, 342, 346], "ppo_loss": 266, "tdlambda": [266, 273, 336, 340], "base_lay": 266, "randn_lik": 266, "samplelogprob": 266, "openreview": [267, 324], "ay8zfzm0tdd": [267, 324], "sub_sample_len": 267, "subsampl": [267, 306, 337], "action_log_prob_actor": 267, "state_action_value_actor": [267, 271], "connectionist": 268, "1992": 268, "doi": 268, "1007": 268, "bf00992696": 268, "actor_net": [268, 340, 342], "1801": 269, "01290": 269, "applic": [269, 277, 347], "1812": 269, "05905": 269, "redqloss": [270, 333], "math": 270, "theta_t": [270, 347], "theta_": [270, 347], "polyak": 270, "policy_nois": 271, "noise_clip": 271, "next_state_valu": [271, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 333], "td0": [272, 340], "strict_shap": 274, "view_a": 274, "qmixer": [277, 333], "local_valu": 277, "visibl": [277, 346], "dafault": 277, "acceptedkei": 277, "global_valu": 277, "penultim": 277, "local_value_network": 277, "mixer_network": 277, "suggest": [277, 346], "value_modul": [277, 342, 351], "qnet": [277, 340], "next_val_kei": 278, "pred_next_v": 278, "usus": 278, "mse": 278, "q_valu": 278, "n_steps_to_next": 278, "value_next_st": 278, "1506": [279, 284, 292], "02438": [279, 284, 292], "exponenti": [279, 280, 281, 282, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 313], "average_ga": [279, 342], "skip_exist": [279, 280, 281, 282], "advang": 279, "gradient_mod": 279, "value_error": [279, 280, 281, 282, 283], "target_param": [279, 280, 281, 282, 283, 340, 346], "98": [279, 280, 281, 282, 340, 341, 347], "94": [279, 282, 341, 347, 348], "unpack": [279, 280, 281, 282], "tensor_kei": [279, 280, 281, 282, 283], "next_valu": [279, 280, 281, 282, 283], "aka": [280, 341], "average_reward": [280, 281, 282], "tdestim": [280, 281, 283], "infti": 281, "valuefunctionbas": 283, "time_dim": [284, 285, 288, 289, 290, 291, 292, 293, 294, 295, 296], "old_stat": [284, 286, 288, 290, 292, 293, 295], "new_stat": [284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296], "rolling_gamma": [288, 289, 290, 291, 293, 294, 295, 296], "g1": [288, 289, 290, 291, 293, 294, 295, 296], "g2": [288, 289, 290, 291, 293, 294, 295, 296], "g3": [288, 289, 290, 291, 293, 294, 295, 296], "g4": [288, 289, 290, 291, 293, 294, 295, 296], "v3": [288, 289, 290, 291, 293, 294, 295, 296], "out_file_bas": 297, "skip_reset": 297, "interv": [297, 298, 307, 317, 341, 347], "center_crop": 298, "make_grid": 298, "exp_nam": [299, 300, 303, 304, 305, 327, 341], "log_dir": [299, 300, 302, 304, 341], "templat": 299, "csv": [300, 302, 341], "minim": [300, 349], "dependeci": 300, "experiment_nam": [301, 302], "uuid": [301, 341, 352], "logger_typ": 302, "logger_nam": 302, "tensorboard": [302, 304, 351], "wandb": [302, 305, 351], "mlflow": [302, 303], "wandb_kwarg": 302, "mlflow_kwarg": 302, "tracking_uri": 303, "uri": 303, "datastor": 303, "tb_log": 304, "tensoarboard": 304, "sub_traj_len": 306, "min_sub_traj_len": 306, "register_op": [306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 317, 337, 341], "process_optim_batch": [306, 312, 313, 337], "td_out": [306, 314], "_process_optim_batch_hook": [306, 337], "batch_subsampl": 306, "clear_cuda": 307, "pre_optim_step": [307, 337], "counter": [308, 337], "log_pbar": [308, 309, 311, 313, 337, 341], "progress": [308, 309, 311, 315, 337, 341, 343, 352], "count_fram": 308, "pre_steps_log": [308, 309, 337], "count_frames_log": 308, "lognam": 309, "r_train": [309, 341], "log_reward": [309, 341], "loss_compon": 310, "appl": 310, "omit": [310, 342, 347, 349], "optimizer_hook": 310, "record_interv": [311, 340, 341], "record_fram": [311, 318, 340, 341], "policy_explor": [311, 327, 340, 341], "log_kei": [311, 341], "suffix": 311, "underestim": 311, "set_exploration_typ": [311, 333, 342, 343, 351], "r_evalu": [311, 340], "flatten_tensordict": [312, 341], "max_dim": 312, "rb_trainer": 312, "batch_process": [312, 313, 314, 337], "post_loss": [312, 337], "999": [313, 341], "jitter": 313, "finfo": 313, "default_dtyp": 313, "get_default_dtyp": 313, "reward_norm": 313, "update_reward_stat": 313, "normalize_reward": 313, "make_train": [314, 333], "_process_batch_hook": [314, 337], "select_kei": [314, 337], "versatil": 315, "optim_steps_per_batch": [315, 337, 341], "epoch": [315, 342, 346], "clip_grad_norm": 315, "clip_norm": 315, "progress_bar": 315, "save_trainer_interv": 315, "log_interv": [315, 341], "save_trainer_fil": [315, 337], "datacollectorbas": [317, 320, 321, 327, 333], "update_weights_interv": [317, 341], "sit": [317, 341], "update_weight": 317, "post_step": [317, 337], "cfg": [318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 331], "dictconfig": [318, 319, 320, 321, 324, 325, 326, 327, 328, 331], "divid": [318, 335, 340, 346, 347], "unknowingli": 318, "annealing_fram": [318, 340], "init_env_step": [318, 319, 340], "proof_environ": [319, 324, 340], "sta": 319, "ot": 319, "actor_model_explor": [320, 321, 340], "make_env_kwarg": [320, 321], "targetnetupdat": [322, 323, 326, 327], "redqloss_deprec": 323, "actor_net_kwarg": 324, "qvalue_net_kwarg": 324, "observation_kei": 324, "parser_env_arg": 324, "parser_model_args_continu": 324, "hydra": 324, "config_stor": 324, "configstor": 324, "config_field": 324, "config_cl": 324, "redqmodelconfig": 324, "envconfig": 324, "make_dataclass": 324, "cls_name": 324, "cs": 324, "config_path": 324, "config_nam": 324, "replayargsconfig": 325, "target_net_updat": [327, 340, 341], "constitu": 327, "tensorboardlogg": [327, 333], "egreedywrapp": [327, 341, 343], "env_proof": 327, "obs_spec": 327, "net_valu": 327, "dir": [327, 337, 341], "gettempdir": 327, "argpars": [328, 331], "namespac": [328, 331], "parser": [328, 331], "transformed_env_constructor": [328, 333], "num_env_per_collector": [329, 330], "video_tag": 331, "norm_obs_onli": 331, "use_env_cr": 331, "custom_env_mak": 331, "custom_env": 331, "return_transformed_env": 331, "action_dim_gsd": 331, "state_dim_gsd": 331, "obs_norm_state_dict": 331, "wheter": 331, "maker": 331, "asyncdatacollector": 333, "distributedsyncdatacollector": 333, "submitit_delayed_launch": 333, "raycollector": 333, "immutabledatasetwrit": 333, "tensordictmaxvaluewrit": 333, "d4rlexperiencereplai": 333, "gendgrlexperiencereplai": 333, "minariexperiencereplai": 333, "openmlexperiencereplai": 333, "openxexperiencereplai": 333, "vd4rlexperiencereplai": 333, "unboundeddiscretetensorspec": [333, 352], "lazystackedtensorspec": 333, "lazystackedcompositespec": 333, "prompttensordicttoken": 333, "rolloutfrommodel": 333, "tokenizeddatasetload": 333, "create_infinite_iter": 333, "consolidate_spec": 333, "check_no_exclusive_kei": 333, "contains_lazy_spec": 333, "check_marl_group": 333, "tensordictrecord": 333, "videorecord": [333, 342], "get_available_librari": 333, "set_exploration_mod": 333, "make_composite_from_td": [333, 347], "terminated_or_trunc": 333, "braxwrapp": 333, "dmcontrolwrapp": 333, "jumanjienv": 333, "jumanjiwrapp": 333, "mogymenv": 333, "mogymwrapp": 333, "multithreadedenvwrapp": 333, "openmlenv": 333, "pettingzooenv": 333, "robohiveenv": 333, "smacv2env": 333, "smacv2wrapp": 333, "vmaswrapp": 333, "qvaluehook": 333, "distributionalqvaluehook": 333, "reset_nois": 333, "cemplann": 333, "mpcplannerbas": 333, "mppiplann": 333, "independentnorm": 333, "truncatednorm": 333, "maskedonehotcategor": 333, "inv_softplu": 333, "vmapmodul": 333, "distributionaldqnloss": [333, 341], "discretesacloss": 333, "iqlloss": 333, "discreteiqlloss": 333, "cqlloss": 333, "discretecqlloss": 333, "dtloss": 333, "onlinedtloss": 333, "a2closs": 333, "reinforceloss": 333, "dreameractorloss": 333, "dreamermodelloss": 333, "dreamervalueloss": 333, "td0estim": [333, 340], "td1estim": [333, 340], "td0_return_estim": 333, "td0_advantage_estim": 333, "td1_return_estim": 333, "vec_td1_return_estim": 333, "td1_advantage_estim": 333, "vec_td1_advantage_estim": 333, "td_lambda_return_estim": 333, "vec_td_lambda_return_estim": 333, "td_lambda_advantage_estim": 333, "vec_td_lambda_advantage_estim": 333, "generalized_advantage_estim": 333, "vec_generalized_advantage_estim": 333, "reward2go": 333, "distance_loss": [333, 340], "hold_out_net": 333, "hold_out_param": [333, 340], "softupd": [333, 340, 341, 343], "hardupd": [333, 340], "batchsubsampl": [333, 337], "clearcudacach": 333, "countframeslog": 333, "logreward": [333, 337, 341], "optimizerhook": [333, 341], "replaybuffertrain": [333, 337, 341], "rewardnorm": 333, "selectkei": [333, 337], "trainerhookbas": [333, 337, 341], "updateweight": [333, 337, 341], "make_collector_offpolici": 333, "make_collector_onpolici": 333, "make_dqn_loss": 333, "make_redq_loss": 333, "make_redq_model": 333, "make_replay_buff": [333, 340], "make_target_updat": 333, "parallel_env_constructor": [333, 340], "sync_async_collector": 333, "sync_sync_collector": 333, "correct_for_frame_skip": 333, "get_stats_random_rollout": 333, "csvlogger": [333, 341], "mlflowlogg": 333, "wandblogg": 333, "get_logg": 333, "generate_exp_nam": 333, "journei": 334, "textbook": 334, "highlight": 334, "ever": [334, 346], "bump": 334, "think": [334, 342, 346, 352], "benefit": [334, 346, 349], "pr": 334, "ground": [335, 340, 347], "recycl": [335, 349], "impos": 335, "violat": 335, "noisier": 335, "Their": [335, 346], "sd": 335, "prob_modul": 335, "pick": [335, 340, 341], "tabl": [335, 341], "hopefulli": [335, 341], "functional_modul": 335, "make_funct": [335, 351], "mathbb": [335, 341], "rightarrow": [335, 341], "soften": 335, "backbon": [335, 343, 345, 351], "make_actor": 335, "make_valu": 335, "shared_param": 335, "make_common": 335, "reusabl": [336, 340, 349], "swappabl": [336, 340], "characterist": [336, 340, 347], "trainabl": [336, 340, 348], "whatev": [336, 340], "smth": [336, 340], "metric": [336, 340], "nutshel": [336, 340], "barto": [336, 346], "chapter": 336, "significantli": [336, 340, 341, 346], "next_stat": 336, "value_net_loss": 336, "pow": [336, 340], "therebi": 336, "room": 336, "signifi": [336, 346], "underperform": 336, "thin": 336, "intric": 336, "believ": 337, "scheme": [337, 352], "substenti": 337, "_pre_steps_log_hook": 337, "_pre_optim_hook": 337, "sub_batch": 337, "_post_loss_hook": 337, "_post_optim_hook": 337, "post_optim": [337, 341], "_post_optim_log": 337, "post_optim_log": 337, "_post_steps_hook": 337, "_post_steps_log_hook": 337, "post_steps_log": 337, "comment": [337, 341, 351], "reserv": 337, "logginghook": 337, "logging_hook": 337, "save_dict": 337, "some_valu": 337, "torchsnapshot": 337, "ckpt_backend": 337, "pt": [337, 348], "filepath": 337, "save_train": 337, "load_from_fil": 337, "561": [339, 347, 350], "galleri": [339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 351, 352], "mem": [339, 350], "mb": [339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352], "torchrl_demo": [339, 350, 351], "59": [339, 340, 341, 347, 348, 350, 351], "610": [339, 347, 350, 351], "torchrl_env": [339, 350, 352], "409": [339, 347, 350, 352], "dqn_with_rnn": [339, 343, 350], "251": [339, 343, 347, 350], "1910": [339, 343, 350], "multiagent_ppo": [339, 346, 350], "630": [339, 346, 350], "coding_dqn": [339, 341, 350], "47": [339, 340, 341, 347, 350], "948": [339, 341, 350], "842": [339, 350], "697": [339, 347, 350], "rb_tutori": [339, 349, 350], "157": [339, 343, 347, 349, 350], "464": [339, 347, 349, 350], "coding_ddpg": [339, 340, 350], "57": [339, 340, 341, 347, 348, 349, 350], "522": [339, 340, 347, 350], "coding_ppo": [339, 342, 350], "044": [339, 342, 350], "pretrained_model": [339, 348, 350], "54": [339, 340, 341, 343, 346, 347, 348, 349, 350], "039": [339, 348, 350], "3367": [339, 348, 350], "multi_task": [339, 345, 350], "49": [339, 341, 343, 345, 346, 347, 348, 350], "254": [339, 345, 347, 350], "author": [340, 341, 342, 343, 346, 347, 349], "vincent": [340, 341, 342, 343, 347, 349], "moen": [340, 341, 342, 343, 347, 349], "assembl": 340, "focus": 340, "straightforward": [340, 341, 349], "overview": [340, 342, 346, 351], "transpar": [340, 343], "understood": 340, "sota": [340, 341, 351], "illustr": [340, 341, 349], "loss_dict": 340, "oblivi": [340, 342, 349], "elementari": 340, "didact": 340, "dilut": 340, "pessimist": [340, 341, 342], "target_actor_network_param": 340, "actor_in_kei": 340, "actor_crit": 340, "noth": [340, 342], "compromis": 340, "hp": 340, "hasattr": 340, "_value_estim": 340, "elif": [340, 341], "notimplementederror": 340, "unknown": 340, "_loss_actor": 340, "td_copi": 340, "actor_network_param": 340, "value_network_param": 340, "_loss_valu": 340, "pred_val": 340, "target_value_network_param": 340, "smooth": [340, 341], "loss_funt": 340, "glue": 340, "_forward": 340, "ndimens": 340, "remaind": 340, "focu": [340, 341, 342], "env_librari": 340, "env_task": 340, "env_arg": 340, "friendli": 340, "torchr": 340, "rescal": 340, "presum": 340, "make_transformed_env": 340, "reward_sc": 340, "double_to_float_list": 340, "double_to_float_inv_list": 340, "marker": 340, "env_per_collector": 340, "transform_state_dict": 340, "make_t_env": 340, "adjust": [340, 346, 347], "seem": [340, 343], "cheat": 340, "10m": 340, "cautiou": 340, "magnitud": 340, "thousand": [340, 343], "get_env_stat": 340, "proof_env": 340, "5000": [340, 341, 342], "maxim": [340, 347], "recal": [340, 342], "ddpgmlpactor": 340, "ddpgmlpqnet": 340, "materi": 340, "ornsteinuhlenbeckprocesswrapp": 340, "make_ddpg_actor": 340, "q_net": 340, "moduless": 340, "sugges": 340, "tight": 340, "10_000": [340, 342, 349], "traj_len": [340, 343], "make_record": 340, "recorder_obj": 340, "flavor": 340, "circular": 340, "buffer_s": [340, 341], "random_crop_len": 340, "prb": 340, "buffer_scratch_dir": 340, "temporari": 340, "dirrectori": 340, "trajecotri": 340, "25": [340, 341, 343, 346, 347, 348], "sampel": 340, "dataflow": 340, "ceil_div": 340, "utd": [340, 343], "update_to_data": 340, "realiz": 340, "_must_": 340, "001": [340, 347], "outdat": 340, "trick": [340, 341], "despit": 340, "adam": [340, 341, 342, 343, 346, 347], "optimizer_actor": 340, "lr": [340, 341, 342, 343, 346, 347], "weight_decai": [340, 341], "optimizer_valu": 340, "total_collection_step": 340, "pretti": [340, 349], "rewards_ev": 340, "collected_fram": 340, "pbar": [340, 342, 343, 346, 347], "r0": 340, "numel": [340, 342, 343, 348, 349], "current_fram": 340, "sampled_tensordict": 340, "gn1": 340, "clip_grad_norm_": [340, 342, 346, 347], "gn2": 340, "gn": [340, 347], "td_record": 340, "rn": 340, "set_descript": [340, 342, 343, 346, 347], "2f": 340, "800": [340, 341], "2882": 340, "63it": [340, 341, 347], "1600": [340, 341], "1042": 340, "32it": [340, 341], "3200": [340, 341], "2132": 340, "26it": [340, 341], "48": [340, 341, 343, 346, 347, 348], "4800": [340, 341, 347], "3054": 340, "10it": [340, 341], "45": [340, 341, 347], "82": [340, 341, 342, 347, 348], "74": [340, 341, 347, 348], "58": [340, 341, 347, 348], "299": [340, 347], "56": [340, 341, 343, 347, 348], "5600": 340, "6400": [340, 351], "1382": 340, "21it": [340, 341, 347], "73": [340, 341, 347, 349], "144": [340, 347], "77": [340, 341, 347, 349], "321": [340, 347], "72": [340, 341, 347, 348], "7200": 340, "855": [340, 347], "18it": [340, 341, 347], "61": [340, 341, 347, 348], "89": [340, 341, 347, 348, 349], "71": [340, 341, 347], "206": [340, 347], "8000": [340, 342], "655": 340, "13it": [340, 341], "83": [340, 341, 347, 348], "78": [340, 341, 347, 348], "8800": 340, "556": [340, 347], "00it": [340, 341], "93": [340, 341, 346, 347, 348, 349], "133": [340, 347], "96": [340, 341, 347, 348, 349], "9600": 340, "419": [340, 347], "162": [340, 347], "76": [340, 341, 347, 348, 349], "62": [340, 341, 347, 348], "10400it": 340, "406": [340, 347], "48it": [340, 341], "165": [340, 347], "plot": [340, 342, 343, 346, 347], "mention": [340, 343, 349, 352], "matplotlib": [340, 342, 343, 346, 347, 349, 352], "pyplot": [340, 342, 343, 346, 347, 349, 352], "plt": [340, 342, 343, 346, 347, 349, 352], "zip": [340, 344], "legend": 340, "xlabel": [340, 343, 346, 347], "ylabel": [340, 346], "tight_layout": 340, "concret": [340, 342], "takeawai": [340, 341], "jupyt": [340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 351, 352], "ipynb": [340, 341, 342, 343, 345, 346, 347, 348, 349, 351, 352], "sphinx": [340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 351, 352], "customis": [341, 346], "road": 341, "aspect": 341, "highest": 341, "prerequisit": [341, 343], "familiar": [341, 346, 352], "lookup": 341, "amort": [341, 342], "conjunct": 341, "cart": 341, "pole": 341, "un": 341, "actuat": 341, "frictionless": 341, "duelingcnndqnet": 341, "is_notebook": 341, "shell": 341, "get_ipython": 341, "__class__": 341, "zmqinteractiveshel": 341, "qtconsol": 341, "terminalinteractiveshel": 341, "ipython": [341, 346, 347], "nameerror": 341, "umbrella": 341, "misplac": 341, "misus": 341, "orchestr": 341, "everyth": [341, 343], "five": [341, 342], "64x64": 341, "motion": [341, 347], "obs_norm_sd": 341, "simpler": 341, "get_norm_stat": 341, "test_env": 341, "make_model": 341, "dummy_env": 341, "output_s": [341, 343], "init_bia": 341, "actor_explor": 341, "eps_greedy_v": 341, "eps_greedy_val_env": 341, "get_replay_buff": 341, "n_optim": 341, "themselv": 341, "simplic": [341, 342, 348, 349], "get_collector": 341, "data_collector": 341, "bunch": 341, "power": 341, "ubiquit": 341, "get_loss_modul": 341, "target_updat": 341, "995": [341, 347], "sensit": 341, "variat": 341, "2e": [341, 347], "wd": 341, "upd": 341, "harder": [341, 351], "5_000": 341, "500000": 341, "100000": 341, "005": 341, "mandatori": [341, 342, 346, 347], "fairer": 341, "budget": [341, 342], "dqn_exp_": 341, "uuid1": [341, 352], "9895": 341, "0737": 341, "registr": 341, "cumbersom": 341, "buffer_hook": 341, "weight_updat": 341, "aliv": 341, "total_reward": 341, "07": [341, 347], "57it": 341, "4045": 341, "9346": [341, 347], "4497": 341, "51": [341, 346, 347, 349], "80it": [341, 347], "3802": 341, "4254": [341, 347], "79it": [341, 347], "3772": 341, "192": [341, 347], "09": [341, 342, 347], "29it": 341, "224": [341, 347], "43": [341, 347], "22it": [341, 347], "4676": 341, "52": [341, 346, 347, 348, 349], "3893": 341, "288": [341, 347], "4948": 341, "14it": 341, "4797": 341, "352": [341, 347], "95it": [341, 347], "384": [341, 347], "66": [341, 347, 348], "67it": [341, 347], "416": [341, 347], "68": [341, 347, 348], "88it": [341, 342, 347], "448": [341, 347], "70": [341, 342, 346, 347, 348], "480": [341, 347, 348], "68it": [341, 347], "99it": [341, 347], "544": [341, 347], "576": [341, 347], "92it": 341, "608": [341, 347], "37it": [341, 347], "4164": [341, 347], "640": 341, "72it": [341, 347], "4375": [341, 347], "672": 341, "09it": 341, "704": 341, "736": 341, "768": 341, "87it": [341, 347], "4526": 341, "35it": [341, 342], "832": 341, "864": 341, "55": [341, 342, 347, 348], "53it": 341, "896": 341, "23it": [341, 347], "928": 341, "960": 341, "992": [341, 347], "53": [341, 346, 347, 348], "27it": [341, 347], "1056": 341, "89it": [341, 347], "1088": 341, "1120": 341, "55it": 341, "1152": 341, "75it": [341, 347], "1184": 341, "4524": 341, "1216": 341, "1248": 341, "78it": [341, 347], "1280": 341, "70it": [341, 347], "30it": 341, "1344": 341, "1376": 341, "98it": 341, "1408": 341, "19it": 341, "1440": 341, "83it": [341, 347], "1472": 341, "20it": [341, 347], "4074": [341, 347], "1504": 341, "54it": [341, 347], "4586": 341, "1536": 341, "36it": 341, "1568": 341, "45it": 341, "49it": 341, "1632": 341, "15it": 341, "1696": 341, "81it": [341, 347], "1728": 341, "1760": 341, "11it": [341, 342], "36": [341, 342, 343, 347], "1792": 341, "01it": 341, "1824": 341, "62it": [341, 347], "1856": 341, "24it": 341, "1888": 341, "1920": 341, "41": [341, 342, 347], "61it": [341, 347], "1952": 341, "1984": 341, "12it": 341, "2016": 341, "65it": 341, "2048": [341, 348], "05it": [341, 342], "2080": 341, "42it": 341, "2112": [341, 347], "2144": 341, "2176": 341, "97it": 341, "2208": 341, "31it": [341, 342, 343], "2240": 341, "40it": 341, "2272": 341, "2304": 341, "60it": [341, 347], "2336": 341, "2368": 341, "2400": 341, "59it": [341, 343], "2432": 341, "2464": 341, "34it": 341, "2496": [341, 342], "2528": [341, 347], "2560": 341, "47it": 341, "2624": 341, "39it": [341, 347], "2656": [341, 347], "2688": 341, "2720": [341, 347], "2752": 341, "82it": [341, 342, 347], "2784": 341, "07it": 341, "2816": 341, "91it": 341, "2848": 341, "2880": 341, "46it": 341, "2912": 341, "2944": [341, 347], "60": [341, 342, 346, 347, 348, 351], "2976": [341, 347], "41it": [341, 347], "3040": 341, "69it": [341, 347], "3072": 341, "3104": 341, "63": [341, 346, 347], "3136": 341, "90it": 341, "3168": 341, "43it": 341, "65": [341, 347, 348], "3232": [341, 347], "2500": 341, "3264": 341, "85it": [341, 347], "3296": 341, "33it": 341, "67": [341, 345, 347], "3328": 341, "51it": [341, 342, 347], "3360": 341, "3392": 341, "3424": 341, "69": [341, 347, 348], "3456": [341, 347], "3488": 341, "50it": 341, "3520": 341, "71it": [341, 347], "3552": 341, "3584": 341, "3616": 341, "96it": 341, "3648": 341, "3680": 341, "44it": 341, "3712": 341, "3744": 341, "3776": 341, "3808": 341, "3840": 341, "3872": 341, "3904": 341, "79": [341, 347, 348], "3936": 341, "3968": 341, "4000": [341, 342], "4032": 341, "4064": 341, "4096": 341, "4128": [341, 347], "4160": 341, "4192": 341, "4224": 341, "85": [341, 347, 348], "4256": [341, 347], "4288": [341, 347], "4320": 341, "04it": 341, "4352": 341, "4384": 341, "4416": 341, "4448": 341, "25it": 341, "90": [341, 342, 346, 347, 348], "4480": 341, "52it": [341, 347], "4512": 341, "94it": 341, "91": [341, 347, 348, 349], "4544": 341, "92": [341, 347], "4576": 341, "4608": 341, "4640": 341, "73it": [341, 347], "4672": [341, 347], "4704": 341, "4736": 341, "4768": 341, "84it": [341, 347], "97": [341, 347], "4832": 341, "4864": 341, "4896": 341, "4928": 341, "4960": 341, "4992": 341, "5024it": 341, "print_csv_files_in_fold": 341, "folder_path": 341, "csv_file": 341, "output_str": 341, "dirpath": 341, "endswith": 341, "strip": 341, "tmp": [341, 349], "tmpud1wv75g": 341, "dqn_exp_461ebf02": 341, "b94e": 341, "11ee": [341, 352], "97b9": [341, 352], "0242ac110002": [341, 352], "4948333501815796": 341, "4796708822250366": 341, "4676021933555603": 341, "23750342428684235": 341, "27068594098091125": 341, "3787801265716553": 341, "2137961983680725": 341, "16817891597747803": 341, "2434740513563156": 341, "29228973388671875": 341, "31548598408699036": 341, "2934505045413971": 341, "grad_norm_0": 341, "832277774810791": 341, "2828564643859863": 341, "7454147338867188": 341, "108038902282715": 341, "193542003631592": 341, "2942051887512207": 341, "096604824066162": 341, "4866714477539062": 341, "571478843688965": 341, "10000000894069672": 341, "qvaluenetwork": 341, "worst": 341, "accuraci": 341, "fanci": 341, "843": [341, 347], "talk": 342, "repetit": 342, "six": 342, "sophist": [342, 346], "invent": 342, "theta_k": 342, "pi_": 342, "exceed": 342, "discourag": [342, 347], "indispens": 342, "analyz": 342, "lingua": 342, "franca": 342, "defaultdict": [342, 347], "has_cuda": [342, 346, 352], "3e": [342, 343, 346], "max_grad_norm": [342, 346], "ourselv": [342, 352], "benefici": 342, "errat": 342, "hamper": [342, 349], "reactiv": 342, "xy": 342, "sub_batch_s": 342, "num_epoch": [342, 346], "entropy_ep": [342, 346], "generalist": 342, "interchang": [342, 348, 349], "panel": 342, "charact": 342, "inverteddoublependulum": 342, "transmit": 342, "stai": 342, "supplementari": [342, 352], "told": 342, "confid": [342, 346], "ran": 342, "f_": 342, "mu_": 342, "difficulti": [342, 352], "brought": [342, 343], "d_ob": 342, "d_action": 342, "policy_modul": [342, 346], "That": 342, "said": 342, "briefli": [342, 346], "refil": [342, 346], "conveni": [342, 346, 347], "easiest": [342, 346], "mathemat": [342, 346], "tradeoff": [342, 346], "advantage_modul": 342, "lr_schedul": [342, 347], "cosineannealinglr": [342, 347], "eval_str": 342, "tensordict_data": [342, 346], "data_view": [342, 346], "subdata": [342, 346], "cum_reward_str": 342, "4f": [342, 343, 347], "stepcount_str": 342, "param_group": 342, "lr_str": 342, "eval_rollout": 342, "nice": 342, "333": [342, 347], "8823": 342, "0885": [342, 347], "0003": [342, 347], "332": [342, 347], "0950": [342, 347], "3000": 342, "334": [342, 347], "1444": 342, "335": [342, 347], "77it": [342, 343, 347], "1933": 342, "0002": [342, 347], "336": [342, 347], "58it": 342, "2034": 342, "6000": 342, "337": [342, 347], "1993": 342, "7000": 342, "331": [342, 347], "2349": 342, "2399": 342, "9000": 342, "2538": [342, 347], "cap": [342, 349], "figsiz": [342, 347], "subplot": [342, 347, 352], "titl": [342, 343, 346, 347], "bit": [342, 343, 346, 349], "lstmmodul": 343, "84x84": 343, "accessori": 343, "stamp": 343, "assist": 343, "emb": 343, "n_cell": 343, "customiz": 343, "almost": 343, "wouldn": 343, "make_tensordict_prim": 343, "qval": 343, "stoch_polici": 343, "opportun": 343, "coupl": [343, 347, 349], "uniniti": 343, "_squeezedtensordict": 343, "again": [343, 346, 348, 349, 352], "redund": 343, "strongli": 343, "million": 343, "sake": [343, 348, 349], "20_000": [343, 347], "longest": 343, "npai": 343, "action_spread": 343, "1000000": 343, "64it": [343, 347], "0008": [343, 347], "120": [343, 347], "0007": [343, 347], "150": [343, 347], "0010": [343, 347], "174": [343, 347], "0013": [343, 347], "tutorials_python": 344, "tutorials_jupyt": 344, "env1_obs_kei": 345, "observation_stand": 345, "env2_obs_kei": 345, "observation_walk": 345, "tdreset1": 345, "tdreset2": 345, "tdreset": 345, "policy_common": 345, "policy_stand": 345, "policy_walk": 345, "But": 345, "exclusive_field": [345, 351], "stack_dim": [345, 351], "env1_mak": 345, "env2_mak": 345, "_single_task": 345, "td_rollout": 345, "matteo": 346, "bettini": 346, "benchmarl": 346, "maddpg": 346, "navig": 346, "lidar": 346, "sensor": 346, "collis": 346, "tie": 346, "mappo": 346, "ippo": 346, "phase": [346, 349], "mathbf": 346, "pi": [346, 347], "fed": [346, 349], "approxim": [346, 352], "literatur": 346, "overcom": 346, "stationari": 346, "concurr": 346, "analys": 346, "gui": 346, "visualis": 346, "multiagentmlp": 346, "divic": 346, "vmas_devic": 346, "6_000": 346, "team": [346, 351], "n_iter": 346, "minibatch_s": 346, "generalis": 346, "furthermor": 346, "simd": 346, "parallelis": 346, "warp": 346, "todai": 346, "circl": 346, "surround": 346, "dot": [346, 347], "collid": 346, "drag": 346, "elast": 346, "acceler": 346, "penalis": 346, "num_vmas_env": 346, "scenario_nam": 346, "four": [346, 347], "environmnet": 346, "final_rew": 346, "agent_collis": 346, "stress": 346, "paramount": 346, "n_rollout_step": 346, "evolut": 346, "yourself": 346, "utilis": 346, "n_actions_per_ag": 346, "n_obs_per_ag": 346, "share_parameters_polici": 346, "policy_net": 346, "denot": 346, "carefulli": [346, 352], "grant": 346, "converg": 346, "cooper": 346, "share_parameters_crit": 346, "critic_net": 346, "fantast": 346, "minibatch": 346, "desc": 346, "episode_reward_mean": 346, "episode_reward_mean_list": 346, "get_item_shap": 346, "critic_param": 346, "target_critic_param": 346, "refresh": 346, "3641679584980011": 346, "4940122067928314": 346, "0600677728652954": 346, "4344534873962402": 346, "1100871562957764": 346, "304917335510254": 346, "6943857669830322": 346, "871443748474121": 346, "8500826358795166": 346, "759843587875366": 346, "xvfb": 346, "pyvirtualdisplai": 346, "1400": [346, 347], "900": 346, "pil": 346, "rendering_callback": 346, "fromarrai": 346, "rgb_arrai": [346, 347], "gif": 346, "save_al": 346, "append_imag": 346, "profici": 346, "master": 346, "freeli": 347, "codebas": 347, "touch": 347, "undertaken": 347, "broader": 347, "wider": 347, "algebra": 347, "acquaint": 347, "avenu": 347, "_apply_to_composit": 347, "default_x": 347, "default_i": 347, "torqu": 347, "upward": 347, "angular": 347, "sin": 347, "rad": 347, "sec": 347, "gravit": 347, "angl": 347, "deleg": 347, "new_th": 347, "new_thdot": 347, "thdot": 347, "g_forc": 347, "max_torqu": 347, "angle_norm": 347, "max_spe": 347, "albeit": 347, "gen_param": 347, "high_th": 347, "high_thdot": 347, "low_th": 347, "low_thdot": 347, "rng": 347, "lazili": 347, "organ": [347, 349], "trivial": 347, "shortcut": [347, 352], "irrelev": 347, "_make_spec": 347, "td_param": 347, "pseudo": 347, "render_mod": 347, "render_fp": 347, "random_": 347, "_make_step": 347, "staticmethod": 347, "complic": [347, 349, 352], "showcas": 347, "skeleton": 347, "_apply_transform": [347, 352], "_inv_apply_transform": [347, 352], "subset": [347, 348], "unitari": 347, "sine": 347, "cosin": 347, "sintransform": 347, "tensordict_reset": 347, "costransform": 347, "t_sin": 347, "t_co": 347, "cat_transform": 347, "mdp": 347, "simple_rollout": 347, "unexplor": 347, "recreat": 347, "init_td": 347, "traj_return": 347, "last_reward": 347, "is_ipython": 347, "inlin": 347, "get_backend": 347, "ion": 347, "gcf": 347, "clear_output": 347, "625": 347, "0748": 347, "519": 347, "0499": 347, "4472": 347, "073": 347, "0685": 347, "0408": 347, "552": 347, "5154": 347, "9086": 347, "9385": 347, "155": 347, "2568": 347, "4981": 347, "223": 347, "8929": 347, "4491": 347, "581": 347, "3233": 347, "0664": 347, "596": 347, "1021": 347, "5263": 347, "9579": 347, "86it": 347, "5807": 347, "8075": 347, "212": 347, "2009": 347, "5525": 347, "914": 347, "2894": 347, "0115": 347, "0977": 347, "1845": 347, "1830": 347, "4858": 347, "233": 347, "2863": 347, "0297": 347, "4617": 347, "5997": 347, "904": 347, "1647": 347, "0777": 347, "901": 347, "4709": 347, "6813": 347, "8317": 347, "3221": 347, "5554": 347, "276": 347, "3353": 347, "701": 347, "8570": 347, "6656": 347, "463": 347, "7779": 347, "6911": 347, "875": 347, "0796": 347, "7082": 347, "308": 347, "0421": 347, "1496": 347, "5037": 347, "1755": 347, "5029": 347, "9454": 347, "665": 347, "9330": 347, "2118": 347, "444": 347, "0995": 347, "6294": 347, "3146": 347, "2909": 347, "461": 347, "9720": 347, "1298": 347, "9923": 347, "0345": 347, "3438": 347, "3688": 347, "424": 347, "6953": 347, "5233": 347, "411": 347, "8011": 347, "5329": 347, "2677": 347, "6969": 347, "7010": 347, "376": 347, "9352": 347, "7707": 347, "6178": 347, "5646": 347, "348": 347, "7304": 347, "9407": 347, "942": 347, "3882": 347, "7604": 347, "3507": 347, "8928": 347, "258": 347, "6978": 347, "4641": 347, "549": 347, "6047": 347, "5005": 347, "4136": 347, "2993": 347, "3222": 347, "4046": 347, "7314": 347, "275": 347, "6331": 347, "9318": 347, "961": 347, "8331": 347, "1604": 347, "4099": 347, "4761": 347, "125": 347, "4262": 347, "6363": 347, "382": 347, "3593": 347, "7377": 347, "2847": 347, "3443": 347, "867": 347, "3592": 347, "4760": 347, "441": 347, "9950": 347, "8021": 347, "3528": 347, "1214": 347, "708": 347, "4023": 347, "3583": 347, "041": 347, "3801": 347, "0310": 347, "4244": 347, "2039": 347, "4850": 347, "8748": 347, "706": 347, "4897": 347, "9210": 347, "8964": 347, "0832": 347, "3934": 347, "456": 347, "8971": 347, "2933": 347, "3377": 347, "6996": 347, "2274": 347, "8916": 347, "098": 347, "2660": 347, "9110": 347, "4503": 347, "6956": 347, "9172": 347, "4026": 347, "946": 347, "9229": 347, "5205": 347, "294": 347, "8872": 347, "6637": 347, "019": 347, "9281": 347, "2082": 347, "724": 347, "8561": 347, "6574": 347, "357": 347, "4138": 347, "5230": 347, "385": 347, "4065": 347, "5642": 347, "921": 347, "9786": 347, "4129": 347, "5831": 347, "266": 347, "7723": 347, "4152": 347, "0898": 347, "389": 347, "5155": 347, "5376": 347, "5616": 347, "4094": 347, "283": 347, "5333": 347, "4803": 347, "895": 347, "6566": 347, "2588": 347, "662": 347, "4732": 347, "7503": 347, "068": 347, "0714": 347, "3370": 347, "059": 347, "8612": 347, "1915": 347, "3855": 347, "0349": 347, "9644": 347, "4538": 347, "445": 347, "0392": 347, "4080": 347, "1648": 347, "9599": 347, "143": 347, "4284": 347, "5946": 347, "2590": 347, "9181": 347, "4621": 347, "9075": 347, "674": 347, "1772": 347, "9444": 347, "351": 347, "9391": 347, "5595": 347, "8673": 347, "6240": 347, "5919": 347, "1071": 347, "9127": 347, "9799": 347, "3131": 347, "9612": 347, "9705": 347, "8741": 347, "2230": 347, "0972": 347, "0337": 347, "0350": 347, "0654": 347, "102": [347, 349], "2441": 347, "4596": 347, "362": 347, "103": 347, "4362": 347, "171": 347, "104": 347, "4041": 347, "6907": 347, "105": 347, "4664": 347, "2760": 347, "0299": 347, "9712": 347, "349": 347, "107": 347, "3332": 347, "4479": 347, "772": 347, "108": 347, "4357": 347, "9591": 347, "543": 347, "109": 347, "6216": 347, "1353": 347, "692": 347, "110": 347, "6261": 347, "7086": 347, "496": 347, "111": 347, "7758": 347, "9818": 347, "112": [347, 349], "7772": 347, "5055": 347, "113": 347, "5840": 347, "3180": 347, "2083": 347, "115": 347, "5275": 347, "6873": 347, "116": 347, "4107": 347, "1624": 347, "117": 347, "6372": 347, "2571": 347, "118": 347, "4039": 347, "4428": 347, "119": [347, 349], "4728": 347, "5628": 347, "6767": 347, "2466": 347, "121": [347, 352], "5873": 347, "5072": 347, "6548": 347, "3766": 347, "123": 347, "5134": 347, "1955": 347, "124": 347, "2481": 347, "0591": 347, "4500": 347, "3368": 347, "126": 347, "9708": 347, "7059": 347, "127": [347, 349], "3031": 347, "2534": 347, "3327": 347, "6193": 347, "129": [347, 349], "4831": 347, "1172": 347, "2593": 347, "4219": 347, "962": 347, "8380": 347, "899": 347, "132": 347, "2721": 347, "9048": 347, "166": 347, "2419": 347, "5248": 347, "2139": 347, "4278": 347, "135": 347, "0690": 347, "5140": 347, "136": 347, "1140": 347, "7402": 347, "137": 347, "5356": 347, "1636": 347, "138": [347, 349], "0671": 347, "8798": 347, "139": [347, 349], "8918": 347, "3298": 347, "307": 347, "140": 347, "1779": 347, "141": 347, "1771": 347, "3624": 347, "936": 347, "142": 347, "1683": 347, "4810": 347, "9373": 347, "4435": 347, "4396": 347, "8092": 347, "145": 347, "2572": 347, "146": 347, "4212": 347, "0260": 347, "147": 347, "0939": 347, "6478": 347, "605": 347, "148": 347, "6606": 347, "7289": 347, "149": 347, "9300": 347, "7193": 347, "563": 347, "1166": 347, "8514": 347, "151": [347, 349], "9108": 347, "0672": 347, "292": 347, "152": 347, "8591": 347, "3768": 347, "153": 347, "9976": 347, "154": 347, "0576": 347, "0067": 347, "935": 347, "4199": 347, "1722": 347, "156": 347, "8310": 347, "3466": 347, "8631": 347, "2492": 347, "158": 347, "8763": 347, "1277": 347, "159": 347, "5562": 347, "7446": 347, "1082": 347, "9830": 347, "161": 347, "0946": 347, "5229": 347, "4574": 347, "6900": 347, "163": [347, 348, 349], "2229": 347, "0318": 347, "482": 347, "164": 347, "0543": 347, "0817": 347, "761": 347, "2809": 347, "5118": 347, "366": 347, "1142": 347, "5635": 347, "167": 347, "1949": 347, "2327": 347, "982": 347, "168": [347, 349], "0967": 347, "0387": 347, "457": 347, "169": 347, "0782": 347, "2150": 347, "170": 347, "5222": 347, "3725": 347, "9288": 347, "9837": 347, "1416": 347, "1099": 347, "173": 347, "8620": 347, "8475": 347, "1807": 347, "175": 347, "93it": 347, "1148": 347, "0645": 347, "2751": 347, "8313": 347, "177": 347, "38it": 347, "9286": 347, "9770": 347, "178": 347, "5735": 347, "2837": 347, "179": 347, "2926": 347, "9489": 347, "180": 347, "1507": 347, "181": 347, "8724": 347, "3567": 347, "182": 347, "3574": 347, "6140": 347, "183": 347, "7895": 347, "2518": 347, "184": [347, 349], "6146": 347, "185": 347, "8776": 347, "7358": 347, "186": 347, "3722": 347, "8428": 347, "187": 347, "7955": 347, "188": 347, "0092": 347, "7106": 347, "829": 347, "189": 347, "2264": 347, "6919": 347, "190": 347, "1438": 347, "1362": 347, "191": 347, "0618": 347, "8217": 347, "9420": 347, "6765": 347, "193": 347, "7745": 347, "0709": 347, "194": 347, "9478": 347, "6867": 347, "195": 347, "6507": 347, "6225": 347, "196": 347, "2244": 347, "2195": 347, "197": 347, "5385": 347, "9263": 347, "198": 347, "1878": 347, "2374": 347, "199": 347, "8054": 347, "3504": 347, "557": 347, "0766": 347, "201": 347, "2011": 347, "8393": 347, "202": 347, "0803": 347, "7815": 347, "203": 347, "8363": 347, "2460": 347, "204": 347, "8643": 347, "2191": 347, "593": 347, "205": 347, "0773": 347, "1343": 347, "8657": 347, "207": 347, "9304": 347, "7584": 347, "208": 347, "8752": 347, "2307": 347, "209": 347, "5250": 347, "4869": 347, "7837": 347, "5762": 347, "211": 347, "6661": 347, "8600": 347, "2502": 347, "1752": 347, "3075": 347, "8871": 347, "214": 347, "9406": 347, "8090": 347, "215": 347, "6291": 347, "8923": 347, "876": 347, "216": 347, "9504": 347, "21e": 347, "217": 347, "7431": 347, "7880": 347, "218": 347, "4463": 347, "5432": 347, "219": 347, "3793": 347, "3313": 347, "220": 347, "8843": 347, "0369": [347, 352], "065": 347, "221": 347, "4828": 347, "8391": 347, "222": 347, "6265": 347, "2913": 347, "947": 347, "5541": 347, "1252": 347, "7342": 347, "2396": 347, "225": 347, "5936": 347, "1924": 347, "226": 347, "9975": 347, "2045": 347, "227": 347, "8367": 347, "9540": 347, "228": 347, "7259": 347, "6743": 347, "229": 347, "4827": 347, "7528": 347, "230": 347, "7361": 347, "8756": 347, "231": 347, "7646": 347, "1116": 347, "232": 347, "5426": 347, "8385": 347, "5662": 347, "8585": 347, "234": 347, "8234": 347, "7930": 347, "235": 347, "2648": 347, "9309": 347, "236": 347, "6817": 347, "237": 347, "0943": 347, "1533": 347, "238": 347, "3045": 347, "0483": 347, "239": 347, "6415": 347, "0201": 347, "241": 347, "4437": 347, "4365": 347, "242": 347, "0358": 347, "4943": 347, "243": 347, "1272": 347, "5003": 347, "1180": 347, "2637": 347, "245": 347, "7197": 347, "0873": 347, "246": 347, "2917": 347, "247": 347, "0160": 347, "0738": 347, "248": 347, "3689": 347, "0120": 347, "249": 347, "5570": 347, "0475": 347, "250": 347, "4423": 347, "2220": 347, "6803": 347, "252": 347, "1465": 347, "7214": 347, "253": 347, "8801": 347, "7034": 347, "9136": 347, "4076": 347, "7589": 347, "5013": 347, "8150": 347, "2241": 347, "257": 347, "0753": 347, "8081": 347, "1951": 347, "8314": 347, "259": 347, "0038": [347, 352], "260": 347, "0889": 347, "4616": 347, "261": 347, "0655": 347, "262": 347, "8333": 347, "9476": 347, "263": 347, "7554": 347, "3798": 347, "264": 347, "3717": 347, "3947": 347, "529": 347, "265": 347, "3060": 347, "6495": 347, "7467": 347, "8889": 347, "267": 347, "8457": 347, "591": 347, "7137": 347, "0536": 347, "771": 347, "269": 347, "1651": 347, "388": 347, "270": 347, "8246": 347, "5709": 347, "281": 347, "271": 347, "7502": 347, "0521": 347, "032": 347, "272": 347, "5475": 347, "7253": 347, "273": 347, "2856": 347, "7130": 347, "274": 347, "2778": 347, "4122": 347, "8368": 347, "1841": 347, "9622": 347, "1603": 347, "003e": 347, "277": 347, "0247": 347, "346": 347, "278": 347, "2238": 347, "6418": 347, "279": 347, "0626": 347, "280": 347, "0149": 347, "7380": 347, "2167": 347, "8911": 347, "282": 347, "8725": 347, "1983": 347, "8142": 347, "3709": 347, "284": 347, "4989": 347, "285": 347, "6464": 347, "6210": 347, "286": 347, "9726": 347, "0820": 347, "287": 347, "6975": 347, "9091": 347, "4926": 347, "4791": 347, "289": 347, "0905": 347, "3500": 347, "290": 347, "2287": 347, "291": 347, "9918": 347, "5543": 347, "9245": 347, "6444": 347, "631": 347, "293": 347, "0448": 347, "4769": 347, "8566": 347, "7208": 347, "295": 347, "0966": 347, "296": 347, "5303": 347, "1537": 347, "023": 347, "297": 347, "2682": 347, "564": 347, "298": 347, "4318": 347, "5063": 347, "7475": 347, "4190": 347, "8186": 347, "5077": 347, "301": 347, "1883": 347, "5291": 347, "472": 347, "302": 347, "3998": 347, "303": 347, "3622": 347, "0930": 347, "626": 347, "304": 347, "9500": 347, "5664": 347, "305": 347, "5697": 347, "3024": 347, "306": 347, "76it": 347, "3117": 347, "0052": 347, "006": 347, "0981": 347, "9312": 347, "3873": 347, "309": 347, "0411": 347, "2650": 347, "1656": 347, "0228": 347, "004": 347, "311": 347, "1196": 347, "2478": 347, "312": 347, "7353": 347, "0812": 347, "313": 347, "3022": 347, "758": 347, "314": 347, "1406": 347, "4626": 347, "315": 347, "2156": 347, "851": 347, "316": 347, "1953": 347, "3774": 347, "317": 347, "6385": 347, "9917": 347, "318": 347, "2764": 347, "905": 347, "319": 347, "6391": 347, "9317": 347, "9748": 347, "2679": 347, "8495": 347, "5125": 347, "8177": 347, "6602": 347, "323": 347, "0704": 347, "5776": 347, "324": 347, "9833": [347, 351], "1339": 347, "402": 347, "325": 347, "1238": [347, 352], "326": 347, "9299": 347, "0227": 347, "327": 347, "7727": 347, "1607": 347, "328": 347, "3958": 347, "3223": 347, "763": 347, "329": 347, "4742": 347, "1797": 347, "330": 347, "0144": 347, "0085": 347, "791": 347, "8284": 347, "0428": 347, "7365": 347, "4566": 347, "0781": 347, "086": 347, "3355": 347, "0230": 347, "0423": 347, "076": 347, "3711": 347, "1335": 347, "6855": 347, "0304": 347, "0023": 347, "8459": 347, "338": 347, "9998": 347, "4399": 347, "339": 347, "2303": 347, "1346": 347, "340": 347, "2915": 347, "7116": 347, "341": 347, "5560": 347, "0487": 347, "342": 347, "5119": 347, "061": 347, "343": 347, "3305": 347, "3705": 347, "957": 347, "344": 347, "6068": 347, "345": 347, "5731": 347, "3897": 347, "0376": 347, "347": 347, "0434": 347, "012": 347, "1300": 347, "1215": 347, "0968": 347, "350": 347, "1348": 347, "0073": 347, "5052": 347, "4184": 347, "2817": 347, "8887": 347, "353": 347, "4779": 347, "1009": 347, "354": 347, "0604": 347, "599": 347, "355": 347, "4486": 347, "1176": 347, "656": 347, "356": 347, "2436": 347, "0668": 347, "8849": 347, "0012": 347, "358": 347, "7511": 347, "8804": 347, "359": 347, "8870": 347, "6728": 347, "360": 347, "8841": 347, "5508": 347, "361": 347, "5242": 347, "6185": 347, "363": 347, "1378": 347, "0204": 347, "364": 347, "0355": 347, "685": 347, "365": 347, "4884": 347, "0231": 347, "0014": 347, "6793": 347, "367": 347, "9834": 347, "863": 347, "368": 347, "6709": 347, "462": 347, "369": 347, "5199": 347, "9790": 347, "370": 347, "9401": 347, "7802": 347, "371": 347, "6723": 347, "372": 347, "2678": 347, "6201": 347, "373": 347, "2184": 347, "7385": 347, "374": 347, "6344": 347, "617": 347, "375": 347, "9945": 347, "0772": 347, "567": 347, "7576": 347, "0398": 347, "377": 347, "3396": 347, "0022": 347, "094": 347, "378": 347, "3073": 347, "4018": 347, "379": 347, "1869": 347, "380": 347, "0481": 347, "1117": 347, "381": 347, "6823": 347, "981": 347, "8305": 347, "0210": 347, "383": 347, "4908": 347, "0272": 347, "538": 347, "3267": 347, "0111": 347, "7965": 347, "1796": 347, "0039": 347, "5396": 347, "386": 347, "3757": 347, "0490": 347, "387": 347, "1394": 347, "4187": 347, "2986": 347, "7954": 347, "1274": 347, "0063": 347, "813": 347, "390": 347, "8706": 347, "0114": 347, "391": 347, "6922": 347, "2423": 347, "392": 347, "9115": 347, "2602": 347, "393": 347, "2449": 347, "0783": 347, "394": 347, "0631": 347, "0057": 347, "7444": 347, "395": 347, "3339": 347, "0167": 347, "396": 347, "4806": 347, "397": 347, "4171": 347, "067": 347, "398": 347, "2618": 347, "5809": 347, "399": 347, "74it": 347, "0054": 347, "3364": 347, "8733": 347, "0184": 347, "401": 347, "9137": 347, "0113": 347, "025": 347, "0386": 347, "0625": 347, "403": 347, "1332": 347, "0582": 347, "7816": 347, "404": 347, "8341": 347, "0941": 347, "854": 347, "405": 347, "8615": 347, "588": 347, "3849": 347, "008": 347, "407": 347, "9395": 347, "0765": 347, "055": 347, "408": 347, "2685": 347, "2235": 347, "688": 347, "3052": 347, "4249": 347, "410": 347, "6806": 347, "6383": 347, "3721": 347, "9981": 347, "412": 347, "1862": 347, "822": 347, "413": 347, "9811": 347, "0171": 347, "013": 347, "414": 347, "0252": 347, "0049": 347, "6205": 347, "415": 347, "1108": 347, "4921": 347, "9142": 347, "8130": 347, "417": 347, "1725": 347, "0036": 347, "3196": 347, "418": 347, "7795": 347, "0242": 347, "799": 347, "7737": 347, "0138": 347, "420": 347, "1462": 347, "0053": 347, "421": 347, "9226": 347, "6139": 347, "422": 347, "9889": 347, "0403": 347, "423": 347, "6194": 347, "0032": 347, "3989": 347, "0104": 347, "425": 347, "9960": 347, "0009": 347, "6009": 347, "426": 347, "2697": 347, "0914": 347, "427": 347, "1114": 347, "428": 347, "9862": 347, "1932": 347, "429": 347, "0637": 347, "0623": 347, "082": 347, "430": 347, "9906": 347, "2031": 347, "431": 347, "9948": 347, "0895": 347, "432": 347, "1970": 347, "0256": 347, "4231": 347, "0449": 347, "644": 347, "434": 347, "1039": 347, "1973": 347, "435": 347, "4561": 347, "1225": 347, "436": 347, "0211": 347, "2125": 347, "437": 347, "3866": 347, "0050": 347, "7202": 347, "438": 347, "6388": 347, "0072": 347, "439": 347, "1187": 347, "0015": 347, "5116": 347, "440": 347, "0432": 347, "0025": 347, "7809": 347, "1925": 347, "0103": 347, "442": 347, "9570": 347, "443": 347, "0871": 347, "5601": 347, "0165": 347, "0047": 347, "6061": 347, "2746": 347, "0027": 347, "7887": 347, "446": 347, "1835": 347, "0035": 347, "447": 347, "8420": 347, "548": 347, "2653": 347, "0126": 347, "9736": 347, "449": 347, "0594": 347, "0119": 347, "6196": 347, "450": 347, "4509": 347, "0373": 347, "451": 347, "0620": 347, "452": 347, "6898": 347, "3235": 347, "687": 347, "453": 347, "5879": 347, "454": 347, "8406": 347, "0694": 347, "455": 347, "8259": 347, "0235": 347, "8500": 347, "0024": 347, "4054": 347, "458": 347, "2027": 347, "0894": 347, "459": 347, "5966": 347, "460": 347, "6942": 347, "0016": 347, "6703": 347, "0145": 347, "8124": 347, "0218": 347, "9196": 347, "0188": 347, "8986": 347, "0884": 347, "0084": 347, "5624": 347, "465": 347, "8862": 347, "0006": 347, "5384": 347, "466": 347, "5837": 347, "467": 347, "8954": 347, "0101": 347, "6751": [347, 352], "468": 347, "8063": 347, "0122": 347, "9635": 347, "469": 347, "0692": 347, "4216": 347, "470": 347, "1227": 347, "0586": 347, "162e": 347, "471": 347, "9690": 347, "4166": 347, "17it": 347, "6324": 347, "473": 347, "0778": 347, "474": 347, "8548": 347, "0017": 347, "4408": 347, "475": 347, "8125": 347, "1515": 347, "476": 347, "2733": 347, "0044": 347, "2836": 347, "477": 347, "7497": 347, "7681": 347, "478": 347, "8547": 347, "0105": 347, "7212": 347, "479": 347, "9848": 347, "0019": 347, "6498": 347, "1987": 347, "0011": 347, "5473": 347, "481": 347, "8991": 347, "6091": 347, "9189": 347, "5771": 347, "483": 347, "6781": 347, "7542": 347, "484": 347, "5959": 347, "0064": 347, "4295": 347, "485": 347, "2547": 347, "486": 347, "0636": 347, "547": 347, "487": 347, "0065": 347, "488": 347, "1694": 347, "0083": 347, "5759": 347, "489": 347, "0493": 347, "0021": 347, "7805": 347, "490": 347, "497": 347, "491": 347, "9717": 347, "3672": 347, "492": 347, "0207": 347, "493": 347, "8266": 347, "5365": 347, "494": 347, "2623": 347, "5078": 347, "495": 347, "4545": 347, "09636": 347, "8754": 347, "498": 347, "0031": 347, "8269": 347, "499": 347, "4082": 347, "6642": 347, "2284": 347, "501": 347, "9130": 347, "502": 347, "503": 347, "7624": 347, "0056": 347, "3858": 347, "504": 347, "0890": 347, "0042": 347, "505": 347, "7505": 347, "2157": 347, "506": 347, "8394": 347, "3413": 347, "507": 347, "9609": 347, "0041": 347, "6905": 347, "508": 347, "8467": 347, "4409": 347, "509": 347, "510": 347, "8128": [347, 352], "3559": 347, "511": 347, "1479": 347, "0264": 347, "1589": 347, "566": 347, "513": 347, "2756": 347, "0046": 347, "5266": 347, "514": 347, "9873": 347, "0112": 347, "9314": 347, "515": 347, "3791": 347, "0721": 347, "516": 347, "4580": 347, "0758": 347, "6114": 347, "517": 347, "2431": 347, "518": 347, "1958": 347, "5553": 347, "8924": 347, "0097": 347, "520": 347, "3737": 347, "0234": 347, "521": 347, "9125": 347, "4623": 347, "3230": 347, "0589": 347, "3784": 347, "523": 347, "9482": 347, "0051": 347, "524": 347, "1979": 347, "0045": 347, "6401": 347, "525": 347, "1588": 347, "0048": 347, "6255": 347, "526": 347, "6084": 347, "3477": 347, "1475": 347, "0209": 347, "528": 347, "7611": 347, "1040": 347, "0099": 347, "0173": 347, "643": 347, "530": 347, "8189": 347, "4358": 347, "531": 347, "9897": 347, "532": 347, "1548": 347, "9751": 347, "533": 347, "6362": 347, "7495": 347, "534": 347, "1749": 347, "9513": 347, "535": 347, "7708": 347, "0371": 347, "536": 347, "2649": 347, "0437": 347, "537": 347, "5491": 347, "0276": 347, "6426": 347, "7294": 347, "078e": 347, "539": 347, "9928": 347, "540": 347, "7937": 347, "0124": 347, "9664": 347, "541": 347, "3342": 347, "542": 347, "2046": 347, "5496": 347, "0956": 347, "0059": 347, "545": 347, "9028": 347, "5843": 347, "546": 347, "0674": 347, "0178": 347, "797": 347, "2815": 347, "0599": 347, "1587": 347, "9276": 347, "8228": 347, "6164": 347, "551": 347, "6850": 347, "9167": 347, "3092": 347, "0670": 347, "9177": 347, "553": 347, "1599": 347, "0043": 347, "554": 347, "6367": 347, "555": 347, "3657": 347, "6694": 347, "2622": 347, "0372": 347, "4841": 347, "558": 347, "2707": 347, "757": 347, "559": 347, "2267": 347, "5415": 347, "560": 347, "4556": 347, "0163": 347, "1839": 347, "0809": 347, "6262": 347, "562": 347, "0278": [347, 352], "1112": 347, "6155": 347, "565": 347, "1427": 347, "3582": 347, "624": 347, "7870": 347, "9490": 347, "0439": 347, "8796": 347, "568": 347, "8026": 347, "612": 347, "569": 347, "3147": 347, "8486": 347, "570": 347, "7917": 347, "0129": 347, "571": 347, "9553": 347, "0020": 347, "6871": 347, "572": 347, "3132": 347, "0159": 347, "8646": 347, "573": 347, "5320": 347, "0269": 347, "574": 347, "2955": 347, "0245": 347, "575": 347, "3347": 347, "0179": 347, "9718": 347, "1629": 347, "804": 347, "577": 347, "0070": 347, "4335": 347, "578": 347, "579": 347, "3049": 347, "9063": 347, "580": 347, "8785": 347, "3295": 347, "5184": 347, "0546": 347, "582": 347, "4589": 347, "583": 347, "4697": 347, "2476": 347, "584": 347, "2397": 347, "585": 347, "4953": 347, "1775": 347, "586": 347, "2258": 347, "0110": 347, "7671": 347, "587": 347, "3981": 347, "8590": 347, "589": 347, "9820": 347, "4221": 347, "590": 347, "1293": 347, "0116": 347, "868": 347, "1675": 347, "5931": 347, "592": 347, "2910": 347, "5219": 347, "2124": 347, "1730": 347, "737": 347, "594": 347, "2914": 347, "0206": 347, "595": 347, "0172": 347, "3982": 347, "0945": 347, "0121": 347, "4789": 347, "597": 347, "3805": 347, "598": 347, "3310": 347, "5065": 347, "6028": 347, "6316": 347, "6724": 347, "6523": 347, "601": 347, "0136": 347, "4298": 347, "602": 347, "3524": 347, "2629": 347, "603": 347, "2635": 347, "7839": 347, "604": 347, "6041": 347, "8027": 347, "4170": 347, "4675": 347, "606": 347, "3153": 347, "9316": 347, "607": 347, "0649": 347, "9722": 347, "7989": 347, "0329": 347, "609": 347, "1976": 347, "6852": 347, "4793": 347, "1255": 347, "611": 347, "4581": 347, "0394": 347, "2047": 347, "0326": 347, "613": 347, "8967": 347, "8619": 347, "614": 347, "5906": 347, "6491": 347, "615": 347, "6634": 347, "4394": 347, "616": 347, "0624": 347, "0061": 347, "5676": 347, "3259": 347, "0131": 347, "7733": 347, "618": 347, "7515": 347, "0189": 347, "5575": 347, "619": 347, "9313": 347, "6286": 347, "620": 347, "4325": 347, "7832": 347, "621": 347, "1134": 347, "622": 347, "4572": 347, "0500": 347, "5838": 347, "623": 347, "3818": 347, "8623": 347, "1253": 347, "6622": 347, "subject": 347, "saw": [347, 349], "explain": 348, "semat": 348, "r3mtransform": 348, "env_transform": [348, 352], "s3": 348, "amazonaw": 348, "r3m_50": 348, "374m": 348, "5m": 348, "8mb": 348, "9m": 348, "0mb": 348, "2m": 348, "1mb": 348, "0m": 348, "3mb": 348, "4mb": 348, "7mb": 348, "100m": 348, "115m": 348, "6mb": 348, "130m": 348, "2mb": 348, "140m": 348, "149m": 348, "164m": 348, "171m": 348, "9mb": 348, "180m": 348, "195m": 348, "5mb": 348, "202m": 348, "212m": 348, "218m": 348, "229m": 348, "244m": 348, "253m": 348, "262m": 348, "268m": 348, "277m": 348, "283m": 348, "293m": 348, "300m": 348, "311m": 348, "326m": 348, "333m": 348, "339m": 348, "348m": 348, "360m": 348, "373m": 348, "wiser": 348, "conclud": 348, "_storag": [348, 349], "supervis": [349, 352], "pull": 349, "temporarili": 349, "batteri": 349, "dataliststorag": 349, "datalazytensorstorag": 349, "tensordidct": 349, "datalazymemmapstorag": 349, "buffer_list": 349, "lowest": 349, "medium": 349, "buffer_lazytensor": 349, "buffer_lazymemmap": 349, "tempdir": 349, "tmp5qglp9jc": 349, "fullest": 349, "convini": 349, "mydata": 349, "background": 349, "question": [349, 351], "_i": 349, "artifici": 349, "0892946e": 349, "she": 349, "augment": 349, "pars": 349, "proport": 349, "hist": 349, "barcontain": 349, "artist": 349, "revert": 349, "expens": 349, "reappear": 349, "unfold": 349, "problemat": 349, "window": 349, "4th": 349, "demo": 351, "icml": 351, "vmoen": 351, "fb": 351, "invest": 351, "platform": 351, "media": 351, "predominantli": 351, "tensordict1": 351, "tensordict2": 351, "tensordict_sampl": 351, "_sampler": 351, "_sum_tre": 351, "modulenotfounderror": 351, "28791671991348267": 351, "noopresetenv": [351, 352], "backbone_modul": 351, "params_expand": 351, "tensordict_exp": 351, "base_modul": 351, "0137": 351, "1524": 351, "0641": 351, "viewbackward0": 351, "asstridedbackward0": 351, "8728": 351, "1334": 351, "3494": 351, "6887": 351, "6402": 351, "_safetanhbackward": 351, "1132": 351, "1762": 351, "3430": 351, "2668": 351, "2918": 351, "6239": 351, "roughli": 351, "tensordicts_prealloc": 351, "tensordicts_stack": 351, "tensordict_rollout": [351, 352], "disclaim": 351, "concatmodul": 351, "loss_td": 351, "year": 351, "roadmap": 351, "compris": 351, "contributor": 351, "curiou": 351, "nascent": 351, "unsupervis": 352, "rom": 352, "licens": 352, "pygam": 352, "unifi": 352, "_build_env": 352, "amidar": 352, "assault": 352, "3606": 352, "deserv": 352, "__episode__": 352, "__trajectory__": 352, "void": 352, "reproduct": 352, "tensordict_tprim": 352, "imshow": 352, "axesimag": 352, "0x7f8d1f0e6970": 352, "inconsist": 352, "wrapper1": 352, "wrapper2": 352, "obviou": 352, "truth": 352, "env0": 352, "env_transformed_bi": 352, "stanc": 352, "transformeddistribut": 352, "base_dist": 352, "concat": 352, "mofidi": 352, "transformedenviron": 352, "moderet": 352, "computation": 352, "legitim": 352, "incom": 352, "amongst": 352, "wor": 352, "convention": 352, "markovian": 352, "3288080526": 352, "constain": 352, "bar_": 352, "get_someth": 352, "bar_5ccc52a6": 352, "b94d": 352, "aargh": 352, "foo_list": 352, "batched_env": 352, "_dispatch_caller_parallel": 352, "0x7f9b7e0bb940": 352, "bar_64429202": 352, "b76b": 352, "bar_644291f8": 352, "bar_6444be74": 352, "9dec": 352, "parallen": 352, "particularili": 352, "evolv": 352, "steadi": 352, "approx": 352, "1379": 352, "3265": 352, "4178": 352, "_extra_st": 352, "observation_ssq": 352, "observation_sum": 352, "1628": 352, "1493": 352, "1876": 352, "2457": 352, "dispach": 352, "absor": 352}, "objects": {"torchrl._utils": [[11, 0, 1, "", "implement_for"]], "torchrl._utils.implement_for": [[11, 1, 1, "", "get_class_that_defined_method"], [11, 1, 1, "", "import_module"], [11, 1, 1, "", "module_set"], [11, 1, 1, "", "reset"]], "torchrl.collectors.collectors": [[12, 0, 1, "", "DataCollectorBase"], [13, 0, 1, "", "MultiSyncDataCollector"], [14, 0, 1, "", "MultiaSyncDataCollector"], [15, 0, 1, "", "RandomPolicy"], [16, 0, 1, "", "SyncDataCollector"], [17, 0, 1, "", "aSyncDataCollector"]], "torchrl.collectors.collectors.DataCollectorBase": [[12, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.collectors.MultiSyncDataCollector": [[13, 1, 1, "", "load_state_dict"], [13, 1, 1, "", "reset"], [13, 1, 1, "", "set_seed"], [13, 1, 1, "", "shutdown"], [13, 1, 1, "", "state_dict"], [13, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.collectors.MultiaSyncDataCollector": [[14, 1, 1, "", "load_state_dict"], [14, 1, 1, "", "reset"], [14, 1, 1, "", "set_seed"], [14, 1, 1, "", "shutdown"], [14, 1, 1, "", "state_dict"], [14, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.collectors.SyncDataCollector": [[16, 1, 1, "", "iterator"], [16, 1, 1, "", "load_state_dict"], [16, 1, 1, "", "reset"], [16, 1, 1, "", "rollout"], [16, 1, 1, "", "set_seed"], [16, 1, 1, "", "shutdown"], [16, 1, 1, "", "state_dict"], [16, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.collectors.aSyncDataCollector": [[17, 1, 1, "", "load_state_dict"], [17, 1, 1, "", "reset"], [17, 1, 1, "", "set_seed"], [17, 1, 1, "", "shutdown"], [17, 1, 1, "", "state_dict"], [17, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.distributed": [[18, 0, 1, "", "DistributedDataCollector"], [19, 0, 1, "", "DistributedSyncDataCollector"], [20, 0, 1, "", "RPCDataCollector"], [21, 0, 1, "", "RayCollector"], [22, 0, 1, "", "submitit_delayed_launcher"]], "torchrl.collectors.distributed.DistributedDataCollector": [[18, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.distributed.DistributedSyncDataCollector": [[19, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.distributed.RPCDataCollector": [[20, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.distributed.RayCollector": [[21, 1, 1, "", "add_collectors"], [21, 1, 1, "", "load_state_dict"], [21, 1, 1, "", "local_policy"], [21, 1, 1, "", "remote_collectors"], [21, 1, 1, "", "set_seed"], [21, 1, 1, "", "shutdown"], [21, 1, 1, "", "state_dict"], [21, 1, 1, "", "stop_remote_collectors"], [21, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.utils": [[23, 2, 1, "", "split_trajectories"]], "torchrl.data": [[24, 0, 1, "", "BinaryDiscreteTensorSpec"], [25, 0, 1, "", "BoundedTensorSpec"], [26, 0, 1, "", "CompositeSpec"], [27, 0, 1, "", "DiscreteTensorSpec"], [28, 0, 1, "", "LazyStackedCompositeSpec"], [29, 0, 1, "", "LazyStackedTensorSpec"], [30, 0, 1, "", "MultiDiscreteTensorSpec"], [31, 0, 1, "", "MultiOneHotDiscreteTensorSpec"], [32, 0, 1, "", "MultiStep"], [33, 0, 1, "", "OneHotDiscreteTensorSpec"], [34, 0, 1, "", "PairwiseDataset"], [35, 0, 1, "", "PrioritizedReplayBuffer"], [36, 0, 1, "", "PromptData"], [37, 0, 1, "", "PromptTensorDictTokenizer"], [38, 0, 1, "", "ReplayBuffer"], [39, 0, 1, "", "RewardData"], [40, 0, 1, "", "RolloutFromModel"], [41, 0, 1, "", "TensorDictPrioritizedReplayBuffer"], [42, 0, 1, "", "TensorDictReplayBuffer"], [43, 0, 1, "", "TensorDictTokenizer"], [44, 0, 1, "", "TensorSpec"], [45, 0, 1, "", "TokenizedDatasetLoader"], [46, 0, 1, "", "UnboundedContinuousTensorSpec"], [47, 0, 1, "", "UnboundedDiscreteTensorSpec"], [48, 0, 1, "", "check_no_exclusive_keys"], [49, 0, 1, "", "consolidate_spec"], [50, 0, 1, "", "contains_lazy_spec"], [51, 0, 1, "", "create_infinite_iterator"], [59, 0, 1, "", "get_dataloader"]], "torchrl.data.BinaryDiscreteTensorSpec": [[24, 1, 1, "", "assert_is_in"], [24, 1, 1, "", "encode"], [24, 1, 1, "", "expand"], [24, 1, 1, "", "implements_for_spec"], [24, 1, 1, "", "index"], [24, 1, 1, "", "is_in"], [24, 1, 1, "", "project"], [24, 1, 1, "", "rand"], [24, 1, 1, "", "squeeze"], [24, 1, 1, "", "to_numpy"], [24, 1, 1, "", "to_one_hot"], [24, 1, 1, "", "to_one_hot_spec"], [24, 1, 1, "", "type_check"], [24, 1, 1, "", "zero"]], "torchrl.data.BoundedTensorSpec": [[25, 1, 1, "", "assert_is_in"], [25, 1, 1, "", "encode"], [25, 1, 1, "", "expand"], [25, 1, 1, "", "implements_for_spec"], [25, 1, 1, "", "index"], [25, 1, 1, "", "is_in"], [25, 1, 1, "", "project"], [25, 1, 1, "", "rand"], [25, 1, 1, "", "squeeze"], [25, 1, 1, "", "to_numpy"], [25, 1, 1, "", "type_check"], [25, 1, 1, "", "zero"]], "torchrl.data.CompositeSpec": [[26, 1, 1, "", "assert_is_in"], [26, 1, 1, "", "empty"], [26, 1, 1, "", "encode"], [26, 1, 1, "", "expand"], [26, 1, 1, "", "get"], [26, 1, 1, "", "implements_for_spec"], [26, 1, 1, "", "index"], [26, 1, 1, "", "is_empty"], [26, 1, 1, "", "is_in"], [26, 1, 1, "", "items"], [26, 1, 1, "", "keys"], [26, 1, 1, "", "lock_"], [26, 1, 1, "", "project"], [26, 1, 1, "", "rand"], [26, 1, 1, "", "squeeze"], [26, 1, 1, "", "to_numpy"], [26, 1, 1, "", "type_check"], [26, 1, 1, "", "unlock_"], [26, 1, 1, "", "values"], [26, 1, 1, "", "zero"]], "torchrl.data.DiscreteTensorSpec": [[27, 1, 1, "", "assert_is_in"], [27, 1, 1, "", "encode"], [27, 1, 1, "", "expand"], [27, 1, 1, "", "implements_for_spec"], [27, 1, 1, "", "index"], [27, 1, 1, "", "is_in"], [27, 1, 1, "", "project"], [27, 1, 1, "", "rand"], [27, 1, 1, "", "squeeze"], [27, 1, 1, "", "to_numpy"], [27, 1, 1, "", "to_one_hot"], [27, 1, 1, "", "to_one_hot_spec"], [27, 1, 1, "", "type_check"], [27, 1, 1, "", "zero"]], "torchrl.data.LazyStackedCompositeSpec": [[28, 1, 1, "", "assert_is_in"], [28, 1, 1, "", "empty"], [28, 1, 1, "", "encode"], [28, 1, 1, "", "expand"], [28, 1, 1, "", "get"], [28, 1, 1, "", "implements_for_spec"], [28, 1, 1, "", "index"], [28, 1, 1, "", "is_empty"], [28, 1, 1, "", "is_in"], [28, 1, 1, "", "items"], [28, 1, 1, "", "keys"], [28, 1, 1, "", "lock_"], [28, 1, 1, "", "project"], [28, 1, 1, "", "rand"], [28, 1, 1, "", "squeeze"], [28, 1, 1, "", "to_numpy"], [28, 1, 1, "", "type_check"], [28, 1, 1, "", "unlock_"], [28, 1, 1, "", "values"], [28, 1, 1, "", "zero"]], "torchrl.data.LazyStackedTensorSpec": [[29, 1, 1, "", "assert_is_in"], [29, 1, 1, "", "encode"], [29, 1, 1, "", "expand"], [29, 1, 1, "", "implements_for_spec"], [29, 1, 1, "", "index"], [29, 1, 1, "", "is_in"], [29, 1, 1, "", "project"], [29, 1, 1, "", "rand"], [29, 1, 1, "", "squeeze"], [29, 1, 1, "", "to_numpy"], [29, 1, 1, "", "type_check"], [29, 1, 1, "", "zero"]], "torchrl.data.MultiDiscreteTensorSpec": [[30, 1, 1, "", "assert_is_in"], [30, 1, 1, "", "encode"], [30, 1, 1, "", "expand"], [30, 1, 1, "", "implements_for_spec"], [30, 1, 1, "", "index"], [30, 1, 1, "", "is_in"], [30, 1, 1, "", "project"], [30, 1, 1, "", "rand"], [30, 1, 1, "", "squeeze"], [30, 1, 1, "", "to_numpy"], [30, 1, 1, "", "to_one_hot"], [30, 1, 1, "", "to_one_hot_spec"], [30, 1, 1, "", "type_check"], [30, 1, 1, "", "zero"]], "torchrl.data.MultiOneHotDiscreteTensorSpec": [[31, 1, 1, "", "assert_is_in"], [31, 1, 1, "", "encode"], [31, 1, 1, "", "expand"], [31, 1, 1, "", "implements_for_spec"], [31, 1, 1, "", "index"], [31, 1, 1, "", "is_in"], [31, 1, 1, "", "project"], [31, 1, 1, "", "rand"], [31, 1, 1, "", "squeeze"], [31, 1, 1, "", "to_categorical"], [31, 1, 1, "", "to_categorical_spec"], [31, 1, 1, "", "to_numpy"], [31, 1, 1, "", "type_check"], [31, 1, 1, "", "zero"]], "torchrl.data.MultiStep": [[32, 1, 1, "", "add_module"], [32, 1, 1, "", "apply"], [32, 1, 1, "", "bfloat16"], [32, 1, 1, "", "buffers"], [32, 1, 1, "", "children"], [32, 1, 1, "", "compile"], [32, 1, 1, "", "cpu"], [32, 1, 1, "", "cuda"], [32, 1, 1, "", "double"], [32, 1, 1, "", "eval"], [32, 1, 1, "", "extra_repr"], [32, 1, 1, "", "float"], [32, 1, 1, "", "forward"], [32, 1, 1, "", "get_buffer"], [32, 1, 1, "", "get_extra_state"], [32, 1, 1, "", "get_parameter"], [32, 1, 1, "", "get_submodule"], [32, 1, 1, "", "half"], [32, 1, 1, "", "ipu"], [32, 1, 1, "", "load_state_dict"], [32, 1, 1, "", "modules"], [32, 1, 1, "", "named_buffers"], [32, 1, 1, "", "named_children"], [32, 1, 1, "", "named_modules"], [32, 1, 1, "", "named_parameters"], [32, 1, 1, "", "parameters"], [32, 1, 1, "", "register_backward_hook"], [32, 1, 1, "", "register_buffer"], [32, 1, 1, "", "register_forward_hook"], [32, 1, 1, "", "register_forward_pre_hook"], [32, 1, 1, "", "register_full_backward_hook"], [32, 1, 1, "", "register_full_backward_pre_hook"], [32, 1, 1, "", "register_load_state_dict_post_hook"], [32, 1, 1, "", "register_module"], [32, 1, 1, "", "register_parameter"], [32, 1, 1, "", "register_state_dict_pre_hook"], [32, 1, 1, "", "requires_grad_"], [32, 1, 1, "", "set_extra_state"], [32, 1, 1, "", "share_memory"], [32, 1, 1, "", "state_dict"], [32, 1, 1, "", "to"], [32, 1, 1, "", "to_empty"], [32, 1, 1, "", "train"], [32, 1, 1, "", "type"], [32, 1, 1, "", "xpu"], [32, 1, 1, "", "zero_grad"]], "torchrl.data.OneHotDiscreteTensorSpec": [[33, 1, 1, "", "assert_is_in"], [33, 1, 1, "", "encode"], [33, 1, 1, "", "expand"], [33, 1, 1, "", "implements_for_spec"], [33, 1, 1, "", "index"], [33, 1, 1, "", "is_in"], [33, 1, 1, "", "project"], [33, 1, 1, "", "rand"], [33, 1, 1, "", "squeeze"], [33, 1, 1, "", "to_categorical"], [33, 1, 1, "", "to_categorical_spec"], [33, 1, 1, "", "to_numpy"], [33, 1, 1, "", "type_check"], [33, 1, 1, "", "zero"]], "torchrl.data.PairwiseDataset": [[34, 3, 1, "", "batch_size"], [34, 3, 1, "", "device"], [34, 1, 1, "", "from_dataset"], [34, 1, 1, "", "from_dict"], [34, 1, 1, "", "from_tensordict"], [34, 1, 1, "", "get"], [34, 1, 1, "", "load_state_dict"], [34, 1, 1, "", "memmap"], [34, 1, 1, "", "memmap_"], [34, 1, 1, "", "memmap_like"], [34, 1, 1, "", "set"], [34, 1, 1, "", "state_dict"], [34, 1, 1, "", "to_tensordict"], [34, 1, 1, "", "unbind"]], "torchrl.data.PrioritizedReplayBuffer": [[35, 1, 1, "", "add"], [35, 1, 1, "", "append_transform"], [35, 1, 1, "", "dumps"], [35, 1, 1, "", "empty"], [35, 1, 1, "", "extend"], [35, 1, 1, "", "insert_transform"], [35, 1, 1, "", "loads"], [35, 1, 1, "", "sample"]], "torchrl.data.PromptData": [[36, 3, 1, "", "batch_size"], [36, 3, 1, "", "device"], [36, 1, 1, "", "from_dataset"], [36, 1, 1, "", "from_dict"], [36, 1, 1, "", "from_tensordict"], [36, 1, 1, "", "get"], [36, 1, 1, "", "load_state_dict"], [36, 1, 1, "", "memmap"], [36, 1, 1, "", "memmap_"], [36, 1, 1, "", "memmap_like"], [36, 1, 1, "", "set"], [36, 1, 1, "", "state_dict"], [36, 1, 1, "", "to_tensordict"], [36, 1, 1, "", "unbind"]], "torchrl.data.ReplayBuffer": [[38, 1, 1, "", "add"], [38, 1, 1, "", "append_transform"], [38, 1, 1, "", "dumps"], [38, 1, 1, "", "empty"], [38, 1, 1, "", "extend"], [38, 1, 1, "", "insert_transform"], [38, 1, 1, "", "loads"], [38, 1, 1, "", "sample"]], "torchrl.data.RewardData": [[39, 3, 1, "", "batch_size"], [39, 3, 1, "", "device"], [39, 1, 1, "", "from_dict"], [39, 1, 1, "", "from_tensordict"], [39, 1, 1, "", "get"], [39, 1, 1, "", "load_state_dict"], [39, 1, 1, "", "memmap"], [39, 1, 1, "", "memmap_"], [39, 1, 1, "", "memmap_like"], [39, 1, 1, "", "set"], [39, 1, 1, "", "state_dict"], [39, 1, 1, "", "to_tensordict"], [39, 1, 1, "", "unbind"]], "torchrl.data.RolloutFromModel": [[40, 1, 1, "", "create_rollout_td"], [40, 1, 1, "", "generate"], [40, 1, 1, "", "logprobs_of_labels"]], "torchrl.data.TensorDictPrioritizedReplayBuffer": [[41, 1, 1, "", "add"], [41, 1, 1, "", "append_transform"], [41, 1, 1, "", "dumps"], [41, 1, 1, "", "empty"], [41, 1, 1, "", "extend"], [41, 1, 1, "", "insert_transform"], [41, 1, 1, "", "loads"], [41, 1, 1, "", "sample"]], "torchrl.data.TensorDictReplayBuffer": [[42, 1, 1, "", "add"], [42, 1, 1, "", "append_transform"], [42, 1, 1, "", "dumps"], [42, 1, 1, "", "empty"], [42, 1, 1, "", "extend"], [42, 1, 1, "", "insert_transform"], [42, 1, 1, "", "loads"], [42, 1, 1, "", "sample"]], "torchrl.data.TensorSpec": [[44, 1, 1, "", "assert_is_in"], [44, 1, 1, "", "encode"], [44, 1, 1, "", "expand"], [44, 1, 1, "", "implements_for_spec"], [44, 1, 1, "", "index"], [44, 1, 1, "", "is_in"], [44, 1, 1, "", "project"], [44, 1, 1, "", "rand"], [44, 1, 1, "", "squeeze"], [44, 1, 1, "", "to_numpy"], [44, 1, 1, "", "type_check"], [44, 1, 1, "", "zero"]], "torchrl.data.TokenizedDatasetLoader": [[45, 1, 1, "", "dataset_to_tensordict"], [45, 1, 1, "", "load"]], "torchrl.data.UnboundedContinuousTensorSpec": [[46, 1, 1, "", "assert_is_in"], [46, 1, 1, "", "encode"], [46, 1, 1, "", "expand"], [46, 1, 1, "", "implements_for_spec"], [46, 1, 1, "", "index"], [46, 1, 1, "", "is_in"], [46, 1, 1, "", "project"], [46, 1, 1, "", "rand"], [46, 1, 1, "", "squeeze"], [46, 1, 1, "", "to_numpy"], [46, 1, 1, "", "type_check"], [46, 1, 1, "", "zero"]], "torchrl.data.UnboundedDiscreteTensorSpec": [[47, 1, 1, "", "assert_is_in"], [47, 1, 1, "", "encode"], [47, 1, 1, "", "expand"], [47, 1, 1, "", "implements_for_spec"], [47, 1, 1, "", "index"], [47, 1, 1, "", "is_in"], [47, 1, 1, "", "project"], [47, 1, 1, "", "rand"], [47, 1, 1, "", "squeeze"], [47, 1, 1, "", "to_numpy"], [47, 1, 1, "", "type_check"], [47, 1, 1, "", "zero"]], "torchrl.data.datasets": [[52, 0, 1, "", "D4RLExperienceReplay"], [53, 0, 1, "", "GenDGRLExperienceReplay"], [54, 0, 1, "", "MinariExperienceReplay"], [55, 0, 1, "", "OpenMLExperienceReplay"], [56, 0, 1, "", "OpenXExperienceReplay"], [57, 0, 1, "", "RobosetExperienceReplay"], [58, 0, 1, "", "VD4RLExperienceReplay"]], "torchrl.data.datasets.D4RLExperienceReplay": [[52, 1, 1, "", "add"], [52, 1, 1, "", "append_transform"], [52, 1, 1, "", "dumps"], [52, 1, 1, "", "empty"], [52, 1, 1, "", "extend"], [52, 1, 1, "", "insert_transform"], [52, 1, 1, "", "loads"], [52, 1, 1, "", "sample"]], "torchrl.data.datasets.GenDGRLExperienceReplay": [[53, 1, 1, "", "add"], [53, 1, 1, "", "append_transform"], [53, 1, 1, "", "dumps"], [53, 1, 1, "", "empty"], [53, 1, 1, "", "extend"], [53, 1, 1, "", "insert_transform"], [53, 1, 1, "", "loads"], [53, 1, 1, "", "sample"]], "torchrl.data.datasets.MinariExperienceReplay": [[54, 1, 1, "", "add"], [54, 1, 1, "", "append_transform"], [54, 1, 1, "", "dumps"], [54, 1, 1, "", "empty"], [54, 1, 1, "", "extend"], [54, 1, 1, "", "insert_transform"], [54, 1, 1, "", "loads"], [54, 1, 1, "", "sample"]], "torchrl.data.datasets.OpenMLExperienceReplay": [[55, 1, 1, "", "add"], [55, 1, 1, "", "append_transform"], [55, 1, 1, "", "dumps"], [55, 1, 1, "", "empty"], [55, 1, 1, "", "extend"], [55, 1, 1, "", "insert_transform"], [55, 1, 1, "", "loads"], [55, 1, 1, "", "sample"]], "torchrl.data.datasets.OpenXExperienceReplay": [[56, 1, 1, "", "add"], [56, 1, 1, "", "append_transform"], [56, 1, 1, "", "dumps"], [56, 1, 1, "", "empty"], [56, 1, 1, "", "extend"], [56, 1, 1, "", "insert_transform"], [56, 1, 1, "", "loads"], [56, 1, 1, "", "sample"]], "torchrl.data.datasets.RobosetExperienceReplay": [[57, 1, 1, "", "add"], [57, 1, 1, "", "append_transform"], [57, 1, 1, "", "dumps"], [57, 1, 1, "", "empty"], [57, 1, 1, "", "extend"], [57, 1, 1, "", "insert_transform"], [57, 1, 1, "", "loads"], [57, 1, 1, "", "sample"]], "torchrl.data.datasets.VD4RLExperienceReplay": [[58, 1, 1, "", "add"], [58, 1, 1, "", "append_transform"], [58, 1, 1, "", "dumps"], [58, 1, 1, "", "empty"], [58, 1, 1, "", "extend"], [58, 1, 1, "", "insert_transform"], [58, 1, 1, "", "loads"], [58, 1, 1, "", "sample"]], "torchrl.data.replay_buffers": [[60, 0, 1, "", "ImmutableDatasetWriter"], [61, 0, 1, "", "LazyMemmapStorage"], [62, 0, 1, "", "LazyTensorStorage"], [63, 0, 1, "", "ListStorage"], [64, 0, 1, "", "PrioritizedSampler"], [65, 0, 1, "", "RandomSampler"], [66, 0, 1, "", "ReplayBufferEnsemble"], [67, 0, 1, "", "RoundRobinWriter"], [68, 0, 1, "", "Sampler"], [69, 0, 1, "", "SamplerEnsemble"], [70, 0, 1, "", "SamplerWithoutReplacement"], [71, 0, 1, "", "SliceSampler"], [72, 0, 1, "", "SliceSamplerWithoutReplacement"], [73, 0, 1, "", "Storage"], [74, 0, 1, "", "StorageEnsemble"], [75, 0, 1, "", "TensorDictMaxValueWriter"], [76, 0, 1, "", "TensorDictRoundRobinWriter"], [77, 0, 1, "", "TensorStorage"], [78, 0, 1, "", "Writer"], [79, 0, 1, "", "WriterEnsemble"]], "torchrl.data.replay_buffers.ImmutableDatasetWriter": [[60, 1, 1, "", "add"], [60, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.LazyMemmapStorage": [[61, 1, 1, "", "attach"]], "torchrl.data.replay_buffers.LazyTensorStorage": [[62, 1, 1, "", "attach"]], "torchrl.data.replay_buffers.ListStorage": [[63, 1, 1, "", "attach"]], "torchrl.data.replay_buffers.PrioritizedSampler": [[64, 1, 1, "", "update_priority"]], "torchrl.data.replay_buffers.ReplayBufferEnsemble": [[66, 1, 1, "", "add"], [66, 1, 1, "", "append_transform"], [66, 1, 1, "", "dumps"], [66, 1, 1, "", "empty"], [66, 1, 1, "", "extend"], [66, 1, 1, "", "insert_transform"], [66, 1, 1, "", "loads"], [66, 1, 1, "", "sample"]], "torchrl.data.replay_buffers.RoundRobinWriter": [[67, 1, 1, "", "add"], [67, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.Storage": [[73, 1, 1, "", "attach"]], "torchrl.data.replay_buffers.StorageEnsemble": [[74, 1, 1, "", "attach"]], "torchrl.data.replay_buffers.TensorDictMaxValueWriter": [[75, 1, 1, "", "add"], [75, 1, 1, "", "extend"], [75, 1, 1, "", "get_insert_index"]], "torchrl.data.replay_buffers.TensorDictRoundRobinWriter": [[76, 1, 1, "", "add"], [76, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.TensorStorage": [[77, 1, 1, "", "attach"]], "torchrl.data.replay_buffers.Writer": [[78, 1, 1, "", "add"], [78, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.WriterEnsemble": [[79, 1, 1, "", "add"], [79, 1, 1, "", "extend"]], "torchrl.envs": [[80, 2, 1, "", "BraxEnv"], [81, 2, 1, "", "BraxWrapper"], [82, 2, 1, "", "DMControlEnv"], [83, 2, 1, "", "DMControlWrapper"], [84, 0, 1, "", "EnvBase"], [85, 0, 1, "", "EnvCreator"], [86, 0, 1, "", "EnvMetaData"], [87, 2, 1, "", "GymEnv"], [88, 0, 1, "", "GymLikeEnv"], [89, 2, 1, "", "GymWrapper"], [90, 2, 1, "", "HabitatEnv"], [91, 2, 1, "", "IsaacGymEnv"], [92, 2, 1, "", "IsaacGymWrapper"], [93, 2, 1, "", "JumanjiEnv"], [94, 2, 1, "", "JumanjiWrapper"], [95, 2, 1, "", "MOGymEnv"], [96, 2, 1, "", "MOGymWrapper"], [97, 2, 1, "", "MarlGroupMapType"], [98, 2, 1, "", "ModelBasedEnvBase"], [99, 2, 1, "", "MultiThreadedEnv"], [100, 2, 1, "", "MultiThreadedEnvWrapper"], [101, 2, 1, "", "OpenMLEnv"], [102, 0, 1, "", "ParallelEnv"], [103, 2, 1, "", "PettingZooEnv"], [104, 2, 1, "", "PettingZooWrapper"], [105, 2, 1, "", "RoboHiveEnv"], [106, 2, 1, "", "SMACv2Env"], [107, 2, 1, "", "SMACv2Wrapper"], [108, 0, 1, "", "SerialEnv"], [109, 2, 1, "", "VmasEnv"], [110, 2, 1, "", "VmasWrapper"], [111, 2, 1, "", "check_marl_grouping"], [112, 2, 1, "", "gym_backend"], [98, 1, 1, "", "rand_step"], [98, 1, 1, "", "reset"], [98, 1, 1, "", "rollout"], [114, 2, 1, "", "set_gym_backend"], [98, 1, 1, "", "set_seed"], [98, 1, 1, "", "step"]], "torchrl.envs.EnvBase": [[84, 3, 1, "", "action_key"], [84, 3, 1, "", "action_keys"], [84, 3, 1, "", "action_spec"], [84, 1, 1, "", "add_module"], [84, 1, 1, "", "apply"], [84, 3, 1, "", "batch_locked"], [84, 1, 1, "", "bfloat16"], [84, 1, 1, "", "buffers"], [84, 1, 1, "", "children"], [84, 1, 1, "", "compile"], [84, 1, 1, "", "cpu"], [84, 1, 1, "", "cuda"], [84, 3, 1, "", "done_key"], [84, 3, 1, "", "done_keys"], [84, 3, 1, "", "done_keys_groups"], [84, 3, 1, "", "done_spec"], [84, 1, 1, "", "double"], [84, 1, 1, "", "empty_cache"], [84, 1, 1, "", "eval"], [84, 1, 1, "", "extra_repr"], [84, 1, 1, "", "fake_tensordict"], [84, 1, 1, "", "float"], [84, 1, 1, "", "forward"], [84, 3, 1, "", "full_action_spec"], [84, 3, 1, "", "full_done_spec"], [84, 3, 1, "", "full_reward_spec"], [84, 3, 1, "", "full_state_spec"], [84, 1, 1, "", "get_buffer"], [84, 1, 1, "", "get_extra_state"], [84, 1, 1, "", "get_parameter"], [84, 1, 1, "", "get_submodule"], [84, 1, 1, "", "half"], [84, 3, 1, "", "input_spec"], [84, 1, 1, "", "ipu"], [84, 1, 1, "", "load_state_dict"], [84, 1, 1, "", "modules"], [84, 1, 1, "", "named_buffers"], [84, 1, 1, "", "named_children"], [84, 1, 1, "", "named_modules"], [84, 1, 1, "", "named_parameters"], [84, 3, 1, "", "observation_spec"], [84, 3, 1, "", "output_spec"], [84, 1, 1, "", "parameters"], [84, 1, 1, "", "rand_action"], [84, 1, 1, "id0", "rand_step"], [84, 1, 1, "", "register_backward_hook"], [84, 1, 1, "", "register_buffer"], [84, 1, 1, "", "register_forward_hook"], [84, 1, 1, "", "register_forward_pre_hook"], [84, 1, 1, "", "register_full_backward_hook"], [84, 1, 1, "", "register_full_backward_pre_hook"], [84, 1, 1, "", "register_gym"], [84, 1, 1, "", "register_load_state_dict_post_hook"], [84, 1, 1, "", "register_module"], [84, 1, 1, "", "register_parameter"], [84, 1, 1, "", "register_state_dict_pre_hook"], [84, 1, 1, "", "requires_grad_"], [84, 1, 1, "id1", "reset"], [84, 3, 1, "", "reset_keys"], [84, 3, 1, "", "reward_key"], [84, 3, 1, "", "reward_keys"], [84, 3, 1, "", "reward_spec"], [84, 1, 1, "id2", "rollout"], [84, 1, 1, "", "set_extra_state"], [84, 1, 1, "id3", "set_seed"], [84, 1, 1, "", "share_memory"], [84, 3, 1, "", "specs"], [84, 1, 1, "", "state_dict"], [84, 3, 1, "", "state_spec"], [84, 1, 1, "id4", "step"], [84, 1, 1, "", "step_and_maybe_reset"], [84, 1, 1, "", "to"], [84, 1, 1, "", "to_empty"], [84, 1, 1, "", "train"], [84, 1, 1, "", "type"], [84, 1, 1, "", "xpu"], [84, 1, 1, "", "zero_grad"]], "torchrl.envs.GymLikeEnv": [[88, 3, 1, "", "action_key"], [88, 3, 1, "", "action_keys"], [88, 3, 1, "", "action_spec"], [88, 1, 1, "", "add_module"], [88, 1, 1, "", "apply"], [88, 1, 1, "", "auto_register_info_dict"], [88, 3, 1, "", "batch_locked"], [88, 1, 1, "", "bfloat16"], [88, 1, 1, "", "buffers"], [88, 1, 1, "", "children"], [88, 1, 1, "", "close"], [88, 1, 1, "", "compile"], [88, 1, 1, "", "cpu"], [88, 1, 1, "", "cuda"], [88, 3, 1, "", "done_key"], [88, 3, 1, "", "done_keys"], [88, 3, 1, "", "done_keys_groups"], [88, 3, 1, "", "done_spec"], [88, 1, 1, "", "double"], [88, 1, 1, "", "empty_cache"], [88, 1, 1, "", "eval"], [88, 1, 1, "", "extra_repr"], [88, 1, 1, "", "fake_tensordict"], [88, 1, 1, "", "float"], [88, 1, 1, "", "forward"], [88, 3, 1, "", "full_action_spec"], [88, 3, 1, "", "full_done_spec"], [88, 3, 1, "", "full_reward_spec"], [88, 3, 1, "", "full_state_spec"], [88, 1, 1, "", "get_buffer"], [88, 1, 1, "", "get_extra_state"], [88, 1, 1, "", "get_parameter"], [88, 1, 1, "", "get_submodule"], [88, 1, 1, "", "half"], [88, 3, 1, "", "input_spec"], [88, 1, 1, "", "ipu"], [88, 1, 1, "", "load_state_dict"], [88, 1, 1, "", "modules"], [88, 1, 1, "", "named_buffers"], [88, 1, 1, "", "named_children"], [88, 1, 1, "", "named_modules"], [88, 1, 1, "", "named_parameters"], [88, 3, 1, "", "observation_spec"], [88, 3, 1, "", "output_spec"], [88, 1, 1, "", "parameters"], [88, 1, 1, "", "rand_action"], [88, 1, 1, "", "rand_step"], [88, 1, 1, "", "read_action"], [88, 1, 1, "", "read_done"], [88, 1, 1, "", "read_obs"], [88, 1, 1, "", "read_reward"], [88, 1, 1, "", "register_backward_hook"], [88, 1, 1, "", "register_buffer"], [88, 1, 1, "", "register_forward_hook"], [88, 1, 1, "", "register_forward_pre_hook"], [88, 1, 1, "", "register_full_backward_hook"], [88, 1, 1, "", "register_full_backward_pre_hook"], [88, 1, 1, "", "register_gym"], [88, 1, 1, "", "register_load_state_dict_post_hook"], [88, 1, 1, "", "register_module"], [88, 1, 1, "", "register_parameter"], [88, 1, 1, "", "register_state_dict_pre_hook"], [88, 1, 1, "", "requires_grad_"], [88, 1, 1, "", "reset"], [88, 3, 1, "", "reset_keys"], [88, 3, 1, "", "reward_key"], [88, 3, 1, "", "reward_keys"], [88, 3, 1, "", "reward_spec"], [88, 1, 1, "", "rollout"], [88, 1, 1, "", "set_extra_state"], [88, 1, 1, "", "set_info_dict_reader"], [88, 1, 1, "", "set_seed"], [88, 1, 1, "", "share_memory"], [88, 3, 1, "", "specs"], [88, 1, 1, "", "state_dict"], [88, 3, 1, "", "state_spec"], [88, 1, 1, "", "step"], [88, 1, 1, "", "step_and_maybe_reset"], [88, 1, 1, "", "to"], [88, 1, 1, "", "to_empty"], [88, 1, 1, "", "train"], [88, 1, 1, "", "type"], [88, 1, 1, "", "xpu"], [88, 1, 1, "", "zero_grad"]], "torchrl.envs.ParallelEnv": [[102, 3, 1, "", "action_key"], [102, 3, 1, "", "action_keys"], [102, 3, 1, "", "action_spec"], [102, 1, 1, "", "add_module"], [102, 1, 1, "", "apply"], [102, 3, 1, "", "batch_locked"], [102, 1, 1, "", "bfloat16"], [102, 1, 1, "", "buffers"], [102, 1, 1, "", "children"], [102, 1, 1, "", "compile"], [102, 1, 1, "", "cpu"], [102, 1, 1, "", "cuda"], [102, 3, 1, "", "done_key"], [102, 3, 1, "", "done_keys"], [102, 3, 1, "", "done_keys_groups"], [102, 3, 1, "", "done_spec"], [102, 1, 1, "", "double"], [102, 1, 1, "", "empty_cache"], [102, 1, 1, "", "eval"], [102, 1, 1, "", "extra_repr"], [102, 1, 1, "", "fake_tensordict"], [102, 1, 1, "", "float"], [102, 1, 1, "", "forward"], [102, 3, 1, "", "full_action_spec"], [102, 3, 1, "", "full_done_spec"], [102, 3, 1, "", "full_reward_spec"], [102, 3, 1, "", "full_state_spec"], [102, 1, 1, "", "get_buffer"], [102, 1, 1, "", "get_extra_state"], [102, 1, 1, "", "get_parameter"], [102, 1, 1, "", "get_submodule"], [102, 1, 1, "", "half"], [102, 3, 1, "", "input_spec"], [102, 1, 1, "", "ipu"], [102, 1, 1, "", "load_state_dict"], [102, 1, 1, "", "modules"], [102, 1, 1, "", "named_buffers"], [102, 1, 1, "", "named_children"], [102, 1, 1, "", "named_modules"], [102, 1, 1, "", "named_parameters"], [102, 3, 1, "", "observation_spec"], [102, 3, 1, "", "output_spec"], [102, 1, 1, "", "parameters"], [102, 1, 1, "", "rand_action"], [102, 1, 1, "", "rand_step"], [102, 1, 1, "", "register_backward_hook"], [102, 1, 1, "", "register_buffer"], [102, 1, 1, "", "register_forward_hook"], [102, 1, 1, "", "register_forward_pre_hook"], [102, 1, 1, "", "register_full_backward_hook"], [102, 1, 1, "", "register_full_backward_pre_hook"], [102, 1, 1, "", "register_gym"], [102, 1, 1, "", "register_load_state_dict_post_hook"], [102, 1, 1, "", "register_module"], [102, 1, 1, "", "register_parameter"], [102, 1, 1, "", "register_state_dict_pre_hook"], [102, 1, 1, "", "requires_grad_"], [102, 1, 1, "", "reset"], [102, 3, 1, "", "reset_keys"], [102, 3, 1, "", "reward_key"], [102, 3, 1, "", "reward_keys"], [102, 3, 1, "", "reward_spec"], [102, 1, 1, "", "rollout"], [102, 1, 1, "", "set_extra_state"], [102, 1, 1, "", "set_seed"], [102, 1, 1, "", "share_memory"], [102, 3, 1, "", "specs"], [102, 1, 1, "", "state_dict"], [102, 3, 1, "", "state_spec"], [102, 1, 1, "", "step"], [102, 1, 1, "", "step_and_maybe_reset"], [102, 1, 1, "", "to"], [102, 1, 1, "", "to_empty"], [102, 1, 1, "", "train"], [102, 1, 1, "", "type"], [102, 1, 1, "", "update_kwargs"], [102, 1, 1, "", "xpu"], [102, 1, 1, "", "zero_grad"]], "torchrl.envs.SerialEnv": [[108, 3, 1, "", "action_key"], [108, 3, 1, "", "action_keys"], [108, 3, 1, "", "action_spec"], [108, 1, 1, "", "add_module"], [108, 1, 1, "", "apply"], [108, 3, 1, "", "batch_locked"], [108, 1, 1, "", "bfloat16"], [108, 1, 1, "", "buffers"], [108, 1, 1, "", "children"], [108, 1, 1, "", "compile"], [108, 1, 1, "", "cpu"], [108, 1, 1, "", "cuda"], [108, 3, 1, "", "done_key"], [108, 3, 1, "", "done_keys"], [108, 3, 1, "", "done_keys_groups"], [108, 3, 1, "", "done_spec"], [108, 1, 1, "", "double"], [108, 1, 1, "", "empty_cache"], [108, 1, 1, "", "eval"], [108, 1, 1, "", "extra_repr"], [108, 1, 1, "", "fake_tensordict"], [108, 1, 1, "", "float"], [108, 1, 1, "", "forward"], [108, 3, 1, "", "full_action_spec"], [108, 3, 1, "", "full_done_spec"], [108, 3, 1, "", "full_reward_spec"], [108, 3, 1, "", "full_state_spec"], [108, 1, 1, "", "get_buffer"], [108, 1, 1, "", "get_extra_state"], [108, 1, 1, "", "get_parameter"], [108, 1, 1, "", "get_submodule"], [108, 1, 1, "", "half"], [108, 3, 1, "", "input_spec"], [108, 1, 1, "", "ipu"], [108, 1, 1, "", "load_state_dict"], [108, 1, 1, "", "modules"], [108, 1, 1, "", "named_buffers"], [108, 1, 1, "", "named_children"], [108, 1, 1, "", "named_modules"], [108, 1, 1, "", "named_parameters"], [108, 3, 1, "", "observation_spec"], [108, 3, 1, "", "output_spec"], [108, 1, 1, "", "parameters"], [108, 1, 1, "", "rand_action"], [108, 1, 1, "", "rand_step"], [108, 1, 1, "", "register_backward_hook"], [108, 1, 1, "", "register_buffer"], [108, 1, 1, "", "register_forward_hook"], [108, 1, 1, "", "register_forward_pre_hook"], [108, 1, 1, "", "register_full_backward_hook"], [108, 1, 1, "", "register_full_backward_pre_hook"], [108, 1, 1, "", "register_gym"], [108, 1, 1, "", "register_load_state_dict_post_hook"], [108, 1, 1, "", "register_module"], [108, 1, 1, "", "register_parameter"], [108, 1, 1, "", "register_state_dict_pre_hook"], [108, 1, 1, "", "requires_grad_"], [108, 1, 1, "", "reset"], [108, 3, 1, "", "reset_keys"], [108, 3, 1, "", "reward_key"], [108, 3, 1, "", "reward_keys"], [108, 3, 1, "", "reward_spec"], [108, 1, 1, "", "rollout"], [108, 1, 1, "", "set_extra_state"], [108, 1, 1, "", "set_seed"], [108, 1, 1, "", "share_memory"], [108, 3, 1, "", "specs"], [108, 1, 1, "", "state_dict"], [108, 3, 1, "", "state_spec"], [108, 1, 1, "", "step"], [108, 1, 1, "", "step_and_maybe_reset"], [108, 1, 1, "", "to"], [108, 1, 1, "", "to_empty"], [108, 1, 1, "", "train"], [108, 1, 1, "", "type"], [108, 1, 1, "", "update_kwargs"], [108, 1, 1, "", "xpu"], [108, 1, 1, "", "zero_grad"]], "torchrl.envs.model_based.dreamer": [[113, 2, 1, "", "DreamerEnv"]], "torchrl.envs.transforms": [[115, 0, 1, "", "ActionMask"], [116, 0, 1, "", "BinarizeReward"], [117, 0, 1, "", "BurnInTransform"], [118, 0, 1, "", "CatFrames"], [119, 0, 1, "", "CatTensors"], [120, 0, 1, "", "CenterCrop"], [121, 0, 1, "", "ClipTransform"], [122, 0, 1, "", "Compose"], [123, 0, 1, "", "DTypeCastTransform"], [124, 0, 1, "", "DeviceCastTransform"], [125, 0, 1, "", "DiscreteActionProjection"], [126, 0, 1, "", "DoubleToFloat"], [127, 0, 1, "", "EndOfLifeTransform"], [128, 0, 1, "", "ExcludeTransform"], [129, 0, 1, "", "FiniteTensorDictCheck"], [130, 0, 1, "", "FlattenObservation"], [131, 0, 1, "", "FrameSkipTransform"], [132, 0, 1, "", "GrayScale"], [133, 0, 1, "", "InitTracker"], [134, 0, 1, "", "KLRewardTransform"], [135, 0, 1, "", "NoopResetEnv"], [136, 0, 1, "", "ObservationNorm"], [137, 0, 1, "", "ObservationTransform"], [138, 0, 1, "", "PermuteTransform"], [139, 0, 1, "", "PinMemoryTransform"], [140, 0, 1, "", "R3MTransform"], [141, 0, 1, "", "RandomCropTensorDict"], [142, 0, 1, "", "RemoveEmptySpecs"], [143, 0, 1, "", "RenameTransform"], [144, 0, 1, "", "Resize"], [145, 0, 1, "", "Reward2GoTransform"], [146, 0, 1, "", "RewardClipping"], [147, 0, 1, "", "RewardScaling"], [148, 0, 1, "", "RewardSum"], [149, 0, 1, "", "SelectTransform"], [150, 0, 1, "", "SignTransform"], [151, 0, 1, "", "SqueezeTransform"], [152, 0, 1, "", "StepCounter"], [153, 0, 1, "", "TargetReturn"], [154, 0, 1, "", "TensorDictPrimer"], [155, 0, 1, "", "TimeMaxPool"], [156, 0, 1, "", "ToTensorImage"], [157, 0, 1, "", "Transform"], [158, 0, 1, "", "TransformedEnv"], [159, 0, 1, "", "UnsqueezeTransform"], [160, 0, 1, "", "VC1Transform"], [161, 0, 1, "", "VIPRewardTransform"], [162, 0, 1, "", "VIPTransform"], [163, 0, 1, "", "VecGymEnvTransform"], [164, 0, 1, "", "VecNorm"], [165, 0, 1, "", "gSDENoise"]], "torchrl.envs.transforms.ActionMask": [[115, 1, 1, "", "forward"]], "torchrl.envs.transforms.BinarizeReward": [[116, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.BurnInTransform": [[117, 1, 1, "", "forward"]], "torchrl.envs.transforms.CatFrames": [[118, 1, 1, "", "forward"], [118, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.CatTensors": [[119, 1, 1, "", "forward"], [119, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.CenterCrop": [[120, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ClipTransform": [[121, 1, 1, "", "transform_observation_spec"], [121, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.Compose": [[122, 1, 1, "", "forward"], [122, 1, 1, "", "to"], [122, 1, 1, "", "transform_env_device"], [122, 1, 1, "", "transform_input_spec"], [122, 1, 1, "", "transform_observation_spec"], [122, 1, 1, "", "transform_output_spec"], [122, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.DTypeCastTransform": [[123, 1, 1, "", "forward"], [123, 1, 1, "", "transform_input_spec"], [123, 1, 1, "", "transform_observation_spec"], [123, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.DeviceCastTransform": [[124, 1, 1, "", "forward"], [124, 1, 1, "", "transform_done_spec"], [124, 1, 1, "", "transform_env_device"], [124, 1, 1, "", "transform_input_spec"], [124, 1, 1, "", "transform_observation_spec"], [124, 1, 1, "", "transform_output_spec"], [124, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.DiscreteActionProjection": [[125, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.EndOfLifeTransform": [[127, 1, 1, "", "forward"], [127, 1, 1, "", "register_keys"], [127, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ExcludeTransform": [[128, 1, 1, "", "forward"], [128, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.FiniteTensorDictCheck": [[129, 1, 1, "", "forward"]], "torchrl.envs.transforms.FlattenObservation": [[130, 1, 1, "", "forward"], [130, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.FrameSkipTransform": [[131, 1, 1, "", "forward"]], "torchrl.envs.transforms.GrayScale": [[132, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.InitTracker": [[133, 1, 1, "", "forward"], [133, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.KLRewardTransform": [[134, 1, 1, "", "forward"], [134, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.ObservationNorm": [[136, 1, 1, "", "init_stats"], [136, 1, 1, "", "transform_input_spec"], [136, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.PermuteTransform": [[138, 1, 1, "", "transform_input_spec"], [138, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.PinMemoryTransform": [[139, 1, 1, "", "forward"]], "torchrl.envs.transforms.R3MTransform": [[140, 1, 1, "", "to"]], "torchrl.envs.transforms.RandomCropTensorDict": [[141, 1, 1, "", "forward"]], "torchrl.envs.transforms.RemoveEmptySpecs": [[142, 1, 1, "", "forward"], [142, 1, 1, "", "transform_input_spec"], [142, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.RenameTransform": [[143, 1, 1, "", "forward"], [143, 1, 1, "", "transform_input_spec"], [143, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.Resize": [[144, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Reward2GoTransform": [[145, 1, 1, "", "forward"]], "torchrl.envs.transforms.RewardClipping": [[146, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.RewardScaling": [[147, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.RewardSum": [[148, 1, 1, "", "forward"], [148, 1, 1, "", "transform_input_spec"], [148, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.SelectTransform": [[149, 1, 1, "", "forward"], [149, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.SignTransform": [[150, 1, 1, "", "transform_observation_spec"], [150, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.StepCounter": [[152, 1, 1, "", "forward"], [152, 1, 1, "", "transform_input_spec"], [152, 1, 1, "", "transform_observation_spec"], [152, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.TargetReturn": [[153, 1, 1, "", "forward"], [153, 1, 1, "", "transform_input_spec"], [153, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.TensorDictPrimer": [[154, 1, 1, "", "forward"], [154, 1, 1, "", "to"], [154, 1, 1, "", "transform_input_spec"], [154, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.TimeMaxPool": [[155, 1, 1, "", "forward"], [155, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ToTensorImage": [[156, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Transform": [[157, 3, 1, "", "container"], [157, 1, 1, "", "forward"], [157, 3, 1, "", "parent"], [157, 1, 1, "", "to"], [157, 1, 1, "", "transform_done_spec"], [157, 1, 1, "", "transform_env_device"], [157, 1, 1, "", "transform_input_spec"], [157, 1, 1, "", "transform_observation_spec"], [157, 1, 1, "", "transform_output_spec"], [157, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.TransformedEnv": [[158, 3, 1, "", "batch_locked"], [158, 1, 1, "", "empty_cache"], [158, 1, 1, "", "eval"], [158, 3, 1, "", "input_spec"], [158, 1, 1, "", "load_state_dict"], [158, 3, 1, "", "output_spec"], [158, 1, 1, "", "set_missing_tolerance"], [158, 1, 1, "", "set_seed"], [158, 1, 1, "", "state_dict"], [158, 1, 1, "", "to"], [158, 1, 1, "", "train"]], "torchrl.envs.transforms.UnsqueezeTransform": [[159, 1, 1, "", "transform_input_spec"], [159, 1, 1, "", "transform_observation_spec"], [159, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.VC1Transform": [[160, 1, 1, "", "forward"], [160, 1, 1, "", "make_noload_model"], [160, 1, 1, "", "to"], [160, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.VIPRewardTransform": [[161, 1, 1, "", "forward"], [161, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.VIPTransform": [[162, 1, 1, "", "to"]], "torchrl.envs.transforms.VecGymEnvTransform": [[163, 1, 1, "", "forward"], [163, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.VecNorm": [[164, 1, 1, "", "build_td_for_shared_vecnorm"], [164, 1, 1, "", "forward"], [164, 1, 1, "", "get_extra_state"], [164, 1, 1, "", "set_extra_state"], [164, 1, 1, "", "to_observation_norm"]], "torchrl.envs.utils": [[166, 2, 1, "", "check_env_specs"], [167, 2, 1, "", "exploration_mode"], [168, 2, 1, "", "exploration_type"], [169, 2, 1, "", "get_available_libraries"], [170, 2, 1, "", "make_composite_from_td"], [171, 2, 1, "", "set_exploration_mode"], [172, 2, 1, "", "set_exploration_type"], [173, 2, 1, "", "step_mdp"], [174, 2, 1, "", "terminated_or_truncated"]], "torchrl.modules": [[175, 0, 1, "", "CEMPlanner"], [176, 0, 1, "", "Conv3dNet"], [177, 0, 1, "", "ConvNet"], [178, 0, 1, "", "DTActor"], [179, 0, 1, "", "DdpgCnnActor"], [180, 0, 1, "", "DdpgCnnQNet"], [181, 0, 1, "", "DdpgMlpActor"], [182, 0, 1, "", "DdpgMlpQNet"], [183, 0, 1, "", "DecisionTransformer"], [184, 0, 1, "", "Delta"], [185, 0, 1, "", "DistributionalDQNnet"], [186, 0, 1, "", "DistributionalQValueHook"], [187, 0, 1, "", "DreamerActor"], [188, 0, 1, "", "DuelingCnnDQNet"], [189, 0, 1, "", "GRU"], [190, 0, 1, "", "GRUCell"], [191, 0, 1, "", "GRUModule"], [192, 0, 1, "", "IndependentNormal"], [193, 0, 1, "", "LSTM"], [194, 0, 1, "", "LSTMCell"], [195, 0, 1, "", "LSTMModule"], [196, 0, 1, "", "LSTMNet"], [197, 0, 1, "", "MLP"], [198, 0, 1, "", "MPCPlannerBase"], [199, 0, 1, "", "MPPIPlanner"], [200, 0, 1, "", "MaskedCategorical"], [201, 0, 1, "", "MaskedOneHotCategorical"], [202, 0, 1, "", "MultiAgentConvNet"], [203, 0, 1, "", "MultiAgentMLP"], [204, 0, 1, "", "NoisyLazyLinear"], [205, 0, 1, "", "NoisyLinear"], [206, 0, 1, "", "NormalParamWrapper"], [207, 0, 1, "", "ObsDecoder"], [208, 0, 1, "", "ObsEncoder"], [209, 0, 1, "", "OneHotCategorical"], [210, 0, 1, "", "OnlineDTActor"], [211, 0, 1, "", "QMixer"], [212, 0, 1, "", "QValueHook"], [213, 0, 1, "", "RSSMPosterior"], [214, 0, 1, "", "RSSMPrior"], [215, 0, 1, "", "Squeeze2dLayer"], [216, 0, 1, "", "SqueezeLayer"], [217, 0, 1, "", "TanhDelta"], [218, 0, 1, "", "TanhNormal"], [219, 0, 1, "", "TruncatedNormal"], [220, 0, 1, "", "VDNMixer"], [221, 0, 1, "", "VmapModule"], [222, 0, 1, "", "reset_noise"]], "torchrl.modules.CEMPlanner": [[175, 1, 1, "", "planning"]], "torchrl.modules.Conv3dNet": [[176, 1, 1, "", "forward"]], "torchrl.modules.ConvNet": [[177, 1, 1, "", "forward"]], "torchrl.modules.DTActor": [[178, 1, 1, "", "default_config"], [178, 1, 1, "", "forward"]], "torchrl.modules.DdpgCnnActor": [[179, 1, 1, "", "forward"]], "torchrl.modules.DdpgCnnQNet": [[180, 1, 1, "", "forward"]], "torchrl.modules.DdpgMlpActor": [[181, 1, 1, "", "forward"]], "torchrl.modules.DdpgMlpQNet": [[182, 1, 1, "", "forward"]], "torchrl.modules.DecisionTransformer": [[183, 0, 1, "", "DTConfig"], [183, 1, 1, "", "forward"]], "torchrl.modules.Delta": [[184, 1, 1, "", "log_prob"], [184, 3, 1, "", "mean"], [184, 3, 1, "", "mode"], [184, 1, 1, "", "rsample"], [184, 1, 1, "", "sample"]], "torchrl.modules.DistributionalDQNnet": [[185, 1, 1, "", "forward"]], "torchrl.modules.DreamerActor": [[187, 1, 1, "", "forward"]], "torchrl.modules.DuelingCnnDQNet": [[188, 1, 1, "", "forward"]], "torchrl.modules.GRU": [[189, 1, 1, "", "forward"]], "torchrl.modules.GRUCell": [[190, 1, 1, "", "forward"]], "torchrl.modules.GRUModule": [[191, 1, 1, "", "forward"], [191, 1, 1, "id0", "set_recurrent_mode"]], "torchrl.modules.IndependentNormal": [[192, 3, 1, "", "mode"]], "torchrl.modules.LSTM": [[193, 1, 1, "", "forward"]], "torchrl.modules.LSTMCell": [[194, 1, 1, "", "forward"]], "torchrl.modules.LSTMModule": [[195, 1, 1, "", "forward"], [195, 1, 1, "id0", "set_recurrent_mode"]], "torchrl.modules.LSTMNet": [[196, 1, 1, "", "forward"]], "torchrl.modules.MLP": [[197, 1, 1, "", "forward"]], "torchrl.modules.MPCPlannerBase": [[198, 1, 1, "", "forward"], [198, 1, 1, "", "planning"]], "torchrl.modules.MPPIPlanner": [[199, 1, 1, "", "planning"]], "torchrl.modules.MaskedCategorical": [[200, 1, 1, "", "log_prob"], [200, 1, 1, "", "sample"]], "torchrl.modules.MaskedOneHotCategorical": [[201, 1, 1, "", "log_prob"], [201, 1, 1, "", "rsample"], [201, 1, 1, "", "sample"]], "torchrl.modules.MultiAgentConvNet": [[202, 1, 1, "", "forward"]], "torchrl.modules.MultiAgentMLP": [[203, 1, 1, "", "forward"]], "torchrl.modules.NoisyLazyLinear": [[204, 1, 1, "", "initialize_parameters"]], "torchrl.modules.NormalParamWrapper": [[206, 1, 1, "", "forward"]], "torchrl.modules.ObsDecoder": [[207, 1, 1, "", "forward"]], "torchrl.modules.ObsEncoder": [[208, 1, 1, "", "forward"]], "torchrl.modules.OneHotCategorical": [[209, 1, 1, "", "log_prob"], [209, 3, 1, "", "mode"], [209, 1, 1, "", "rsample"], [209, 1, 1, "", "sample"]], "torchrl.modules.OnlineDTActor": [[210, 1, 1, "", "default_config"], [210, 1, 1, "", "forward"]], "torchrl.modules.QMixer": [[211, 1, 1, "", "mix"]], "torchrl.modules.RSSMPosterior": [[213, 1, 1, "", "forward"]], "torchrl.modules.RSSMPrior": [[214, 1, 1, "", "forward"]], "torchrl.modules.SqueezeLayer": [[216, 1, 1, "", "forward"]], "torchrl.modules.TanhDelta": [[217, 3, 1, "", "mean"], [217, 3, 1, "", "mode"]], "torchrl.modules.TanhNormal": [[218, 3, 1, "", "mode"]], "torchrl.modules.TruncatedNormal": [[219, 1, 1, "", "log_prob"], [219, 3, 1, "", "mode"]], "torchrl.modules.VDNMixer": [[220, 1, 1, "", "mix"]], "torchrl.modules.VmapModule": [[221, 1, 1, "", "forward"]], "torchrl.modules.tensordict_module": [[223, 0, 1, "", "Actor"], [224, 0, 1, "", "ActorCriticOperator"], [225, 0, 1, "", "ActorCriticWrapper"], [226, 0, 1, "", "ActorValueOperator"], [227, 0, 1, "", "AdditiveGaussianWrapper"], [228, 0, 1, "", "DecisionTransformerInferenceWrapper"], [229, 0, 1, "", "DistributionalQValueActor"], [230, 0, 1, "", "DistributionalQValueModule"], [231, 0, 1, "", "EGreedyModule"], [232, 0, 1, "", "EGreedyWrapper"], [233, 0, 1, "", "LMHeadActorValueOperator"], [234, 0, 1, "", "OrnsteinUhlenbeckProcessWrapper"], [235, 0, 1, "", "ProbabilisticActor"], [236, 0, 1, "", "QValueActor"], [237, 0, 1, "", "QValueModule"], [238, 0, 1, "", "SafeModule"], [239, 0, 1, "", "SafeProbabilisticModule"], [240, 0, 1, "", "SafeProbabilisticTensorDictSequential"], [241, 0, 1, "", "SafeSequential"], [242, 0, 1, "", "TanhModule"], [243, 0, 1, "", "ValueOperator"], [244, 0, 1, "", "WorldModelWrapper"]], "torchrl.modules.tensordict_module.ActorCriticOperator": [[224, 1, 1, "", "get_critic_operator"], [224, 1, 1, "", "get_policy_head"], [224, 1, 1, "", "get_value_head"], [224, 1, 1, "", "get_value_operator"]], "torchrl.modules.tensordict_module.ActorCriticWrapper": [[225, 1, 1, "", "get_policy_head"], [225, 1, 1, "", "get_policy_operator"], [225, 1, 1, "", "get_value_head"], [225, 1, 1, "", "get_value_operator"]], "torchrl.modules.tensordict_module.ActorValueOperator": [[226, 1, 1, "", "get_policy_head"], [226, 1, 1, "", "get_policy_operator"], [226, 1, 1, "", "get_value_head"], [226, 1, 1, "", "get_value_operator"]], "torchrl.modules.tensordict_module.AdditiveGaussianWrapper": [[227, 1, 1, "", "forward"], [227, 1, 1, "", "step"]], "torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper": [[228, 1, 1, "", "forward"], [228, 1, 1, "", "mask_context"], [228, 1, 1, "", "set_tensor_keys"]], "torchrl.modules.tensordict_module.DistributionalQValueModule": [[230, 1, 1, "", "forward"]], "torchrl.modules.tensordict_module.EGreedyModule": [[231, 1, 1, "", "forward"], [231, 1, 1, "", "step"]], "torchrl.modules.tensordict_module.EGreedyWrapper": [[232, 1, 1, "", "forward"], [232, 1, 1, "", "step"]], "torchrl.modules.tensordict_module.OrnsteinUhlenbeckProcessWrapper": [[234, 1, 1, "", "forward"], [234, 1, 1, "", "step"]], "torchrl.modules.tensordict_module.QValueModule": [[237, 1, 1, "", "forward"]], "torchrl.modules.tensordict_module.SafeModule": [[238, 1, 1, "", "random"], [238, 1, 1, "", "random_sample"], [238, 1, 1, "", "to"]], "torchrl.modules.tensordict_module.SafeProbabilisticModule": [[239, 1, 1, "", "random"], [239, 1, 1, "", "random_sample"]], "torchrl.modules.tensordict_module.TanhModule": [[242, 1, 1, "", "forward"]], "torchrl.modules.tensordict_module.WorldModelWrapper": [[244, 1, 1, "", "get_reward_operator"], [244, 1, 1, "", "get_transition_model_operator"]], "torchrl.modules.utils": [[245, 0, 1, "", "biased_softplus"], [246, 0, 1, "", "inv_softplus"], [247, 0, 1, "", "mappings"]], "torchrl.modules.utils.biased_softplus": [[245, 1, 1, "", "forward"]], "torchrl.objectives": [[248, 0, 1, "", "A2CLoss"], [249, 0, 1, "", "CQLLoss"], [250, 0, 1, "", "ClipPPOLoss"], [251, 0, 1, "", "DDPGLoss"], [252, 0, 1, "", "DQNLoss"], [253, 0, 1, "", "DTLoss"], [254, 0, 1, "", "DiscreteCQLLoss"], [255, 0, 1, "", "DiscreteIQLLoss"], [256, 0, 1, "", "DiscreteSACLoss"], [257, 0, 1, "", "DistributionalDQNLoss"], [258, 0, 1, "", "DreamerActorLoss"], [259, 0, 1, "", "DreamerModelLoss"], [260, 0, 1, "", "DreamerValueLoss"], [261, 0, 1, "", "HardUpdate"], [262, 0, 1, "", "IQLLoss"], [263, 0, 1, "", "KLPENPPOLoss"], [264, 0, 1, "", "LossModule"], [265, 0, 1, "", "OnlineDTLoss"], [266, 0, 1, "", "PPOLoss"], [267, 0, 1, "", "REDQLoss"], [268, 0, 1, "", "ReinforceLoss"], [269, 0, 1, "", "SACLoss"], [270, 0, 1, "", "SoftUpdate"], [271, 0, 1, "", "TD3Loss"], [272, 0, 1, "", "ValueEstimators"], [273, 0, 1, "", "default_value_kwargs"], [274, 0, 1, "", "distance_loss"], [275, 0, 1, "", "hold_out_net"], [276, 0, 1, "", "hold_out_params"], [278, 0, 1, "", "next_state_value"]], "torchrl.objectives.A2CLoss": [[248, 1, 1, "", "forward"], [248, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.CQLLoss": [[249, 1, 1, "", "forward"], [249, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.ClipPPOLoss": [[250, 1, 1, "", "forward"]], "torchrl.objectives.DDPGLoss": [[251, 1, 1, "", "forward"], [251, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DQNLoss": [[252, 1, 1, "", "forward"], [252, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DTLoss": [[253, 1, 1, "", "forward"]], "torchrl.objectives.DiscreteCQLLoss": [[254, 1, 1, "", "forward"], [254, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DiscreteSACLoss": [[256, 1, 1, "", "forward"], [256, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DistributionalDQNLoss": [[257, 1, 1, "", "forward"], [257, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DreamerActorLoss": [[258, 1, 1, "", "forward"], [258, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DreamerModelLoss": [[259, 1, 1, "", "forward"]], "torchrl.objectives.DreamerValueLoss": [[260, 1, 1, "", "forward"]], "torchrl.objectives.IQLLoss": [[262, 1, 1, "", "forward"], [262, 1, 1, "", "loss_value_diff"], [262, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.KLPENPPOLoss": [[263, 1, 1, "", "forward"]], "torchrl.objectives.LossModule": [[264, 1, 1, "", "convert_to_functional"], [264, 1, 1, "", "forward"], [264, 1, 1, "", "make_value_estimator"], [264, 1, 1, "", "named_parameters"], [264, 1, 1, "", "parameters"], [264, 1, 1, "", "set_keys"], [264, 3, 1, "", "value_estimator"]], "torchrl.objectives.OnlineDTLoss": [[265, 1, 1, "", "forward"]], "torchrl.objectives.PPOLoss": [[266, 1, 1, "", "forward"], [266, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.REDQLoss": [[267, 1, 1, "", "forward"], [267, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.ReinforceLoss": [[268, 1, 1, "", "forward"], [268, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.SACLoss": [[269, 1, 1, "", "forward"], [269, 1, 1, "", "load_state_dict"], [269, 1, 1, "", "make_value_estimator"], [269, 1, 1, "", "state_dict"]], "torchrl.objectives.TD3Loss": [[271, 1, 1, "", "forward"], [271, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.multiagent": [[277, 0, 1, "", "QMixerLoss"]], "torchrl.objectives.multiagent.QMixerLoss": [[277, 1, 1, "", "forward"], [277, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.value": [[279, 0, 1, "", "GAE"], [280, 0, 1, "", "TD0Estimator"], [281, 0, 1, "", "TD1Estimator"], [282, 0, 1, "", "TDLambdaEstimator"], [283, 0, 1, "", "ValueEstimatorBase"]], "torchrl.objectives.value.GAE": [[279, 1, 1, "", "forward"], [279, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TD0Estimator": [[280, 1, 1, "", "forward"], [280, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TD1Estimator": [[281, 1, 1, "", "forward"], [281, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TDLambdaEstimator": [[282, 1, 1, "", "forward"], [282, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.ValueEstimatorBase": [[283, 1, 1, "", "forward"], [283, 1, 1, "", "set_keys"], [283, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.functional": [[284, 0, 1, "", "generalized_advantage_estimate"], [285, 0, 1, "", "reward2go"], [286, 0, 1, "", "td0_advantage_estimate"], [287, 0, 1, "", "td0_return_estimate"], [288, 0, 1, "", "td1_advantage_estimate"], [289, 0, 1, "", "td1_return_estimate"], [290, 0, 1, "", "td_lambda_advantage_estimate"], [291, 0, 1, "", "td_lambda_return_estimate"], [292, 0, 1, "", "vec_generalized_advantage_estimate"], [293, 0, 1, "", "vec_td1_advantage_estimate"], [294, 0, 1, "", "vec_td1_return_estimate"], [295, 0, 1, "", "vec_td_lambda_advantage_estimate"], [296, 0, 1, "", "vec_td_lambda_return_estimate"]], "torchrl.record": [[297, 2, 1, "", "TensorDictRecorder"], [298, 2, 1, "", "VideoRecorder"]], "torchrl.record.loggers": [[299, 2, 1, "", "Logger"], [301, 2, 1, "", "generate_exp_name"], [302, 2, 1, "", "get_logger"]], "torchrl.record.loggers.csv": [[300, 2, 1, "", "CSVLogger"]], "torchrl.record.loggers.mlflow": [[303, 2, 1, "", "MLFlowLogger"]], "torchrl.record.loggers.tensorboard": [[304, 2, 1, "", "TensorboardLogger"]], "torchrl.record.loggers.wandb": [[305, 2, 1, "", "WandbLogger"]], "torchrl.trainers": [[306, 0, 1, "", "BatchSubSampler"], [307, 0, 1, "", "ClearCudaCache"], [308, 0, 1, "", "CountFramesLog"], [309, 0, 1, "", "LogReward"], [310, 0, 1, "", "OptimizerHook"], [311, 0, 1, "", "Recorder"], [312, 0, 1, "", "ReplayBufferTrainer"], [313, 0, 1, "", "RewardNormalizer"], [314, 0, 1, "", "SelectKeys"], [315, 0, 1, "", "Trainer"], [316, 0, 1, "", "TrainerHookBase"], [317, 0, 1, "", "UpdateWeights"]], "torchrl.trainers.BatchSubSampler": [[306, 1, 1, "", "register"]], "torchrl.trainers.ClearCudaCache": [[307, 1, 1, "", "register"]], "torchrl.trainers.CountFramesLog": [[308, 1, 1, "", "register"]], "torchrl.trainers.LogReward": [[309, 1, 1, "", "register"]], "torchrl.trainers.OptimizerHook": [[310, 1, 1, "", "register"]], "torchrl.trainers.Recorder": [[311, 1, 1, "", "register"]], "torchrl.trainers.ReplayBufferTrainer": [[312, 1, 1, "", "register"]], "torchrl.trainers.RewardNormalizer": [[313, 1, 1, "", "register"]], "torchrl.trainers.SelectKeys": [[314, 1, 1, "", "register"]], "torchrl.trainers.TrainerHookBase": [[316, 1, 1, "", "register"]], "torchrl.trainers.UpdateWeights": [[317, 1, 1, "", "register"]], "torchrl.trainers.helpers": [[318, 2, 1, "", "correct_for_frame_skip"], [319, 2, 1, "", "get_stats_random_rollout"], [320, 2, 1, "", "make_collector_offpolicy"], [321, 2, 1, "", "make_collector_onpolicy"], [322, 2, 1, "", "make_dqn_loss"], [323, 2, 1, "", "make_redq_loss"], [324, 2, 1, "", "make_redq_model"], [325, 2, 1, "", "make_replay_buffer"], [326, 2, 1, "", "make_target_updater"], [327, 2, 1, "", "make_trainer"], [328, 2, 1, "", "parallel_env_constructor"], [329, 2, 1, "", "sync_async_collector"], [330, 2, 1, "", "sync_sync_collector"], [331, 2, 1, "", "transformed_env_constructor"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"]}, "titleterms": {"torchrl": [0, 1, 2, 3, 6, 9, 335, 336, 337, 338, 340, 341, 342, 346, 347, 351, 352], "tutori": [0, 342, 346], "basic": [0, 349], "intermedi": [0, 8], "advanc": 0, "refer": [0, 333], "knowledg": [0, 334], "base": [0, 7, 334], "indic": 0, "tabl": 0, "collector": [1, 340, 341, 342, 343, 346, 351], "packag": [1, 2, 3, 335, 336, 337, 338], "singl": [1, 4], "node": 1, "data": [1, 2, 4, 340, 341, 342, 346, 351], "distribut": [1, 335], "helper": [1, 3], "function": [1, 4, 336, 341, 342, 346, 351], "replai": [2, 340, 341, 342, 343, 346, 349, 351], "buffer": [2, 340, 341, 342, 343, 346, 349, 351], "compos": [2, 122], "share": 2, "across": 2, "process": 2, "store": [2, 341], "trajectori": 2, "checkpoint": [2, 337], "dataset": 2, "tensorspec": [2, 44], "reinforc": [2, 336, 342, 346], "learn": [2, 4, 342, 346], "from": [2, 6, 7], "human": 2, "feedback": 2, "rlhf": 2, "util": [2, 335, 336, 337], "env": [3, 347, 351, 352], "vector": [3, 351], "multi": [3, 335, 336, 345, 346], "agent": [3, 4, 335, 336, 346], "environ": [3, 4, 6, 7, 340, 341, 342, 343, 345, 346, 347, 351, 352], "transform": [3, 157, 340, 342, 346, 347, 349, 351, 352], "clone": [3, 7], "mask": 3, "action": [3, 4, 343, 347], "record": [3, 311, 337, 340], "domain": [3, 335], "specif": [3, 335, 345], "librari": [3, 351], "thing": [4, 340, 347], "consid": 4, "when": [4, 7], "debug": 4, "rl": [4, 9, 351], "gener": [4, 335], "have": 4, "you": 4, "valid": 4, "your": [4, 6, 340, 347], "algorithm": [4, 335], "implement": 4, "few": 4, "small": 4, "toi": 4, "problem": 4, "known": 4, "optim": [4, 340, 341], "return": [4, 336], "e": 4, "g": 4, "gridworld": 4, "mountaincar": 4, "visual": 4, "Be": 4, "veri": 4, "care": 4, "ani": 4, "augment": 4, "polici": [4, 340, 342, 343, 345, 346, 347], "doe": 4, "entropi": 4, "converg": 4, "too": [4, 8], "quickli": 4, "slowli": 4, "chang": [4, 351], "drastic": 4, "reward": 4, "beyond": 4, "go": 4, "up": [4, 6], "Is": 4, "favor": 4, "compon": 4, "i": 4, "veloc": 4, "vs": 4, "l2": 4, "magnitud": 4, "task": [4, 345], "horizon": 4, "extrem": 4, "long": 4, "ar": 4, "normal": [4, 340, 341, 342], "standard": 4, "explor": [4, 335, 340, 341], "valu": [4, 335, 336, 340, 342, 343], "loss": [4, 340, 341, 342, 343, 346], "earli": 4, "train": [4, 8, 336, 340, 342, 343, 346, 347], "roughli": 4, "uniformli": 4, "random": [4, 346], "intrins": 4, "decai": 4, "progress": 4, "singleton": 4, "episod": 4, "remain": 4, "constant": [4, 341], "increas": 4, "an": [4, 342, 343, 347], "dynam": [4, 349], "can": 4, "low": 4, "forward": [4, 340], "model": [4, 335, 340, 341, 343, 348, 351], "also": 4, "us": [4, 6, 9, 343, 348, 349, 351], "offlin": 4, "observ": [4, 340], "space": 4, "effect": [4, 347], "dramat": 4, "dure": [4, 7], "high": 4, "dimension": 4, "work": [5, 6, 7], "gym": [5, 352], "what": 5, "openai": 5, "version": [5, 7, 10], "habitat": 6, "lab": 6, "set": 6, "instal": [6, 7, 351], "pip": [6, 7], "common": [6, 7, 8], "issu": [6, 7, 10], "mujoco": 7, "prerequisit": 7, "render": [7, 346, 352], "all": 7, "new": 7, "bindindg": 7, "2": 7, "1": 7, "old": 7, "bind": 7, "py": 7, "option": 7, "repo": [7, 9], "import": [7, 340], "pytorch": [8, 9, 10], "error": 8, "solut": 8, "gradient": 8, "relat": 8, "newcom": 8, "my": 8, "slow": 8, "bug": 8, "resourc": 9, "paper": 9, "document": 9, "functorch": 9, "blog": 9, "websit": 9, "educ": 9, "forum": 9, "how": 10, "reproduc": [10, 347], "workaround": 10, "implement_for": 11, "datacollectorbas": 12, "multisyncdatacollector": 13, "multiasyncdatacollector": 14, "randompolici": 15, "syncdatacollector": 16, "asyncdatacollector": 17, "distributeddatacollector": 18, "distributedsyncdatacollector": 19, "rpcdatacollector": 20, "raycollector": 21, "submitit_delayed_launch": 22, "split_trajectori": 23, "binarydiscretetensorspec": 24, "boundedtensorspec": 25, "compositespec": 26, "discretetensorspec": 27, "lazystackedcompositespec": 28, "lazystackedtensorspec": 29, "multidiscretetensorspec": 30, "multionehotdiscretetensorspec": 31, "multistep": 32, "onehotdiscretetensorspec": 33, "pairwisedataset": 34, "prioritizedreplaybuff": 35, "promptdata": 36, "prompttensordicttoken": 37, "replaybuff": 38, "rewarddata": 39, "rolloutfrommodel": 40, "tensordictprioritizedreplaybuff": 41, "tensordictreplaybuff": 42, "tensordicttoken": 43, "tokenizeddatasetload": 45, "unboundedcontinuoustensorspec": 46, "unboundeddiscretetensorspec": 47, "check_no_exclusive_kei": 48, "consolidate_spec": 49, "contains_lazy_spec": 50, "create_infinite_iter": 51, "d4rlexperiencereplai": 52, "gendgrlexperiencereplai": 53, "minariexperiencereplai": 54, "openmlexperiencereplai": 55, "openxexperiencereplai": 56, "robosetexperiencereplai": 57, "vd4rlexperiencereplai": 58, "get_dataload": 59, "immutabledatasetwrit": 60, "lazymemmapstorag": 61, "lazytensorstorag": 62, "liststorag": 63, "prioritizedsampl": 64, "randomsampl": 65, "replaybufferensembl": 66, "roundrobinwrit": 67, "sampler": 68, "samplerensembl": 69, "samplerwithoutreplac": 70, "slicesampl": 71, "slicesamplerwithoutreplac": 72, "storag": [73, 340, 349], "storageensembl": 74, "tensordictmaxvaluewrit": 75, "tensordictroundrobinwrit": 76, "tensorstorag": 77, "writer": 78, "writerensembl": 79, "braxenv": 80, "braxwrapp": 81, "dmcontrolenv": 82, "dmcontrolwrapp": 83, "envbas": [84, 347], "envcreat": 85, "envmetadata": 86, "gymenv": 87, "gymlikeenv": 88, "gymwrapp": 89, "habitatenv": 90, "isaacgymenv": 91, "isaacgymwrapp": 92, "jumanjienv": 93, "jumanjiwrapp": 94, "mogymenv": 95, "mogymwrapp": 96, "marlgroupmaptyp": 97, "modelbasedenvbas": 98, "multithreadedenv": 99, "multithreadedenvwrapp": 100, "openmlenv": 101, "parallelenv": 102, "pettingzooenv": 103, "pettingzoowrapp": 104, "robohiveenv": 105, "smacv2env": 106, "smacv2wrapp": 107, "serialenv": 108, "vmasenv": 109, "vmaswrapp": 110, "check_marl_group": 111, "gym_backend": 112, "dreamerenv": 113, "set_gym_backend": 114, "actionmask": 115, "binarizereward": 116, "burnintransform": 117, "catfram": [118, 349], "cattensor": 119, "centercrop": 120, "cliptransform": 121, "dtypecasttransform": 123, "devicecasttransform": 124, "discreteactionproject": 125, "doubletofloat": 126, "endoflifetransform": 127, "excludetransform": 128, "finitetensordictcheck": 129, "flattenobserv": 130, "frameskiptransform": 131, "grayscal": 132, "inittrack": 133, "klrewardtransform": 134, "noopresetenv": 135, "observationnorm": 136, "observationtransform": 137, "permutetransform": 138, "pinmemorytransform": 139, "r3mtransform": 140, "randomcroptensordict": 141, "removeemptyspec": 142, "renametransform": 143, "resiz": 144, "reward2gotransform": 145, "rewardclip": 146, "rewardsc": 147, "rewardsum": 148, "selecttransform": 149, "signtransform": 150, "squeezetransform": 151, "stepcount": 152, "targetreturn": 153, "tensordictprim": 154, "timemaxpool": 155, "totensorimag": 156, "transformedenv": 158, "unsqueezetransform": 159, "vc1transform": 160, "viprewardtransform": 161, "viptransform": 162, "vecgymenvtransform": 163, "vecnorm": [164, 352], "gsdenois": 165, "check_env_spec": 166, "exploration_mod": 167, "exploration_typ": 168, "get_available_librari": 169, "make_composite_from_td": 170, "set_exploration_mod": 171, "set_exploration_typ": 172, "step_mdp": 173, "terminated_or_trunc": 174, "cemplann": 175, "conv3dnet": 176, "convnet": 177, "dtactor": 178, "ddpgcnnactor": 179, "ddpgcnnqnet": 180, "ddpgmlpactor": 181, "ddpgmlpqnet": 182, "decisiontransform": 183, "delta": 184, "distributionaldqnnet": 185, "distributionalqvaluehook": 186, "dreameractor": 187, "duelingcnndqnet": 188, "gru": 189, "grucel": 190, "grumodul": 191, "independentnorm": 192, "lstm": [193, 343], "lstmcell": 194, "lstmmodul": 195, "lstmnet": 196, "mlp": [197, 343], "mpcplannerbas": 198, "mppiplann": 199, "maskedcategor": 200, "maskedonehotcategor": 201, "multiagentconvnet": 202, "multiagentmlp": 203, "noisylazylinear": 204, "noisylinear": 205, "normalparamwrapp": 206, "obsdecod": 207, "obsencod": 208, "onehotcategor": 209, "onlinedtactor": 210, "qmixer": [211, 336], "qvaluehook": 212, "rssmposterior": 213, "rssmprior": 214, "squeeze2dlay": 215, "squeezelay": 216, "tanhdelta": 217, "tanhnorm": 218, "truncatednorm": 219, "vdnmixer": 220, "vmapmodul": 221, "reset_nois": 222, "actor": [223, 335, 340], "actorcriticoper": 224, "actorcriticwrapp": 225, "actorvalueoper": 226, "additivegaussianwrapp": 227, "decisiontransformerinferencewrapp": 228, "distributionalqvalueactor": 229, "distributionalqvaluemodul": 230, "egreedymodul": 231, "egreedywrapp": 232, "lmheadactorvalueoper": 233, "ornsteinuhlenbeckprocesswrapp": 234, "probabilisticactor": 235, "qvalueactor": 236, "qvaluemodul": 237, "safemodul": [238, 335], "safeprobabilisticmodul": 239, "safeprobabilistictensordictsequenti": 240, "safesequenti": 241, "tanhmodul": 242, "valueoper": 243, "worldmodelwrapp": 244, "biased_softplu": 245, "inv_softplu": 246, "map": 247, "a2closs": 248, "cqlloss": 249, "clipppoloss": 250, "ddpgloss": 251, "dqnloss": 252, "dtloss": 253, "discretecqlloss": 254, "discreteiqlloss": 255, "discretesacloss": 256, "distributionaldqnloss": 257, "dreameractorloss": 258, "dreamermodelloss": 259, "dreamervalueloss": 260, "hardupd": 261, "iqlloss": 262, "klpenppoloss": 263, "lossmodul": [264, 340], "onlinedtloss": 265, "ppoloss": 266, "redqloss": 267, "reinforceloss": 268, "sacloss": 269, "softupd": 270, "td3loss": 271, "valueestim": 272, "default_value_kwarg": 273, "distance_loss": 274, "hold_out_net": 275, "hold_out_param": 276, "qmixerloss": 277, "next_state_valu": 278, "gae": 279, "td0estim": 280, "td1estim": 281, "tdlambdaestim": 282, "valueestimatorbas": 283, "generalized_advantage_estim": 284, "reward2go": 285, "td0_advantage_estim": 286, "td0_return_estim": 287, "td1_advantage_estim": 288, "td1_return_estim": 289, "td_lambda_advantage_estim": 290, "td_lambda_return_estim": 291, "vec_generalized_advantage_estim": 292, "vec_td1_advantage_estim": 293, "vec_td1_return_estim": 294, "vec_td_lambda_advantage_estim": 295, "vec_td_lambda_return_estim": 296, "tensordictrecord": 297, "videorecord": 298, "logger": [299, 337], "csvlogger": 300, "generate_exp_nam": 301, "get_logg": 302, "mlflowlogg": 303, "tensorboardlogg": 304, "wandblogg": 305, "batchsubsampl": 306, "clearcudacach": 307, "countframeslog": 308, "logreward": 309, "optimizerhook": 310, "replaybuffertrain": 312, "rewardnorm": 313, "selectkei": 314, "trainer": [315, 337, 341], "trainerhookbas": 316, "updateweight": 317, "correct_for_frame_skip": 318, "get_stats_random_rollout": 319, "make_collector_offpolici": 320, "make_collector_onpolici": 321, "make_dqn_loss": 322, "make_redq_loss": 323, "make_redq_model": 324, "make_replay_buff": 325, "make_target_updat": 326, "make_train": 327, "parallel_env_constructor": 328, "sync_async_collector": 329, "sync_sync_collector": 330, "transformed_env_constructor": 331, "readm": [332, 344], "tuto": [332, 344], "api": 333, "contribut": [334, 351], "content": 334, "modul": [335, 340, 343, 351], "tensordict": [335, 349, 351], "wrapper": 335, "probabilist": 335, "q": [335, 341, 343], "oper": 335, "join": 335, "hook": [335, 337, 341], "regular": 335, "planner": 335, "object": [336, 340, 351], "dqn": [336, 341, 343], "ddpg": [336, 340], "sac": 336, "redq": 336, "iql": 336, "cql": 336, "dt": 336, "td3": 336, "ppo": [336, 342, 346], "a2c": 336, "dreamer": 336, "builder": 337, "_util": 338, "comput": [339, 341, 347, 350], "time": [339, 340, 350], "code": [340, 347], "setup": [340, 343], "The": 340, "__init__": 340, "method": 340, "estim": 340, "put": 340, "togeth": [340, 347], "call": 340, "parallel": [340, 345, 352], "execut": [340, 345, 347], "stat": 340, "build": [340, 341, 349], "evalu": 340, "batch": [340, 347, 349], "size": [340, 349], "construct": 340, "target": [340, 341], "network": [340, 341, 342, 343, 346], "updat": 340, "experi": [340, 347], "result": [340, 342, 346], "conclus": [340, 341, 342, 343, 346, 347, 349], "A": [341, 349], "exampl": [341, 349], "deep": 341, "collect": [341, 342], "paramet": [341, 342], "hyperparamet": [341, 342, 346], "regist": 341, "possibl": 341, "improv": 341, "defin": [342, 346], "loop": [342, 343, 346, 347], "next": [342, 346], "step": [342, 346, 352], "recurr": 343, "overview": 343, "convolut": 343, "select": 343, "further": 343, "read": 343, "divers": 345, "rollout": [345, 346, 347, 352], "critic": 346, "pendulum": 347, "write": 347, "_step": 347, "reset": [347, 352], "simul": 347, "_reset": 347, "metadata": 347, "_spec": 347, "spec": [347, 352], "shape": 347, "seed": [347, 352], "wrap": 347, "class": [347, 351], "test": 347, "our": 347, "custom": [347, 349], "simpl": 347, "pretrain": 348, "vanilla": 349, "integr": 349, "tensorclass": 349, "sampl": 349, "iter": 349, "over": 349, "fix": 349, "priorit": 349, "save": 349, "raw": 349, "imag": 349, "more": 349, "complex": 349, "introduct": 351, "config": 351, "tensordictmodul": 351, "sequenc": 351, "program": 351, "ensembl": 351, "meta": 351, "special": 351, "state": 351, "frame_skip": 352, "deepmind": 352, "control": 352, "devic": 352, "run": 352, "close": 352, "access": 352, "attribut": 352, "kwarg": 352}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 56}})